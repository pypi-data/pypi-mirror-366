import os
import hashlib
import time
import shutil
from tabnanny import verbose
from typing import Any, Optional, List, Dict

from llama_index.core import (
    SimpleDirectoryReader,
    Settings,
    Document,
    StorageContext,
    VectorStoreIndex,
)
from llama_index.core.ingestion import IngestionPipeline
from llama_index.core.storage.docstore import SimpleDocumentStore
from llama_index.core.node_parser import SemanticSplitterNodeParser
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.agent.workflow import ReActAgent, ToolCallResult, AgentStream
from llama_index.core.agent.react.formatter import ReActChatFormatter
from llama_index.core.tools import QueryEngineTool
from llama_index.core.workflow import Context
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.embeddings.google_genai import GoogleGenAIEmbedding
from llama_index.llms.google_genai import GoogleGenAI
from qdrant_client import AsyncQdrantClient, QdrantClient

from .knowledge_base_store import KnowledgeBaseStore
from .adapters.file_source_adapter import FileSourceAdapter


def generate_document_id(file_path: str, page_label: Optional[str] = None) -> str:
    """Generate MD5-based document ID from file_path and page_label

    Args:
        file_path: The file path
        page_label: Optional page label, defaults to empty string if None

    Returns:
        str: MD5 hash of file_path + page_label
    """
    page_label = page_label or ""  # Empty string if None
    content = f"{file_path}{page_label}"
    return hashlib.md5(content.encode("utf-8")).hexdigest()


class KnowledgeBaseQdrantStore(KnowledgeBaseStore):
    """Qdrant Knowledge Base Store Implementation

    åŸºæ–¼ LlamaIndex å’Œ Qdrant çš„çŸ¥è­˜åº«å¯¦ç¾ã€‚
    æ”¯æ´ Google GenAI embeddings å’Œèªç¾©åˆ‡åˆ†è™•ç†ã€‚
    """

    def __init__(
        self,
        file_source_adapter: FileSourceAdapter,
        qdrant_client: QdrantClient,
        qdrant_aclient: AsyncQdrantClient,
        google_api_key: str,
        embedding_model: str = "gemini-embedding-001",
        llm_model: str = "gemini-2.5-flash",
    ):
        """Initialize Qdrant Knowledge Base Store

        Args:
            file_source_adapter: FileSourceAdapter instance
            qdrant_client: Qdrant client instance
            qdrant_client: AsyncQdrant client instance
            google_api_key: Google GenAI API key
            embedding_model: Embedding model name
            llm_model: ReAct Agent æŸ¥è©¢æ™‚ä½¿ç”¨çš„æ¨¡å‹åç¨±
        """
        super().__init__(file_source_adapter)
        self.qdrant_client = qdrant_client
        self.qdrant_aclient = qdrant_aclient
        self.google_api_key = google_api_key
        self.embedding_model = embedding_model
        self.llm_model = llm_model
        self.collection_name = file_source_adapter.get_collection_name()

        # Cache directory for IngestionPipeline
        cache_base_dir = ".pipeline_cache"
        os.makedirs(cache_base_dir, exist_ok=True)
        self.cache_dir = os.path.join(cache_base_dir, f"storage_{self.collection_name}")

        # Initialize components
        self._setup_embeddings()
        self._setup_llm()
        self._setup_vector_store()
        self._setup_node_parser()

        # Will be set during rebuild
        self.index: Optional[VectorStoreIndex] = None
        self.query_engine: Optional[RetrieverQueryEngine] = None

    def _setup_embeddings(self) -> None:
        """è¨­å®š Google GenAI Embeddings"""
        self.embed_model = GoogleGenAIEmbedding(
            model_name=self.embedding_model,
            api_key=self.google_api_key,
            retries=5,
            timeout=30,
            retry_min_seconds=10,
            retry_max_seconds=30,
            retry_exponential_base=2,
        )
        # Set global embedding model
        Settings.embed_model = self.embed_model

    def _setup_llm(self) -> None:
        """è¨­å®š Google Gemini MultiModal LLM"""
        self.agent_llm = GoogleGenAI(
            model=self.llm_model, api_key=self.google_api_key  # ä½¿ç”¨æŒ‡å®šçš„ Gemini æ¨¡å‹
        )
        # Set global LLM
        Settings.llm = self.agent_llm

    def _setup_vector_store(self) -> None:
        """è¨­å®š Qdrant Vector Store with Hybrid Search"""
        self.vector_store = QdrantVectorStore(
            client=self.qdrant_client,
            aclient=self.qdrant_aclient,
            collection_name=self.collection_name,
            enable_hybrid=True,  # è§£æ±ºå‘é‡å‘½åå•é¡Œ
            fastembed_sparse_model="Qdrant/bm25",  # BM25 sparse vectors
            batch_size=20,  # æ‰¹æ¬¡è™•ç†å„ªåŒ–
        )

    def _setup_node_parser(self) -> None:
        """è¨­å®šèªæ„åˆ‡åˆ†å™¨"""
        self.node_parser = SemanticSplitterNodeParser(
            buffer_size=1,
            breakpoint_percentile_threshold=95,
            embed_model=self.embed_model,
        )
        # Set global node parser
        Settings.node_parser = self.node_parser

    def create_hybrid_query_engine(
        self, index: VectorStoreIndex
    ) -> RetrieverQueryEngine:
        """å»ºç«‹æ··åˆæœå°‹æŸ¥è©¢å¼•æ“"""
        return index.as_query_engine(
            vector_store_query_mode="hybrid",
            similarity_top_k=2,  # Dense vector results
            sparse_top_k=12,  # Sparse vector results
            hybrid_top_k=3,  # Final fused results
            response_mode="tree_summarize",
            use_async=True,
        )

    def create_hybrid_agent(
        self, query_engine: RetrieverQueryEngine, system_prompt: Optional[str] = None
    ) -> ReActAgent:
        """å»ºç«‹æ”¯æ´æ··åˆæœå°‹çš„ ReAct Agent"""
        query_tool = QueryEngineTool.from_defaults(
            query_engine=query_engine,
            name="hybrid_knowledge_base_query",
            description=(
                "Query the knowledge base for relevant information and document content. "
                "Uses hybrid search technology combining semantic understanding and keyword matching "
                "to provide more accurate and comprehensive search results. "
                "Supports Traditional Chinese, Taiwan terminology, and mixed Chinese-English queries."
            ),
        )

        # Default system prompt in English
        default_agent_prompt = """
        - You MUST use English to answer questions.
        - You can only answer questions based on the tool results. If there is no information, respond that there is no information in the knowledge base. You must not answer on your own.
        - Use as much information as possible from the tool results to answer the question.
        """

        # Use provided system_prompt or default
        agent_prompt = (
            system_prompt if system_prompt is not None else default_agent_prompt
        )

        # Create custom formatter with system prompt
        custom_formatter = ReActChatFormatter.from_defaults(context=agent_prompt)

        return ReActAgent(
            tools=[query_tool],
            llm=self.agent_llm,
            formatter=custom_formatter,
        )

    async def refresh_knowledge_base(self) -> None:
        """åˆ·æ–°çŸ¥è­˜åº«

        å¦‚æœçŸ¥è­˜åº«ä¸å­˜åœ¨ï¼Œæœƒè‡ªå‹•å»ºç«‹ï¼›å¦‚æœå·²å­˜åœ¨ï¼Œæœƒé€²è¡Œæ›´æ–°ã€‚
        åŸ·è¡Œå®Œæ•´çš„æ–‡ä»¶è™•ç†æµç¨‹ï¼šæª”æ¡ˆè¼‰å…¥ â†’ èªç¾©åˆ‡åˆ† â†’ å‘é‡åŒ– â†’ ç´¢å¼•å»ºç«‹
        """
        print(f"ğŸ”„ é–‹å§‹åˆ·æ–°çŸ¥è­˜åº«: {self.collection_name}")

        # Step 1: æª”æ¡ˆæƒæèˆ‡è¼‰å…¥
        print("ğŸ“ æƒææª”æ¡ˆ...")
        file_paths = await self.file_source_adapter.get_files()

        if not file_paths:
            print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•æª”æ¡ˆï¼Œé›†åˆ: {self.collection_name}")
            return

        print(f"   æ‰¾åˆ° {len(file_paths)} å€‹æª”æ¡ˆ")

        # Step 2: æº–å‚™è™•ç†ï¼ˆä¸æ¸…ç©ºçŸ¥è­˜åº«ï¼Œç”± SimpleDocumentStore è™•ç†é‡è¤‡ï¼‰
        print("ğŸš€ æº–å‚™å¹³è¡Œè™•ç†æµç¨‹...")

        try:
            # Step 3: æ–‡ä»¶è¼‰å…¥èˆ‡è™•ç†
            print("ğŸ“– è¼‰å…¥æ–‡ä»¶...")
            documents = []
            successful_files = 0
            failed_files = 0

            for file_path in file_paths:
                try:
                    reader = SimpleDirectoryReader(input_files=[file_path])
                    docs = reader.load_data()

                    # Set custom doc_id and add metadata
                    for doc in docs:
                        file_path_meta = doc.metadata.get("file_path", file_path)
                        page_label = doc.metadata.get("page_label", "")

                        # Generate custom doc_id
                        doc.doc_id = generate_document_id(file_path_meta, page_label)

                        # Add basic metadata (remove redundant updates)
                        doc.metadata.update(
                            {
                                "file_path": file_path,
                                "file_name": os.path.basename(file_path),
                                "collection": self.collection_name,
                            }
                        )

                    documents.extend(docs)
                    successful_files += 1

                except Exception as e:
                    import traceback

                    traceback.print_exc()
                    print(f"   âš ï¸  è¼‰å…¥å¤±æ•— {file_path}: {e}")
                    failed_files += 1
                    continue

            if not documents:
                print("âŒ æ²’æœ‰æˆåŠŸè¼‰å…¥ä»»ä½•æ–‡ä»¶")
                return

            print(f"   âœ… æˆåŠŸè¼‰å…¥: {successful_files} æª”æ¡ˆ")
            if failed_files > 0:
                print(f"   âš ï¸  è¼‰å…¥å¤±æ•—: {failed_files} æª”æ¡ˆ")

            # Step 4: ä½¿ç”¨ IngestionPipeline é€²è¡Œæ‰¹æ¬¡è™•ç† (å« Cache æ©Ÿåˆ¶)
            print("âš¡ ä½¿ç”¨ IngestionPipeline é€²è¡Œæ‰¹æ¬¡è™•ç†...")
            print(f"   ğŸ“ Cache ç›®éŒ„: {self.cache_dir}")

            # æ‰¹æ¬¡è™•ç†è¨­å®š
            BATCH_SIZE = 50
            MAX_RETRIES = 3
            RETRY_DELAY = 60  # seconds

            # Create IngestionPipeline with SimpleDocumentStore for duplicate detection
            pipeline = IngestionPipeline(
                transformations=[
                    self.node_parser,
                    self.embed_model,
                ],
                docstore=SimpleDocumentStore(),
                vector_store=self.vector_store,
            )

            # Load existing cache if available
            if os.path.exists(self.cache_dir):
                print("   ğŸ“‚ è¼‰å…¥ç¾æœ‰ cache...")
                try:
                    pipeline.load(self.cache_dir)
                    print("   âœ… Cache è¼‰å…¥æˆåŠŸ")
                except Exception as e:
                    print(f"   âš ï¸  Cache è¼‰å…¥å¤±æ•—: {e}")
                    print("   ğŸ”„ å°‡å»ºç«‹æ–°çš„ cache")

            # é–‹å§‹æ‰¹æ¬¡è™•ç†
            all_nodes = []
            total_batches = (len(documents) + BATCH_SIZE - 1) // BATCH_SIZE

            print(f"   ğŸ“¦ é–‹å§‹æ‰¹æ¬¡è™•ç†ï¼š{len(documents)} å€‹æ–‡ä»¶åˆ†ç‚º {total_batches} æ‰¹")

            # æ‰¹æ¬¡è™•ç†å¾ªç’°
            for batch_idx in range(total_batches):
                batch_start = batch_idx * BATCH_SIZE
                batch_end = min(batch_start + BATCH_SIZE, len(documents))
                batch = documents[batch_start:batch_end]

                print(
                    f"   ğŸ“¦ è™•ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} ({len(batch)} å€‹æ–‡ä»¶)"
                )

                # é‡è©¦æ©Ÿåˆ¶
                batch_success = False
                for attempt in range(MAX_RETRIES):
                    try:
                        batch_nodes = pipeline.run(
                            documents=batch,
                            num_workers=1,  # é¿å… multiprocessing å•é¡Œ
                            show_progress=True,
                        )

                        all_nodes.extend(batch_nodes if batch_nodes else [])

                        # æ¯æ‰¹è™•ç†å®Œç«‹å³ä¿å­˜ cache
                        pipeline.persist(self.cache_dir)
                        print(
                            f"   âœ… æ‰¹æ¬¡ {batch_idx + 1} è™•ç†å®Œæˆ ({len(batch_nodes) if batch_nodes else 0} å€‹ç¯€é»)ï¼Œcache å·²ä¿å­˜"
                        )
                        batch_success = True
                        break

                    except Exception as e:
                        if attempt < MAX_RETRIES - 1:
                            print(
                                f"   âš ï¸  æ‰¹æ¬¡ {batch_idx + 1} å¤±æ•— (å˜—è©¦ {attempt + 1}/{MAX_RETRIES}): {e}"
                            )
                            print(f"   ğŸ˜´ ç­‰å¾… {RETRY_DELAY} ç§’å¾Œé‡è©¦...")
                            time.sleep(RETRY_DELAY)
                        else:
                            import traceback

                            traceback.print_exc()
                            print(f"   âŒ æ‰¹æ¬¡ {batch_idx + 1} æœ€çµ‚å¤±æ•—: {e}")
                            # ä¸ç«‹å³ raiseï¼Œç¹¼çºŒè™•ç†å…¶ä»–æ‰¹æ¬¡ï¼Œæœ€å¾Œçµ±ä¸€å ±å‘Šå¤±æ•—
                            raise e

                if not batch_success:
                    print(f"   âš ï¸  è·³éå¤±æ•—çš„æ‰¹æ¬¡ {batch_idx + 1}ï¼Œç¹¼çºŒè™•ç†å‰©é¤˜æ‰¹æ¬¡")

            # æœ€çµ‚çµæœ
            nodes = all_nodes
            print(f"   ğŸ¯ æ‰¹æ¬¡è™•ç†å®Œæˆï¼šç¸½å…±è™•ç† {len(nodes)} å€‹ç¯€é»")
            # Step 5: å¾ vector store å»ºç«‹ç´¢å¼•
            print("ğŸ”¢ å»ºç«‹å‘é‡ç´¢å¼•...")
            self.index = VectorStoreIndex.from_vector_store(
                vector_store=self.vector_store,
                embed_model=self.embed_model,
            )

            # Step 6: é©—è­‰ Qdrant Collection æ˜¯å¦å»ºç«‹æˆåŠŸ
            print("ğŸ” é©—è­‰ Qdrant Collection...")
            try:
                collections = await self.qdrant_aclient.get_collections()
                collection_names = [col.name for col in collections.collections]

                if self.collection_name not in collection_names:
                    print(f"âŒ Qdrant Collection å»ºç«‹å¤±æ•—: {self.collection_name}")
                    print("   é‡å»ºæµç¨‹ä¸­æ­¢")
                    return

                # ç²å– collection è³‡è¨Šç¢ºèªæœ‰è³‡æ–™
                collection_info = await self.qdrant_aclient.get_collection(
                    self.collection_name
                )
                points_count = collection_info.points_count

                if points_count == 0:
                    print(
                        f"âš ï¸  Qdrant Collection å·²å»ºç«‹ä½†ç„¡è³‡æ–™: {self.collection_name}"
                    )
                    print("   å¯èƒ½æ˜¯è™•ç†éç¨‹ä¸­ç™¼ç”Ÿå•é¡Œ")
                    return

                print(f"   âœ… Collection å»ºç«‹æˆåŠŸï¼Œå‘é‡æ•¸é‡: {points_count}")

            except Exception as e:
                print(f"âŒ é©—è­‰ Qdrant Collection å¤±æ•—: {e}")
                print("   é‡å»ºæµç¨‹ä¸­æ­¢")
                return

            # Step 7: å»ºç«‹æ··åˆæœå°‹æŸ¥è©¢å¼•æ“
            print("ğŸ” è¨­å®šæ··åˆæœå°‹å¼•æ“...")
            self.query_engine = self.create_hybrid_query_engine(self.index)

            print(f"âœ… çŸ¥è­˜åº«åˆ·æ–°å®Œæˆï¼")
            print(f"   è™•ç†æ–‡ä»¶æ•¸é‡: {len(documents)}")
            print(f"   è™•ç†ç¯€é»æ•¸é‡: {len(nodes) if nodes else 0}")
            print(f"   å‘é‡æ•¸é‡: {points_count}")
            print(f"   é›†åˆåç¨±: {self.collection_name}")
            print(f"   æ‰¹æ¬¡è™•ç†: {total_batches} æ‰¹æ¬¡ (æ¯æ‰¹ {BATCH_SIZE} å€‹æ–‡ä»¶)")
            print(f"   é‡è©¦è¨­å®š: æœ€å¤š {MAX_RETRIES} æ¬¡ï¼Œé–“éš” {RETRY_DELAY} ç§’")
            print(f"   Cache ç›®éŒ„: {self.cache_dir}")

        except Exception as e:
            import traceback

            traceback.print_exc()
            print(f"âŒ åˆ·æ–°çŸ¥è­˜åº«å¤±æ•—: {e}")
            raise
        finally:
            # æ¸…ç†æš«å­˜æª”æ¡ˆ
            self.file_source_adapter.cleanup_temp_files(file_paths)

    async def clear_knowledge_base(self) -> None:
        """æ¸…ç©ºçŸ¥è­˜åº«

        ç§»é™¤æ‰€æœ‰å‘é‡è³‡æ–™å’Œç´¢å¼•ï¼Œæ¸…ç©ºå¿«å–ï¼Œé‡ç½®çŸ¥è­˜åº«ç‚ºç©ºç™½ç‹€æ…‹ã€‚
        """
        try:
            # Check if collection exists
            collections = await self.qdrant_aclient.get_collections()
            collection_names = [col.name for col in collections.collections]

            if self.collection_name in collection_names:
                # Delete collection from Qdrant
                await self.qdrant_aclient.delete_collection(self.collection_name)
                print(f"   ğŸ—‘ï¸  å·²åˆªé™¤é›†åˆ: {self.collection_name}")
            else:
                print(f"   â„¹ï¸  é›†åˆä¸å­˜åœ¨: {self.collection_name}")

            # Clear cache directory
            if os.path.exists(self.cache_dir):
                shutil.rmtree(self.cache_dir)
                print(f"   ğŸ—‘ï¸  å·²æ¸…ç©ºå¿«å–ç›®éŒ„: {self.cache_dir}")
            else:
                print(f"   â„¹ï¸  å¿«å–ç›®éŒ„ä¸å­˜åœ¨: {self.cache_dir}")

            # Reset index and query engine
            self.index = None
            self.query_engine = None

            print(f"   âœ… çŸ¥è­˜åº«å·²æ¸…ç©º")

        except Exception as e:
            print(f"   âŒ æ¸…ç©ºçŸ¥è­˜åº«å¤±æ•—: {e}")
            raise

    async def query_knowledge_base(self, query: str, system_prompt: Optional[str] = None) -> str:
        """æŸ¥è©¢çŸ¥è­˜åº«

        ä½¿ç”¨ ReAct Agent æŸ¥è©¢ç›¸é—œæ–‡ä»¶ç‰‡æ®µï¼Œé‡å°ç¹é«”ä¸­æ–‡å’Œå°ç£ç”¨èªå„ªåŒ–ã€‚

        Args:
            query: æŸ¥è©¢å­—ä¸²ï¼ˆæ”¯æ´ç¹é«”ä¸­æ–‡å’Œä¸­è‹±æ··åˆï¼‰
            system_prompt: ç³»çµ±æç¤ºè©ï¼ˆå¯é¸ï¼‰

        Returns:
            str: æŸ¥è©¢çµæœå›æ‡‰
        """
        if not self.query_engine:
            raise RuntimeError("çŸ¥è­˜åº«å°šæœªåˆå§‹åŒ–ï¼Œè«‹å…ˆåŸ·è¡Œåˆ·æ–°")

        try:
            print(f"ğŸ¤– ä½¿ç”¨æ··åˆæœå°‹ ReAct Agent æŸ¥è©¢: {query}")

            # response = await self.query_engine.aquery(query)
            # print("ğŸ“– Query Engine Response: ")
            # print("-" * 50)
            # print(response)
            # Create hybrid agent
            agent = self.create_hybrid_agent(self.query_engine, system_prompt)

            # Create context for this session
            ctx = Context(agent)

            # Process query with agent and stream the thinking process
            print(f"ğŸ§  Agent æ€è€ƒéç¨‹ï¼š")
            print("-" * 50)

            handler = agent.run(query, ctx=ctx)

            # Stream the events to show thinking process
            async for ev in handler.stream_events():
                if isinstance(ev, ToolCallResult):
                    print(f"ğŸ”§ èª¿ç”¨å·¥å…·: {ev.tool_name}")
                    print(f"   åƒæ•¸: {ev.tool_kwargs}")
                    print(f"   çµæœ: {str(ev.tool_output)[:200]}...")
                    for source_node in ev.tool_output.raw_output.source_nodes:
                        print(f"     -- åƒè€ƒä¾†æº node id: {source_node.node_id}")
                        print(f"     -- åƒè€ƒä¾†æº node åˆ†æ•¸: {source_node.score}")
                        print(f"     -- åƒè€ƒä¾†æº node å…§å®¹: {source_node.text}")
                    print()
                elif isinstance(ev, AgentStream):
                    print(ev.delta, end="", flush=True)
                # else:
                #     print(ev)

            # Get final response
            response = await handler
            result = str(response)

            print()
            print("-" * 50)
            print(f"   âœ… Agent æŸ¥è©¢å®Œæˆ")
            return result

        except Exception as e:
            print(f"   âŒ æŸ¥è©¢å¤±æ•—: {e}")
            raise

    async def load_from_existing_collection(self) -> None:
        """å¾ç¾æœ‰ Qdrant collection è¼‰å…¥çŸ¥è­˜åº«ç´¢å¼•"""

        print(f"ğŸ“¥ è¼‰å…¥ç¾æœ‰çŸ¥è­˜åº«ç´¢å¼•: {self.collection_name}")

        try:
            # Phase 1: Collection Validation
            await self._validate_existing_collection()

            # Phase 2: Index Creation from Existing Vectors
            self._create_index_from_existing_vectors()

            # Phase 3: Query Engine Initialization
            self._initialize_query_components()

            # Phase 4: Success Confirmation
            await self._confirm_load_success()

        except Exception as e:
            print(f"âŒ è¼‰å…¥å¤±æ•—: {e}")
            # Reset to safe state
            self.index = None
            self.query_engine = None
            raise

    async def _validate_existing_collection(self) -> None:
        """é©—è­‰ç¾æœ‰ collection çš„å­˜åœ¨æ€§å’Œç›¸å®¹æ€§"""

        # Check collection existence
        collections = await self.qdrant_aclient.get_collections()
        collection_names = [col.name for col in collections.collections]

        if self.collection_name not in collection_names:
            raise RuntimeError(f"Collection ä¸å­˜åœ¨: {self.collection_name}")

        # Get collection info
        collection_info = await self.qdrant_aclient.get_collection(self.collection_name)

        # Validate vector configuration
        vector_config = collection_info.config.params.vectors

        if isinstance(vector_config, dict):
            # Dense vector validation
            if "dense" in vector_config:
                dense_size = vector_config["dense"].size
                expected_size = 3072  # gemini-embedding-001 dimension

                if dense_size != expected_size:
                    raise ValueError(
                        f"å‘é‡ç¶­åº¦ä¸ç¬¦: æœŸæœ› {expected_size}, å¯¦éš› {dense_size}"
                    )

        print(f"   âœ… Collection é©—è­‰é€šé")

    def _create_index_from_existing_vectors(self) -> None:
        """å¾ç¾æœ‰å‘é‡å»ºç«‹ VectorStoreIndexï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰"""

        print("ğŸ”¢ å¾ç¾æœ‰å‘é‡å»ºç«‹ç´¢å¼•...")

        # Create index from existing vector store with optimizations
        self.index = VectorStoreIndex.from_vector_store(
            vector_store=self.vector_store,
            embed_model=self.embed_model,
            show_progress=False,  # è¼‰å…¥æ¨¡å¼ä¸éœ€è¦é€²åº¦é¡¯ç¤º
            use_async=False,  # Sync for faster small operations
        )

        print(f"   âœ… ç´¢å¼•å»ºç«‹å®Œæˆ")

    def _initialize_query_components(self) -> None:
        """åˆå§‹åŒ–æŸ¥è©¢å¼•æ“çµ„ä»¶"""

        print("ğŸ” è¨­å®šæŸ¥è©¢å¼•æ“...")

        # Create hybrid query engine with same config as rebuild mode
        self.query_engine = self.create_hybrid_query_engine(self.index)

        print(f"   âœ… æŸ¥è©¢å¼•æ“è¨­å®šå®Œæˆ")

    async def _confirm_load_success(self) -> None:
        """ç¢ºèªè¼‰å…¥æˆåŠŸä¸¦é¡¯ç¤ºç‹€æ…‹è³‡è¨Š"""

        # Get collection statistics
        collection_info = await self.qdrant_aclient.get_collection(self.collection_name)

        points_count = collection_info.points_count

        print(f"âœ… çŸ¥è­˜åº«è¼‰å…¥å®Œæˆï¼")
        print(f"   Collection: {self.collection_name}")
        print(f"   å‘é‡æ•¸é‡: {points_count}")
        print(f"   æŸ¥è©¢æ¨¡å¼: Hybrid Search (Dense + Sparse)")
