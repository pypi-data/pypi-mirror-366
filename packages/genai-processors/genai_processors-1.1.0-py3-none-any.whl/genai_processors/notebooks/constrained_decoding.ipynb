{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiEUDeWHA44f"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 DeepMind Technologies Limited. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59hCSLjTBmXC"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/genai-processors/blob/main/notebooks/constrained_decoding_intro.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_markdown_refactored"
      },
      "source": [
        "# Structured Clarity: Dataclasses as a Modality\n",
        "\n",
        "Large language models are great at generating text, but what if you need to work with structured data like Python `dataclasses`? The GenAI Processors library treats your custom data types as just another modality, like text or images.\n",
        "\n",
        "This makes it trivial to create pipelines that consume, produce, and transform structured data. The key features are:\n",
        "\n",
        "*   **Dataclasses as a Modality:** Your custom `dataclasses` can be easily packed into and unpacked from `ProcessorPart` objects using `ProcessorPart.from_dataclass()` and `part.get_dataclass()`. The underlying representation is simply JSON.\n",
        "*   **Automatic Model Integration:** When using `GenaiModel` or `OllamaModel`, you can simply specify a `response_schema` (e.g., `response_schema=MyDataclass`). The library automatically handles the constrained decoding request and parses the model's JSON output into typed `ProcessorPart` objects, ready for you to use. If the schema is a list, each item is yielded as a separate part, enabling concurrent processing.\n",
        "\n",
        "This notebook will walk you through these features, showing how to seamlessly integrate structured data into your AI workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G7p8Vi3JYHP"
      },
      "source": [
        "## 1. ‚öôÔ∏è Setup\n",
        "\n",
        "First, let's install the GenAI Processors library and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GasIyUf5JYHP"
      },
      "outputs": [],
      "source": [
        "!pip install -q genai-processors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMu9r0YZJYHP"
      },
      "source": [
        "### API Key\n",
        "\n",
        "To use the GenAI model processors, you'll need a Gemini API key. If you haven't already, get your key from Google AI Studio and add it as a secret in Colab (recommended) or set it directly below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fybEpDUNJYHP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "  os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "except userdata.SecretNotFoundError:\n",
        "  print(\n",
        "      'GOOGLE_API_KEY not found in Colab secrets. You can still run the'\n",
        "      ' notebook, but the sections using GenaiModel will fail.'\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_cell"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import dataclasses\n",
        "import enum\n",
        "\n",
        "import dataclasses_json\n",
        "from genai_processors import content_api\n",
        "from genai_processors import processor\n",
        "from genai_processors import streams\n",
        "from genai_processors.core import constrained_decoding\n",
        "from genai_processors.core import genai_model\n",
        "from google.genai import types as genai_types\n",
        "from IPython.display import Markdown, display\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()  # Needed to run async loops in Colab\n",
        "\n",
        "ProcessorPart = content_api.ProcessorPart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pr6m_l0JYHP"
      },
      "source": [
        "## 2. üé¨ Defining Our Data Structures\n",
        "\n",
        "First, let's define the Python data structures (`dataclasses` and `enums`) that we want our model to generate. These act as the \"schema\" for our desired output.\n",
        "\n",
        "**Note:** For `dataclasses`, you must use the `@dataclasses_json.dataclass_json` decorator to enable automatic JSON serialization and deserialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define_dataclasses_cell"
      },
      "outputs": [],
      "source": [
        "class Genre(enum.StrEnum):\n",
        "  \"\"\"Enum for movie genres.\"\"\"\n",
        "\n",
        "  SCI_FI = \"Science Fiction\"\n",
        "  FANTASY = \"Fantasy\"\n",
        "  ACTION = \"Action\"\n",
        "  COMEDY = \"Comedy\"\n",
        "  DRAMA = \"Drama\"\n",
        "\n",
        "\n",
        "@dataclasses_json.dataclass_json\n",
        "@dataclasses.dataclass(frozen=True)\n",
        "class Actor:\n",
        "  \"\"\"Represents a single actor.\"\"\"\n",
        "\n",
        "  name: str\n",
        "  birth_year: int\n",
        "\n",
        "\n",
        "@dataclasses_json.dataclass_json\n",
        "@dataclasses.dataclass(frozen=True)\n",
        "class Movie:\n",
        "  \"\"\"Represents a movie with its details.\"\"\"\n",
        "\n",
        "  title: str\n",
        "  release_year: int\n",
        "  genre: Genre\n",
        "  lead_actors: list[Actor]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataclass_modality_intro"
      },
      "source": [
        "## 3. üß© Custom Dataclasses as a Modality\n",
        "\n",
        "The library is designed to let you treat your own data types as a first-class modality, just like text or images. You can easily pack a dataclass instance into a `ProcessorPart` and unpack it later.\n",
        "\n",
        "This is useful for passing structured data between processors in a pipeline. Under the hood, the `ProcessorPart` simply stores the object as a JSON string, which means it's still compatible with any model that expects text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pack_unpack_example"
      },
      "outputs": [],
      "source": [
        "# 1. Create an instance of our dataclass.\n",
        "movie_instance = Movie(\n",
        "    title=\"The Matrix\",\n",
        "    release_year=1999,\n",
        "    genre=Genre.SCI_FI,\n",
        "    lead_actors=[Actor(name=\"Keanu Reeves\", birth_year=1964)],\n",
        ")\n",
        "\n",
        "# 2. Pack it into a ProcessorPart.\n",
        "part = ProcessorPart.from_dataclass(dataclass=movie_instance)\n",
        "\n",
        "print(\"The underlying representation is just JSON:\")\n",
        "print(part.text)\n",
        "print(\"\\n---\\n\")\n",
        "\n",
        "# 3. Unpack it back into a Python object.\n",
        "unpacked_movie = part.get_dataclass(Movie)\n",
        "\n",
        "print(f\"Unpacked a '{type(unpacked_movie).__name__}' object:\")\n",
        "print(unpacked_movie)\n",
        "\n",
        "# They are identical.\n",
        "assert movie_instance == unpacked_movie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "automatic_usage_intro"
      },
      "source": [
        "## 4. ü™Ñ Automatic Structured Output from Models\n",
        "\n",
        "While packing and unpacking data is useful, the real power comes from getting structured objects directly from a language model.\n",
        "\n",
        "With `GenaiModel` (and `OllamaModel`), you don't need to do any manual parsing. Simply provide your `dataclass` or `enum` as the `response_schema` in the model's configuration. The library will then automatically:\n",
        "\n",
        "1.  Instruct the model to generate a JSON response matching your schema.\n",
        "2.  Parse the incoming JSON stream.\n",
        "3.  Yield `ProcessorPart` objects that are already packed with your dataclass instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "automatic_single_cell"
      },
      "source": [
        "### Example: Generating a Single Object\n",
        "\n",
        "Let's ask the model to invent a movie and return it directly as a structured `Movie` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "automatic_single_code"
      },
      "outputs": [],
      "source": [
        "# Configure the model to use our Movie dataclass as the response schema.\n",
        "structured_movie_model = genai_model.GenaiModel(\n",
        "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generate_content_config=genai_types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Movie,\n",
        "        temperature=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "prompt = (\n",
        "    \"Invent a plausible but fictional sci-fi movie. It should be a completely\"\n",
        "    \" new concept.\"\n",
        ")\n",
        "output_parts = processor.apply_sync(structured_movie_model, [prompt])\n",
        "\n",
        "movie_instance = output_parts[0].get_dataclass(Movie)\n",
        "print(\n",
        "    f\"The model generated a '{type(movie_instance).__name__}' object\"\n",
        "    \" directly!\\n\"\n",
        ")\n",
        "print(movie_instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "list_json_cell"
      },
      "source": [
        "### Example: Generating a List of Objects\n",
        "\n",
        "This feature is even more powerful when working with lists. If you specify the target schema as a `list` (e.g., `list[Movie]`), the model processor will parse the JSON array and **yield each item as a separate `ProcessorPart`**.\n",
        "\n",
        "This is incredibly useful for creating pipelines where subsequent processors can operate on each item individually and concurrently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "list_json_code"
      },
      "outputs": [],
      "source": [
        "# This time, the schema is a list of movies.\n",
        "movie_list_model = genai_model.GenaiModel(\n",
        "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generate_content_config=genai_types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=list[Movie],\n",
        "    ),\n",
        ")\n",
        "\n",
        "prompt = \"Recommend two classic fantasy movies from the 1980s.\"\n",
        "output_parts = processor.apply_sync(movie_list_model, [prompt])\n",
        "\n",
        "print(\n",
        "    f\"The model returned {len(output_parts)} separate parts, one for each\"\n",
        "    \" movie:\"\n",
        ")\n",
        "for i, part in enumerate(output_parts):\n",
        "  movie = part.get_dataclass(Movie)\n",
        "  print(f\"  Part {i+1}: {movie.title}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "full_pipeline_cell"
      },
      "source": [
        "## 5. üßë‚Äçüî¨ Building a Pipeline with Structured Data\n",
        "\n",
        "Now that we can reliably get structured `Movie` objects from the model, let's use them in a pipeline. Our agent will:\n",
        "\n",
        "1.  Take a user prompt asking for movie recommendations.\n",
        "2.  Use a `GenaiModel` configured to return a `list[Movie]`, which yields each `Movie` as a separate part.\n",
        "3.  Chain a custom `PartProcessor` that takes each `Movie` object and formats it into a nice Markdown summary.\n",
        "4.  Display the formatted summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "full_pipeline_code"
      },
      "outputs": [],
      "source": [
        "@processor.part_processor_function\n",
        "async def format_movie_summary(\n",
        "    part: content_api.ProcessorPart,\n",
        ") -\u003e str:\n",
        "  \"\"\"Takes a ProcessorPart containing a Movie and yields a Markdown string.\"\"\"\n",
        "  movie = part.get_dataclass(Movie)  # Unpack the movie object from the part.\n",
        "  if not movie:\n",
        "    return  # Ignore any parts that aren't Movies.\n",
        "\n",
        "  actor_list = \", \".join([actor.name for actor in movie.lead_actors])\n",
        "  summary = (\n",
        "      f\"### {movie.title} ({movie.release_year})\\n\"\n",
        "      f\"**Genre**: {movie.genre.value}\\n\"\n",
        "      f\"**Starring**: {actor_list}\\n\"\n",
        "      \"---\"\n",
        "  )\n",
        "  yield summary\n",
        "\n",
        "\n",
        "movie_recommender_model = genai_model.GenaiModel(\n",
        "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generate_content_config=genai_types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=list[Movie],\n",
        "    ),\n",
        ")\n",
        "\n",
        "recommendation_agent = movie_recommender_model + format_movie_summary\n",
        "\n",
        "prompt = \"Recommend three classic fantasy movies from the 1980s.\"\n",
        "\n",
        "display(Markdown(f\"**User Prompt:** *{prompt}*\\n\"))\n",
        "display(Markdown(\"## Recommendations\"))\n",
        "async for result_part in recommendation_agent(\n",
        "    processor.stream_content([prompt])\n",
        "):\n",
        "  display(Markdown(result_part.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced_intro"
      },
      "source": [
        "## 6. ‚öôÔ∏è Advanced: Under the Hood\n",
        "\n",
        "For most use cases, the automatic handling of structured output shown above is all you need. However, for advanced scenarios, you might want to control the process more directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "disable_parsing_cell"
      },
      "source": [
        "### Disabling Automatic Parsing\n",
        "\n",
        "What if you provide a `response_schema` to guide the model's output, but you still want the raw JSON string instead of the parsed dataclass? You can achieve this by setting `stream_json=True` in the model processor's constructor. This disables the automatic parsing behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "disable_parsing_code"
      },
      "outputs": [],
      "source": [
        "# This model will still request JSON from the API, but won't parse it.\n",
        "raw_json_model = genai_model.GenaiModel(\n",
        "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generate_content_config=genai_types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Movie,  # The API is still guided by this.\n",
        "    ),\n",
        "    stream_json=True,  # This is the key to disable parsing.\n",
        ")\n",
        "\n",
        "prompt = \"Invent a plausible but fictional fantasy movie.\"\n",
        "output_parts = processor.apply_sync(raw_json_model, [prompt])\n",
        "\n",
        "raw_json_string = content_api.as_text(output_parts)\n",
        "print(\"Got the raw JSON string from the model:\\n\")\n",
        "print(raw_json_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "direct_usage_intro_advanced"
      },
      "source": [
        "### Direct Usage of the Parser\n",
        "\n",
        "The automatic behavior is powered by a processor called `constrained_decoding.StructuredOutputParser`. While you typically don't need to use it directly, it can be useful if you have a stream of raw JSON from a source other than a model processor and want to parse it into typed `ProcessorPart` objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "direct_usage_code_advanced"
      },
      "outputs": [],
      "source": [
        "# The StructuredOutputParser needs to know the target type.\n",
        "json_parser = constrained_decoding.StructuredOutputParser(Movie)\n",
        "\n",
        "json_input_stream = [\n",
        "    ProcessorPart(\n",
        "        '{\"title\": \"The Matrix\", \"release_year\": 1999, \"genre\": \"Science'\n",
        "        ' Fiction\", '\n",
        "    ),\n",
        "    ProcessorPart(\n",
        "        '\"lead_actors\": [{\"name\": \"Keanu Reeves\", \"birth_year\": 1964}]}'\n",
        "    ),\n",
        "]\n",
        "\n",
        "output_parts = processor.apply_sync(json_parser, json_input_stream)\n",
        "movie_instance = output_parts[0].get_dataclass(Movie)\n",
        "\n",
        "print(f\"Successfully parsed a '{type(movie_instance).__name__}' instance:\")\n",
        "print(movie_instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "## 7. üöÄ Next Steps\n",
        "\n",
        "You've now seen how to seamlessly work with structured data in GenAI Processors. This is a key technique for building reliable and predictable AI applications.\n",
        "\n",
        "To continue your journey, explore these other notebooks:\n",
        "\n",
        "*   [**Processor Introduction**](https://colab.research.google.com/github/google/genai-processors/blob/main/notebooks/processor_intro.ipynb): Get a foundational understanding of the core concepts of the library.\n",
        "*   [**Create Your Own Processor**](https://colab.research.google.com/github/google/genai-processors/blob/main/notebooks/create_your_own_processor.ipynb): Learn how to build custom processors to create complex, multi-step AI pipelines."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
