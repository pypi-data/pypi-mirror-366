# æ•°æ®å¤„ç†ç¤ºä¾‹

æœ¬æ–‡æ¡£å±•ç¤ºäº† CryptoService çš„æ•°æ®å¤„ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ•°æ®å­˜å‚¨ã€æŸ¥è¯¢ã€åˆ†æå’Œå¯è§†åŒ–çš„å®Œæ•´å·¥ä½œæµç¨‹ã€‚

## ğŸ—„ï¸ æ•°æ®åº“å­˜å‚¨å’Œç®¡ç†

### åŸºç¡€æ•°æ®åº“æ“ä½œ

```python
import os
from pathlib import Path
from cryptoservice.data import MarketDB
from cryptoservice.services import MarketDataService
from cryptoservice.models import Freq
from dotenv import load_dotenv

load_dotenv()

# åˆå§‹åŒ–æ•°æ®åº“
db_path = "./data/market.db"
db = MarketDB(db_path)

# åˆå§‹åŒ–å¸‚åœºæ•°æ®æœåŠ¡
service = MarketDataService(
    api_key=os.getenv("BINANCE_API_KEY"),
    api_secret=os.getenv("BINANCE_API_SECRET")
)

def setup_database():
    """è®¾ç½®å’Œåˆå§‹åŒ–æ•°æ®åº“"""

    # åˆ›å»ºæ•°æ®ç›®å½•
    Path("./data").mkdir(exist_ok=True)

    # æ•°æ®åº“ä¼šè‡ªåŠ¨åˆ›å»ºè¡¨ç»“æ„
    print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    print(f"ğŸ“ æ•°æ®åº“æ–‡ä»¶: {db_path}")

    # æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
    stats = db.get_database_stats()
    print(f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡: {stats}")

setup_database()
```

### Universe æ•°æ®ä¸‹è½½å’Œå­˜å‚¨

```python
from cryptoservice.models.universe import UniverseDefinition

def download_and_store_universe_data():
    """ä¸‹è½½å¹¶å­˜å‚¨Universeæ•°æ®"""

    # å®šä¹‰Universe
    universe_def = service.define_universe(
        start_date="2024-01-01",
        end_date="2024-03-31",
        t1_months=1,
        t2_months=1,
        t3_months=3,
        top_k=10,
        output_path="./data/test_universe.json",
        description="æµ‹è¯•Universeæ•°æ®å¤„ç†"
    )

    print(f"âœ… Universeå®šä¹‰å®Œæˆ: {len(universe_def.snapshots)} ä¸ªå¿«ç…§")

    # ä¸‹è½½æ•°æ®åˆ°æ•°æ®åº“
    service.download_universe_data(
        universe_file="./data/test_universe.json",
        db_path=db_path,
        interval=Freq.h1,
        max_workers=2,
        max_retries=3
    )

    print("âœ… Universeæ•°æ®ä¸‹è½½å®Œæˆ")

    return universe_def

# universe = download_and_store_universe_data()
```

## ğŸ“Š æ•°æ®æŸ¥è¯¢å’Œåˆ†æ

### åŸºç¡€æ•°æ®æŸ¥è¯¢

```python
import pandas as pd
from datetime import datetime, timedelta

def query_market_data():
    """æŸ¥è¯¢å¸‚åœºæ•°æ®ç¤ºä¾‹"""

    # æŸ¥è¯¢ç‰¹å®šæ—¶é—´æ®µçš„æ•°æ®
    start_time = "2024-01-01"
    end_time = "2024-01-31"
    symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]

    # è¯»å–å°æ—¶çº§æ•°æ®
    df = db.read_data(
        start_time=start_time,
        end_time=end_time,
        freq=Freq.h1,
        symbols=symbols
    )

    print(f"ğŸ“Š æŸ¥è¯¢ç»“æœ: {df.shape} (è¡Œ, åˆ—)")
    print(f"ğŸ“ˆ æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")
    print(f"ğŸ’° äº¤æ˜“å¯¹: {df.columns.get_level_values('symbol').unique().tolist()}")

    # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
    print("\næ•°æ®æ¦‚è§ˆ:")
    print(df.head())

    return df

# æ‰§è¡ŒæŸ¥è¯¢
market_df = query_market_data()
```

### é«˜çº§æ•°æ®ç­›é€‰

```python
def advanced_data_filtering():
    """é«˜çº§æ•°æ®ç­›é€‰ç¤ºä¾‹"""

    # æŒ‰æ¡ä»¶ç­›é€‰æ•°æ®
    filtered_data = db.read_data_with_conditions(
        start_time="2024-01-01",
        end_time="2024-03-31",
        freq=Freq.d1,
        symbols=["BTCUSDT", "ETHUSDT"],
        conditions={
            'volume': ('>', 1000),  # æˆäº¤é‡å¤§äº1000
            'close_price': ('between', 30000, 50000)  # ä»·æ ¼åœ¨30k-50kä¹‹é—´
        }
    )

    print("ğŸ” ç­›é€‰åçš„æ•°æ®:")
    print(filtered_data.describe())

    # æŒ‰ç™¾åˆ†ä½æ•°ç­›é€‰
    high_volume_data = db.read_data_by_percentile(
        start_time="2024-01-01",
        end_time="2024-03-31",
        symbols=["BTCUSDT"],
        column="volume",
        percentile=90  # æˆäº¤é‡å‰10%çš„æ•°æ®
    )

    print(f"\nğŸ“ˆ é«˜æˆäº¤é‡æ•°æ® (å‰10%): {len(high_volume_data)} æ¡è®°å½•")

    return filtered_data, high_volume_data

# advanced_data = advanced_data_filtering()
```

## ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—

### åŸºç¡€æŠ€æœ¯æŒ‡æ ‡

```python
import numpy as np
import pandas as pd

class TechnicalIndicators:
    """æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ç±»"""

    @staticmethod
    def sma(data, window):
        """ç®€å•ç§»åŠ¨å¹³å‡çº¿"""
        return data.rolling(window=window).mean()

    @staticmethod
    def ema(data, window):
        """æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿"""
        return data.ewm(span=window).mean()

    @staticmethod
    def rsi(data, window=14):
        """ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡"""
        delta = data.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    @staticmethod
    def bollinger_bands(data, window=20, std_dev=2):
        """å¸ƒæ—å¸¦"""
        sma = data.rolling(window=window).mean()
        std = data.rolling(window=window).std()
        upper_band = sma + (std * std_dev)
        lower_band = sma - (std * std_dev)
        return sma, upper_band, lower_band

    @staticmethod
    def macd(data, fast=12, slow=26, signal=9):
        """MACDæŒ‡æ ‡"""
        ema_fast = data.ewm(span=fast).mean()
        ema_slow = data.ewm(span=slow).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal).mean()
        histogram = macd_line - signal_line
        return macd_line, signal_line, histogram

def calculate_technical_indicators():
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ç¤ºä¾‹"""

    # è·å–BTCæ•°æ®
    btc_data = db.read_data(
        start_time="2024-01-01",
        end_time="2024-03-31",
        freq=Freq.d1,
        symbols=["BTCUSDT"]
    )

    # æå–æ”¶ç›˜ä»·
    close_prices = btc_data[('close_price', 'BTCUSDT')]

    # è®¡ç®—å„ç§æŠ€æœ¯æŒ‡æ ‡
    indicators = TechnicalIndicators()

    # ç§»åŠ¨å¹³å‡çº¿
    sma_20 = indicators.sma(close_prices, 20)
    ema_20 = indicators.ema(close_prices, 20)

    # RSI
    rsi = indicators.rsi(close_prices)

    # å¸ƒæ—å¸¦
    bb_middle, bb_upper, bb_lower = indicators.bollinger_bands(close_prices)

    # MACD
    macd, signal, histogram = indicators.macd(close_prices)

    # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡DataFrame
    tech_df = pd.DataFrame({
        'close': close_prices,
        'sma_20': sma_20,
        'ema_20': ema_20,
        'rsi': rsi,
        'bb_upper': bb_upper,
        'bb_middle': bb_middle,
        'bb_lower': bb_lower,
        'macd': macd,
        'macd_signal': signal,
        'macd_histogram': histogram
    })

    print("ğŸ“Š æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ:")
    print(tech_df.tail())

    # ç”Ÿæˆäº¤æ˜“ä¿¡å·
    signals = generate_trading_signals(tech_df)

    return tech_df, signals

def generate_trading_signals(tech_df):
    """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""

    signals = pd.DataFrame(index=tech_df.index)

    # RSIä¿¡å·
    signals['rsi_overbought'] = tech_df['rsi'] > 70
    signals['rsi_oversold'] = tech_df['rsi'] < 30

    # ç§»åŠ¨å¹³å‡ä¿¡å·
    signals['golden_cross'] = (tech_df['sma_20'] > tech_df['ema_20'].shift(1)) & \
                             (tech_df['sma_20'].shift(1) <= tech_df['ema_20'].shift(1))

    # å¸ƒæ—å¸¦ä¿¡å·
    signals['bb_breakout_upper'] = tech_df['close'] > tech_df['bb_upper']
    signals['bb_breakout_lower'] = tech_df['close'] < tech_df['bb_lower']

    # MACDä¿¡å·
    signals['macd_bullish'] = (tech_df['macd'] > tech_df['macd_signal']) & \
                             (tech_df['macd'].shift(1) <= tech_df['macd_signal'].shift(1))

    print("\nğŸ“ˆ äº¤æ˜“ä¿¡å·ç»Ÿè®¡:")
    for signal in signals.columns:
        count = signals[signal].sum()
        print(f"   {signal}: {count} æ¬¡")

    return signals

# tech_data, trade_signals = calculate_technical_indicators()
```

## ğŸ“Š æ•°æ®å¯è§†åŒ–

### ä»·æ ¼å›¾è¡¨å¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.dates import DateFormatter

def create_price_charts():
    """åˆ›å»ºä»·æ ¼å›¾è¡¨"""

    # è·å–æ•°æ®
    btc_data = db.read_data(
        start_time="2024-01-01",
        end_time="2024-03-31",
        freq=Freq.d1,
        symbols=["BTCUSDT"]
    )

    # æå–OHLCVæ•°æ®
    ohlcv = pd.DataFrame({
        'open': btc_data[('open_price', 'BTCUSDT')],
        'high': btc_data[('high_price', 'BTCUSDT')],
        'low': btc_data[('low_price', 'BTCUSDT')],
        'close': btc_data[('close_price', 'BTCUSDT')],
        'volume': btc_data[('volume', 'BTCUSDT')]
    }).dropna()

    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(3, 1, figsize=(15, 12))
    fig.suptitle('BTC/USDT å¸‚åœºåˆ†æ', fontsize=16, fontweight='bold')

    # 1. ä»·æ ¼èµ°åŠ¿å›¾
    ax1 = axes[0]
    ax1.plot(ohlcv.index, ohlcv['close'], label='æ”¶ç›˜ä»·', linewidth=2, color='blue')
    ax1.fill_between(ohlcv.index, ohlcv['low'], ohlcv['high'], alpha=0.3, color='lightblue', label='ä»·æ ¼èŒƒå›´')
    ax1.set_title('ä»·æ ¼èµ°åŠ¿')
    ax1.set_ylabel('ä»·æ ¼ (USDT)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # æ·»åŠ ç§»åŠ¨å¹³å‡çº¿
    sma_20 = ohlcv['close'].rolling(20).mean()
    sma_50 = ohlcv['close'].rolling(50).mean()
    ax1.plot(ohlcv.index, sma_20, label='SMA-20', alpha=0.7, color='orange')
    ax1.plot(ohlcv.index, sma_50, label='SMA-50', alpha=0.7, color='red')
    ax1.legend()

    # 2. æˆäº¤é‡å›¾
    ax2 = axes[1]
    colors = ['green' if close >= open else 'red' for close, open in zip(ohlcv['close'], ohlcv['open'])]
    ax2.bar(ohlcv.index, ohlcv['volume'], color=colors, alpha=0.7, width=0.8)
    ax2.set_title('æˆäº¤é‡')
    ax2.set_ylabel('æˆäº¤é‡ (BTC)')
    ax2.grid(True, alpha=0.3)

    # 3. ä»·æ ¼åˆ†å¸ƒå›¾
    ax3 = axes[2]
    ax3.hist(ohlcv['close'], bins=50, alpha=0.7, color='purple', edgecolor='black')
    ax3.set_title('ä»·æ ¼åˆ†å¸ƒ')
    ax3.set_xlabel('ä»·æ ¼ (USDT)')
    ax3.set_ylabel('é¢‘æ¬¡')
    ax3.grid(True, alpha=0.3)

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    mean_price = ohlcv['close'].mean()
    median_price = ohlcv['close'].median()
    ax3.axvline(mean_price, color='red', linestyle='--', label=f'å‡å€¼: ${mean_price:.0f}')
    ax3.axvline(median_price, color='orange', linestyle='--', label=f'ä¸­ä½æ•°: ${median_price:.0f}')
    ax3.legend()

    plt.tight_layout()
    plt.show()

    return fig

# chart = create_price_charts()
```

### å¤šå¸ç§æ¯”è¾ƒåˆ†æ

```python
def multi_symbol_analysis():
    """å¤šå¸ç§æ¯”è¾ƒåˆ†æ"""

    symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT"]

    # è·å–æ•°æ®
    multi_data = db.read_data(
        start_time="2024-01-01",
        end_time="2024-03-31",
        freq=Freq.d1,
        symbols=symbols
    )

    # æå–æ”¶ç›˜ä»·
    close_prices = pd.DataFrame({
        symbol: multi_data[('close_price', symbol)]
        for symbol in symbols
    }).dropna()

    # è®¡ç®—å½’ä¸€åŒ–ä»·æ ¼ (ä»¥ç¬¬ä¸€å¤©ä¸ºåŸºå‡†)
    normalized_prices = close_prices / close_prices.iloc[0] * 100

    # è®¡ç®—æ”¶ç›Šç‡
    returns = close_prices.pct_change().dropna()

    # åˆ›å»ºæ¯”è¾ƒå›¾è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('å¤šå¸ç§æ¯”è¾ƒåˆ†æ', fontsize=16, fontweight='bold')

    # 1. å½’ä¸€åŒ–ä»·æ ¼å¯¹æ¯”
    ax1 = axes[0, 0]
    for symbol in symbols:
        ax1.plot(normalized_prices.index, normalized_prices[symbol], label=symbol, linewidth=2)
    ax1.set_title('ä»·æ ¼è¡¨ç°å¯¹æ¯” (å½’ä¸€åŒ–)')
    ax1.set_ylabel('ç›¸å¯¹ä»·æ ¼ (%)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # 2. æ³¢åŠ¨ç‡å¯¹æ¯”
    ax2 = axes[0, 1]
    volatility = returns.rolling(window=7).std() * np.sqrt(365) * 100  # å¹´åŒ–æ³¢åŠ¨ç‡
    for symbol in symbols:
        ax2.plot(volatility.index, volatility[symbol], label=symbol, alpha=0.7)
    ax2.set_title('æ³¢åŠ¨ç‡å¯¹æ¯” (7æ—¥æ»šåŠ¨)')
    ax2.set_ylabel('å¹´åŒ–æ³¢åŠ¨ç‡ (%)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # 3. æ”¶ç›Šç‡åˆ†å¸ƒ
    ax3 = axes[1, 0]
    returns.plot(kind='box', ax=ax3)
    ax3.set_title('æ”¶ç›Šç‡åˆ†å¸ƒ')
    ax3.set_ylabel('æ—¥æ”¶ç›Šç‡')
    ax3.grid(True, alpha=0.3)

    # 4. ç›¸å…³æ€§çƒ­å›¾
    ax4 = axes[1, 1]
    correlation_matrix = returns.corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0,
                square=True, ax=ax4, fmt='.3f')
    ax4.set_title('æ”¶ç›Šç‡ç›¸å…³æ€§')

    plt.tight_layout()
    plt.show()

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯æ‘˜è¦:")
    print("=" * 50)

    stats = pd.DataFrame({
        'å¹³å‡æ”¶ç›Šç‡(%)': returns.mean() * 100,
        'æ³¢åŠ¨ç‡(%)': returns.std() * 100,
        'å¤æ™®æ¯”ç‡': returns.mean() / returns.std(),
        'æœ€å¤§æ”¶ç›Šç‡(%)': returns.max() * 100,
        'æœ€å¤§äºæŸ(%)': returns.min() * 100
    })

    print(stats.round(3))

    return normalized_prices, returns, stats

# multi_analysis = multi_symbol_analysis()
```

## ğŸ’¾ æ•°æ®å¯¼å‡ºå’Œå¤‡ä»½

### å¤šæ ¼å¼æ•°æ®å¯¼å‡º

```python
def export_processed_data():
    """å¯¼å‡ºå¤„ç†åçš„æ•°æ®"""

    # åˆ›å»ºå¯¼å‡ºç›®å½•
    export_dir = Path("./data/exports")
    export_dir.mkdir(exist_ok=True)

    # è·å–æ•°æ®
    data = db.read_data(
        start_time="2024-01-01",
        end_time="2024-03-31",
        freq=Freq.d1,
        symbols=["BTCUSDT", "ETHUSDT"]
    )

    # 1. å¯¼å‡ºä¸ºCSV
    csv_file = export_dir / "market_data.csv"
    data.to_csv(csv_file)
    print(f"âœ… CSVå¯¼å‡ºå®Œæˆ: {csv_file}")

    # 2. å¯¼å‡ºä¸ºParquet (é«˜æ•ˆå‹ç¼©)
    parquet_file = export_dir / "market_data.parquet"
    data.to_parquet(parquet_file)
    print(f"âœ… Parquetå¯¼å‡ºå®Œæˆ: {parquet_file}")

    # 3. å¯¼å‡ºä¸ºExcel (å¤šå·¥ä½œè¡¨)
    excel_file = export_dir / "market_analysis.xlsx"
    with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
        # åŸå§‹æ•°æ®
        data.to_excel(writer, sheet_name='åŸå§‹æ•°æ®')

        # ç»Ÿè®¡æ‘˜è¦
        summary = data.describe()
        summary.to_excel(writer, sheet_name='ç»Ÿè®¡æ‘˜è¦')

        # æŠ€æœ¯æŒ‡æ ‡ (å¦‚æœå·²è®¡ç®—)
        if 'tech_data' in locals():
            tech_data.to_excel(writer, sheet_name='æŠ€æœ¯æŒ‡æ ‡')

    print(f"âœ… Excelå¯¼å‡ºå®Œæˆ: {excel_file}")

    # 4. å¯¼å‡ºä¸ºNumPyæ•°ç»„
    numpy_file = export_dir / "market_data.npz"

    # è½¬æ¢ä¸ºæ•°ç»„æ ¼å¼
    close_prices = data['close_price'].values
    volumes = data['volume'].values
    timestamps = data.index.values

    np.savez_compressed(
        numpy_file,
        close_prices=close_prices,
        volumes=volumes,
        timestamps=timestamps,
        symbols=data['close_price'].columns.tolist()
    )
    print(f"âœ… NumPyå¯¼å‡ºå®Œæˆ: {numpy_file}")

    # æ–‡ä»¶å¤§å°æ¯”è¾ƒ
    print("\nğŸ“ æ–‡ä»¶å¤§å°æ¯”è¾ƒ:")
    for file_path in [csv_file, parquet_file, excel_file, numpy_file]:
        size_mb = file_path.stat().st_size / (1024 * 1024)
        print(f"   {file_path.name}: {size_mb:.2f} MB")

# export_processed_data()
```

### æ•°æ®åº“å¤‡ä»½å’Œæ¢å¤

```python
import shutil
from datetime import datetime

def backup_database():
    """å¤‡ä»½æ•°æ®åº“"""

    backup_dir = Path("./data/backups")
    backup_dir.mkdir(exist_ok=True)

    # åˆ›å»ºæ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # 1. å®Œæ•´æ•°æ®åº“å¤‡ä»½
    backup_file = backup_dir / f"market_db_backup_{timestamp}.db"
    shutil.copy2(db_path, backup_file)
    print(f"âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: {backup_file}")

    # 2. å¯¼å‡ºä¸ºSQLè„šæœ¬
    sql_backup = backup_dir / f"market_db_dump_{timestamp}.sql"

    # ä½¿ç”¨SQLiteçš„.dumpå‘½ä»¤
    import sqlite3

    conn = sqlite3.connect(db_path)
    with open(sql_backup, 'w') as f:
        for line in conn.iterdump():
            f.write('%s\n' % line)
    conn.close()

    print(f"âœ… SQLè„šæœ¬å¤‡ä»½å®Œæˆ: {sql_backup}")

    # 3. å‹ç¼©å¤‡ä»½
    import zipfile

    zip_backup = backup_dir / f"market_db_archive_{timestamp}.zip"
    with zipfile.ZipFile(zip_backup, 'w', zipfile.ZIP_DEFLATED) as zipf:
        zipf.write(backup_file, backup_file.name)
        zipf.write(sql_backup, sql_backup.name)

    print(f"âœ… å‹ç¼©å¤‡ä»½å®Œæˆ: {zip_backup}")

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    backup_file.unlink()
    sql_backup.unlink()

    return zip_backup

def restore_database(backup_file):
    """æ¢å¤æ•°æ®åº“"""

    if not Path(backup_file).exists():
        print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
        return False

    try:
        # å¤‡ä»½å½“å‰æ•°æ®åº“
        current_backup = f"{db_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        shutil.copy2(db_path, current_backup)
        print(f"ğŸ“ å½“å‰æ•°æ®åº“å·²å¤‡ä»½åˆ°: {current_backup}")

        # æ¢å¤æ•°æ®åº“
        shutil.copy2(backup_file, db_path)
        print(f"âœ… æ•°æ®åº“æ¢å¤å®Œæˆ: {backup_file}")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®åº“æ¢å¤å¤±è´¥: {e}")
        return False

# æ‰§è¡Œå¤‡ä»½
# backup_file = backup_database()
```

## ğŸ”„ è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†æµæ°´çº¿

```python
import schedule
import time
from concurrent.futures import ThreadPoolExecutor

class DataProcessingPipeline:
    """è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†æµæ°´çº¿"""

    def __init__(self):
        self.db = MarketDB(db_path)
        self.service = MarketDataService(
            api_key=os.getenv("BINANCE_API_KEY"),
            api_secret=os.getenv("BINANCE_API_SECRET")
        )
        self.symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]

    def daily_data_update(self):
        """æ¯æ—¥æ•°æ®æ›´æ–°"""
        print(f"ğŸ”„ å¼€å§‹æ¯æ—¥æ•°æ®æ›´æ–° - {datetime.now()}")

        try:
            # è·å–æœ€æ–°æ•°æ®
            end_time = datetime.now()
            start_time = end_time - timedelta(days=1)

            for symbol in self.symbols:
                klines = self.service.get_historical_klines(
                    symbol=symbol,
                    start_time=start_time.strftime("%Y-%m-%d"),
                    end_time=end_time.strftime("%Y-%m-%d"),
                    interval=Freq.h1
                )

                # å­˜å‚¨åˆ°æ•°æ®åº“
                self.db.insert_klines(symbol, klines)
                print(f"âœ… {symbol} æ•°æ®æ›´æ–°å®Œæˆ: {len(klines)} æ¡è®°å½•")

            print("ğŸ‰ æ¯æ—¥æ•°æ®æ›´æ–°å®Œæˆ")

        except Exception as e:
            print(f"âŒ æ¯æ—¥æ•°æ®æ›´æ–°å¤±è´¥: {e}")

    def weekly_analysis(self):
        """æ¯å‘¨åˆ†ææŠ¥å‘Š"""
        print(f"ğŸ“Š å¼€å§‹æ¯å‘¨åˆ†æ - {datetime.now()}")

        try:
            # ç”Ÿæˆå‘¨æŠ¥
            end_time = datetime.now()
            start_time = end_time - timedelta(days=7)

            weekly_data = self.db.read_data(
                start_time=start_time.strftime("%Y-%m-%d"),
                end_time=end_time.strftime("%Y-%m-%d"),
                freq=Freq.d1,
                symbols=self.symbols
            )

            # è®¡ç®—å‘¨åº¦ç»Ÿè®¡
            weekly_stats = {}
            for symbol in self.symbols:
                close_prices = weekly_data[('close_price', symbol)]
                weekly_stats[symbol] = {
                    'return': (close_prices.iloc[-1] / close_prices.iloc[0] - 1) * 100,
                    'volatility': close_prices.pct_change().std() * 100,
                    'max_price': close_prices.max(),
                    'min_price': close_prices.min()
                }

            # ç”ŸæˆæŠ¥å‘Š
            report_file = f"./data/reports/weekly_report_{end_time.strftime('%Y%m%d')}.txt"
            Path("./data/reports").mkdir(exist_ok=True)

            with open(report_file, 'w') as f:
                f.write(f"åŠ å¯†è´§å¸å‘¨åº¦åˆ†ææŠ¥å‘Š\n")
                f.write(f"æŠ¥å‘Šæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 50 + "\n\n")

                for symbol, stats in weekly_stats.items():
                    f.write(f"{symbol}:\n")
                    f.write(f"  å‘¨åº¦æ”¶ç›Šç‡: {stats['return']:.2f}%\n")
                    f.write(f"  æ³¢åŠ¨ç‡: {stats['volatility']:.2f}%\n")
                    f.write(f"  æœ€é«˜ä»·: ${stats['max_price']:.2f}\n")
                    f.write(f"  æœ€ä½ä»·: ${stats['min_price']:.2f}\n\n")

            print(f"âœ… å‘¨åº¦æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_file}")

        except Exception as e:
            print(f"âŒ å‘¨åº¦åˆ†æå¤±è´¥: {e}")

    def monthly_backup(self):
        """æ¯æœˆæ•°æ®å¤‡ä»½"""
        print(f"ğŸ’¾ å¼€å§‹æ¯æœˆå¤‡ä»½ - {datetime.now()}")

        try:
            backup_file = backup_database()
            print(f"âœ… æœˆåº¦å¤‡ä»½å®Œæˆ: {backup_file}")

        except Exception as e:
            print(f"âŒ æœˆåº¦å¤‡ä»½å¤±è´¥: {e}")

    def setup_schedule(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""

        # æ¯æ—¥å‡Œæ™¨2ç‚¹æ›´æ–°æ•°æ®
        schedule.every().day.at("02:00").do(self.daily_data_update)

        # æ¯å‘¨ä¸€æ—©ä¸Š8ç‚¹ç”Ÿæˆå‘¨æŠ¥
        schedule.every().monday.at("08:00").do(self.weekly_analysis)

        # æ¯æœˆ1å·å‡Œæ™¨3ç‚¹å¤‡ä»½æ•°æ®
        schedule.every().month.do(self.monthly_backup)

        print("â° å®šæ—¶ä»»åŠ¡è®¾ç½®å®Œæˆ:")
        print("   - æ¯æ—¥ 02:00: æ•°æ®æ›´æ–°")
        print("   - æ¯å‘¨ä¸€ 08:00: å‘¨åº¦åˆ†æ")
        print("   - æ¯æœˆ1å· 03:00: æ•°æ®å¤‡ä»½")

    def run_forever(self):
        """è¿è¡Œå®šæ—¶ä»»åŠ¡"""
        self.setup_schedule()

        print("ğŸš€ æ•°æ®å¤„ç†æµæ°´çº¿å¯åŠ¨...")
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

# ä½¿ç”¨ç¤ºä¾‹
def run_data_pipeline():
    pipeline = DataProcessingPipeline()

    # æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡æ›´æ–°
    pipeline.daily_data_update()

    # æˆ–è€…å¯åŠ¨å®šæ—¶ä»»åŠ¡
    # pipeline.run_forever()

# run_data_pipeline()
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [åŸºç¡€ä½¿ç”¨ç¤ºä¾‹](basic.md) - åŸºç¡€åŠŸèƒ½æ¼”ç¤º
- [å¸‚åœºæ•°æ®ç¤ºä¾‹](market_data.md) - å®æ—¶æ•°æ®å¤„ç†
- [æ•°æ®å­˜å‚¨æŒ‡å—](../guides/data-processing/storage.md) - å­˜å‚¨æ¶æ„è¯¦è§£
- [æ•°æ®åº“æ“ä½œ](../guides/data-processing/database.md) - æ•°æ®åº“ç®¡ç†
- [MarketDB API](../api/data/storage_db.md) - å­˜å‚¨APIå‚è€ƒ

---

ğŸ’¡ **æç¤º**:
- å®šæœŸå¤‡ä»½é‡è¦æ•°æ®
- å¤§æ•°æ®é‡å¤„ç†æ—¶æ³¨æ„å†…å­˜ä½¿ç”¨
- ä½¿ç”¨é€‚å½“çš„æ•°æ®æ ¼å¼å¯æé«˜å¤„ç†æ•ˆç‡
- å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å®ç°é”™è¯¯ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶
