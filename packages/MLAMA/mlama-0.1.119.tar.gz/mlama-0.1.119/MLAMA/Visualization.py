# -*- coding: utf-8 -*-
"""Visualization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fdbWbsZgYTqDMrbVlC0MVfjGy8HRutCm
"""

from pandas import read_csv
from pandas import DataFrame
from pandas import concat
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import datetime

import matplotlib.dates as mdates
import matplotlib.colors as mcolors

import matplotlib.ticker as ticker

from .Predictions import individual_model_weekly_count, individual_model_weekly_MAPE
from .Processor import process_metrics_df, find_model_week_values_sum_shift, extract_wave_id, safe_to_datetime, extract_predictions_from_dict

#MLAMA Package 2025 Data.ipynb

#visualization updated

def plot_weekly_predictions(
    weekly_prediction_future,
    prediction_week,
    prediction_length,
    models,
    shift_type='Responsiveness',
    model_colors=None
):
    """
    Plots model predictions (ARIMA, MLAMA, others) as points connected by lines for a specific prediction week
    and prediction length. X-axis is future Week dates, and Shift is inferred from data.

    Parameters:
        weekly_prediction_future (dict): Dictionary containing weekly predictions.
        prediction_week (str): The base week from which the prediction was made (i.e., CurrentWeek).
        prediction_length (float or int): The prediction length to filter.
        models (dict): Dictionary mapping model names to their implementations.
        shift_type (str): Label used in the plot title.
        model_colors (dict): Optional dictionary mapping model names to colors.
    """
    import matplotlib.pyplot as plt
    import pandas as pd

    # Extract all predictions into one DataFrame
    df_all = extract_predictions_from_dict(weekly_prediction_future, target_length=prediction_length, models=models)

    # Filter rows for the specified prediction_week and prediction_length
    df_filtered = df_all[
        (df_all['CurrentWeek'] == prediction_week) &
        (df_all['Length'] == prediction_length)
    ]

    if df_filtered.empty:
        print(f"No data found for prediction_week = {prediction_week} and length = {prediction_length}")
        return

    # Sort by prediction target date (Week)
    df_filtered['Week'] = pd.to_datetime(df_filtered['Week'])
    df_filtered = df_filtered.sort_values('Week')

    # Get the unique shift value (used for labeling)
    shift_val = df_filtered['Shift'].unique()
    shift_val = shift_val[0] if len(shift_val) == 1 else str(shift_val)

    # Plot
    plt.figure(figsize=(12, 6))
    x = df_filtered['Week']

    required_models = ['Observed', 'ARIMA', 'MLAMA']
    optional_models = list(models.keys())
    all_models = list(dict.fromkeys(required_models + optional_models))  # Preserve order and uniqueness

    for model in all_models:
        if model in df_filtered.columns:
            y = df_filtered[model].values
            color = model_colors.get(model) if model_colors and model in model_colors else None

            # Draw lines connecting the predictions
            plt.plot(x, y, linestyle='-', linewidth=1.5, color=color, alpha=0.7, zorder=1)

            # Overlay scatter points
            if model.upper() == 'MLAMA':
                plt.scatter(x, y, s=100, c=color, marker='*', label=model, zorder=5, edgecolors='black', linewidths=1.5)
            else:
                plt.scatter(x, y, s=60, c=color, marker='o', label=model)

    plt.xlabel("Prediction Target Date (Week)")
    plt.ylabel("Predicted Value")
    plt.title(f"Predictions from Week = {prediction_week}, Length = {prediction_length}, Shift ({shift_type}) = {shift_val}")
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()



def plot_weekly_predictions_all_weeks(weekly_prediction_future, models, shift, length, shift_type='Responsiveness', model_colors=None):
    """
    Plots the latest weekly predictions (per CurrentWeek) from different models for a specified shift and prediction length.

    Parameters:
        weekly_prediction_future (dict): Dictionary containing weekly predictions.
        models (dict): Dictionary mapping model names to their implementations.
        shift (int): The shift value to filter the data.
        length (float): The prediction length value to filter the data.
        shift_type (str): Label used in the plot title.
        model_colors (dict): Optional dictionary mapping model names to colors.
    """
    # Extract predictions
    df = extract_predictions_from_dict(weekly_prediction_future, target_length=length, models=models)
    print(df)
    # Filter by shift and length
    df = df[(df['Shift'] == shift) & (df['Length'] == length)]
    if df.empty:
        print(f"No data found for Shift={shift} and Length={length}")
        return

    # Ensure datetime format for proper sorting
    df['CurrentWeek'] = pd.to_datetime(df['CurrentWeek'])
    df['Week'] = pd.to_datetime(df['Week'])

    # For each CurrentWeek, keep the row with the latest Week, to ensure predcition length
    df = df.sort_values(['CurrentWeek', 'Week'])
    df = df.groupby('CurrentWeek', as_index=False).last()
    #print(df)
    # Plotting
    plt.figure(figsize=(12, 6))
    x = df['CurrentWeek']

    # Determine all model names to plot
    required_models = ['Observed', 'ARIMA', 'MLAMA']
    optional_models = list(models.keys())
    all_models = list(dict.fromkeys(required_models + optional_models))  # preserve order

    for model in all_models:
        if model in df:
            plot_kwargs = {
                'marker': 'o',
                'label': model,
            }

            if model_colors and model in model_colors:
                plot_kwargs['color'] = model_colors[model]

            if model.upper() == 'MLAMA':
                plot_kwargs['linewidth'] = 4
                plot_kwargs['zorder'] = 2
                plot_kwargs['alpha'] = 0.9  # partial transparency for overlap visibility
            else:
                plot_kwargs['zorder'] = 3  # ensure others are beneath MLAMA

            plt.plot(x, df[model], **plot_kwargs)



    plt.xlabel("Week")
    plt.ylabel("Predicted Value")
    plt.title(f"Weekly Predictions for {shift_type} Shift = {shift}, Length = {length}")
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()


#Visualization.py
# Purpose:
# Show how different shift values affect training and test segmentation for a particular wave and all shift values.
#Demonstrates temporal shifts in training start/end and test set start (end depends on prediction length) for the specific shift value, each prediction length
# Visualization:
def visualize_wave_train_test_with_shift_PL(data_dict, waveID):
    """
    Plots time interval ranges for wave-shift combinations that match the given waveID.

    Args:
        data_dict (dict): A dictionary with wave-shift combination keys and 'all', 'train', and 'test' DataFrames.
        waveID (int): The integer wave ID to filter for (e.g., 1, 2, or 3).
    """
    fig, ax = plt.subplots(figsize=(14, 8))
    ax.set_title(f"Time Interval Comparison for Wave {waveID} (All Shifts)", fontsize=16, pad=20)
    ax.set_xlabel("Date", fontsize=14, labelpad=20)

    ax.xaxis.set_label_coords(0.5, -0.25)  # Move x-axis label downward
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%D'))
    ax.set_ylabel("Wave-shift Combinations", fontsize=14)
    ax.yaxis.set_label_coords(-0.25, 0.5)  # Push label farther left
    plt.subplots_adjust(left=0.18, right=0.98, top=0.92, bottom=0.2)  # Make space for the label

    y_offset = 1
    spacing = 2

    for wave_name, intervals in data_dict.items():
        if extract_wave_id(wave_name) != waveID:
            continue  # Skip non-matching wave IDs

        all_range = [safe_to_datetime(i) for i in intervals['all'].index]
        train_range = [safe_to_datetime(i) for i in intervals['train'].index]
        test_range = [safe_to_datetime(i) for i in intervals['test'].index]

        shift = intervals['shift']
        max_prediction_length = intervals['max_prediction_length']

        for prediction_length in range(1, max_prediction_length+1):
            plot_wave_train_test_shift_PL(
                all_range,
                train_range,
                test_range,
                shift,
                prediction_length,
                y_offset,
                wave_name + '_prediction_length' + str(prediction_length),
                plot_shift_as_dots=True
            )
            y_offset += spacing

    if y_offset == 1:
        print(f"No data found for wave {waveID}.")
        return

    ax.set_ylim(0, y_offset)
    ax.set_yticks([])
    ax.tick_params(axis='x', labelrotation=45, labelsize=12)

    # Move legend outside plot area but above x-axis
    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12),
              fontsize=12, ncol=3, frameon=False)

    # Adjust layout manually to avoid cutting off legend/y-label
    plt.subplots_adjust(left=0.12, right=0.98, top=0.92, bottom=0.2)

    plt.show()


def plot_wave_train_test_shift_PL(all_range, train_range, test_range,
                                   shift, prediction_length, y_offset,
                                   wave_name, plot_shift_as_dots=True,
                                   segment_gap_minutes=None,
                                   show_ylabel=False):
    """
    Plots a segmented timeline for a forecasting wave, visualizing the full data range,
    training segment (including shifted extension), and test data.

    Parameters:
        all_range (list of datetime): The complete timeline of the dataset.
        train_range (list of datetime): The datetime values used for training.
        test_range (list of datetime): The datetime values used for testing.
        shift (int): Number of points added at the end of training as shifted/extended data.
        prediction_length (int): Number of time points used for prediction within test_range.
        y_offset (float): Vertical offset for plotting the current wave (to avoid overlap).
        wave_name (str): Identifier label for the wave (used in y-axis labeling).
        plot_shift_as_dots (bool, optional): If True, plots shifted training and test prediction points as dots.
                                             If False, uses horizontal segments. Default is True.
        segment_gap_minutes (float, optional): Estimated time gap in minutes between data points
                                               for drawing segments. If None, it is inferred automatically.
        show_ylabel (bool, optional): If True, displays wave name as y-axis label on the left.

    Notes:
        - Displays training data in blue, with optional distinction for shifted extension.
        - Displays test prediction data in orange and any remaining test data in gray.
        - Supports both dot and segment plotting styles.
    """

    # Plot full timeline (gray line)
    plt.hlines(y=y_offset, xmin=all_range[0], xmax=all_range[-1], color='gray',
               label='Full Range' if y_offset == 1 else "", linewidth=2, alpha=0.7)

    train_len = len(train_range)
    test_len = len(test_range)

    # === Train Line (Blue) ===
    if shift == 0 or train_len <= shift:
        plt.hlines(y=y_offset + 0.5, xmin=train_range[0], xmax=train_range[-1],
                   color='blue', label='Train' if y_offset == 1 else "", linewidth=2)
    else:
        main_end = train_range[train_len - shift - 1]
        plt.hlines(y=y_offset + 0.5, xmin=train_range[0], xmax=main_end,
                   color='blue', label='Train (Main)' if y_offset == 1 else "", linewidth=2)

        final_points = train_range[train_len - shift:]
        if plot_shift_as_dots:
            plt.scatter(final_points, [y_offset + 0.5] * shift,
                        color='blue', edgecolor='black', s=40,
                        label='Train (Extension)' if y_offset == 1 else "")
        else:
            if segment_gap_minutes is None:
                if len(train_range) >= 2:
                    deltas = np.diff([dt.timestamp() for dt in train_range])
                    segment_gap_minutes = np.median(deltas) / (60 * 10)
                else:
                    segment_gap_minutes = 10080 / 10
            gap = datetime.timedelta(minutes=segment_gap_minutes)

            for i in range(shift):
                start = final_points[i]
                if i < shift - 1:
                    end = final_points[i + 1] - gap
                else:
                    end = start + gap
                if end > start:
                    plt.hlines(y=y_offset + 0.5, xmin=start, xmax=end,
                               color='blue', linewidth=2,
                               label='Train (Extension)' if (i == 0 and y_offset == 1) else "")

    # === Test Line (Orange and Gray) ===
    if test_len > 0:
        if plot_shift_as_dots:
            orange_points = test_range[:prediction_length]
            gray_points = test_range[prediction_length:] if prediction_length < test_len else []

            if orange_points:
                plt.scatter(orange_points, [y_offset + 1] * len(orange_points),
                            color='orange', edgecolor='black', s=40,
                            label='Test (Pred)' if y_offset == 1 else "")
            if gray_points:
                plt.scatter(gray_points, [y_offset + 1] * len(gray_points),
                            color='gray', edgecolor='black', s=40,
                            label='Test (Remaining)' if y_offset == 1 else "")
        else:
            if segment_gap_minutes is None:
                if len(test_range) >= 2:
                    deltas = np.diff([dt.timestamp() for dt in test_range])
                    segment_gap_minutes = np.median(deltas) / (60 * 10)
                else:
                    segment_gap_minutes = 10080 / 10
            gap = datetime.timedelta(minutes=segment_gap_minutes)

            for i in range(min(prediction_length, test_len)):
                start = test_range[i]
                if i < test_len - 1:
                    end = test_range[i + 1] - gap
                else:
                    end = start + gap
                if i < prediction_length:
                    color = 'orange'
                    label = 'Test (Pred)' if i == 0 and y_offset == 1 else ''
                else:
                    color = 'gray'
                    label = 'Test (Remaining)' if i == prediction_length and y_offset == 1 else ''
                if end > start:
                    plt.hlines(y=y_offset + 1, xmin=start, xmax=end,
                               color=color, linewidth=2, label=label)

    # === Endpoint Markers ===
    plt.scatter([all_range[0], all_range[-1]], [y_offset, y_offset],
                color='gray', edgecolor='black', s=40, label='_nolegend_')
    plt.scatter([train_range[0], train_range[-1]], [y_offset + 0.5, y_offset + 0.5],
                color='blue', edgecolor='black', s=40, label='_nolegend_')

    # === Add left-side prediction length labels ===
    if show_ylabel:
        x_left = all_range[0] - datetime.timedelta(days=20)
        plt.text(x_left, y_offset + 0.5, wave_name, fontsize=11, ha='right', va='center')


# Purpose:
# Show how different shift values affect training and test segmentation for a particular wave and all shift values.
#Demonstrates temporal shifts in training start/end and test set start (end depends on prediction length) for the specific shift value, each prediction length
# each subplot represents one specific shift for the specific waveID
# same as visualize_wave_train_test_with_shift_PL, different presentation.
def plot_train_test_by_shifts_prediction_lengths_for_wave_horizontal(data_dict, waveID):
    """
    Plots subplots for each shift of a given waveID, stacking varying prediction lengths vertically per subplot. Horizontally side by side each shifts.
    """
    import matplotlib.pyplot as plt

    shifts = sorted([
        intervals['shift']
        for wave_name, intervals in data_dict.items()
        if extract_wave_id(wave_name) == waveID
    ])

    if not shifts:
        print(f"No data found for wave {waveID}.")
        return

    n_shifts = len(shifts)
    fig, axes = plt.subplots(nrows=1, ncols=n_shifts, figsize=(6 * n_shifts, 8), sharey=True)

    if n_shifts == 1:
        axes = [axes]

    for i, shift in enumerate(shifts):
        ax = axes[i]
        plt.sca(ax)

        ax.set_title(f"Shift {shift}", fontsize=14, pad=10)
        ax.set_xlabel("Date", fontsize=12)

        if i == 0:
            ax.set_ylabel("Prediction Length (PL)", fontsize=12, labelpad=60)  # Shifted left
        else:
            ax.set_yticks([])
            ax.set_ylabel("")

        y_offset = 1
        spacing = 2

        for wave_name, intervals in data_dict.items():
            if extract_wave_id(wave_name) != waveID or intervals['shift'] != shift:
                continue

            all_range = [safe_to_datetime(i) for i in intervals['all'].index]
            train_range = [safe_to_datetime(i) for i in intervals['train'].index]
            test_range = [safe_to_datetime(i) for i in intervals['test'].index]
            max_prediction_length = intervals.get('max_prediction_length', 1)

            for prediction_length in range(1, max_prediction_length + 1):
                label = f"PL: {prediction_length}"
                plot_wave_train_test_shift_PL(
                    all_range,
                    train_range,
                    test_range,
                    shift,
                    prediction_length,
                    y_offset,
                    label,
                    plot_shift_as_dots=True,
                    show_ylabel=(i == 0)
                )
                y_offset += spacing

        ax.tick_params(axis='x', rotation=45)
        ax.set_ylim(0, y_offset + 1)

    handles, labels = axes[0].get_legend_handles_labels()
    plt.tight_layout(rect=[0, 0, 1, 0.92])
    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.98), ncol=3, frameon=False)
    fig.suptitle(f"Wave {waveID} – Train/Test Visualization for All Shifts", fontsize=16, y=1.02)

    plt.show()


def plot_time_series_cv_splits(tscv, dates, data_name='Time Series'):
    """
    Plot the train/test date ranges for each cross-validation split using a TimeSeriesSplit object.

    Parameters:
        tscv: instance of TimeSeriesSplit
            A fitted or configured time series cross-validator.

        dates: list or array-like of datetime
            Array of datetime objects corresponding to the time series indices.

        data_name: str
            Label for the dataset being plotted (for plot title).
    """
    fig, ax = plt.subplots(figsize=(12, tscv.n_splits * 1.2))

    for i, (train_idx, test_idx) in enumerate(tscv.split(dates)):
        # Convert indices to dates
        train_dates = [dates[j] for j in train_idx]
        test_dates = [dates[j] for j in test_idx]

        # Plot training range
        ax.plot(train_dates, [i] * len(train_dates), color='blue', label='Train' if i == 0 else "")
        # Annotate train size
        ax.text(train_dates[len(train_dates)//2], i + 0.1, f'Train={len(train_dates)}', color='blue', ha='center', fontsize=9)

        # Plot test range
        ax.plot(test_dates, [i] * len(test_dates), color='orange', label='Test' if i == 0 else "")
        # Annotate test size
        ax.text(test_dates[len(test_dates)//2], i + 0.1, f'Test={len(test_dates)}', color='orange', ha='center', fontsize=9)

    # Formatting
    ax.set_title(f'{data_name} Cross-Validation Splits', fontsize=14)
    ax.set_xlabel('Date')
    ax.set_ylabel('CV Split Index')

    # Integer y-axis
    ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))

    # Legend placement outside the plot area
    ax.legend(loc='upper left', bbox_to_anchor=(1.01, 1.0), borderaxespad=0.)

    # Grid and date formatting
    ax.grid(True, linestyle='--', alpha=0.5)
    ax.xaxis.set_major_locator(mdates.AutoDateLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%D'))
    fig.autofmt_xdate()

    plt.tight_layout()
    plt.show()


# Purpose:
# Show how cross-validation is performed on a specific (wave, shift) pair using custom TimeSeriesSplit.
# This explains how hyperparameters are tuned only using training folds and validated over CV-split sets.

# Visualization:

# Overlaying line segments of train/test indices per CV fold on a timeline.

# Label fold numbers, train and test (validation) size for the crossvalidation data.

# Use color coding: e.g., blue for train, orange for validation.

# to do: remove the space/ gap between train and test
# Unable to do: (gap is going to be there as test starts next week of train ends)

def visualize_wave_shift_cross_validation(data_dict, waveID, shift_value, cv):
  n_splits = cv.n_splits
  test_size = cv.test_size
  for wave_name, intervals in data_dict.items():
        if extract_wave_id(wave_name) != waveID:
            continue
        if intervals['shift'] != shift_value:
            continue

        # all_range = [safe_to_datetime(i) for i in intervals['all'].index]
        train_range = [safe_to_datetime(i) for i in intervals['train'].index]
        #print('train size', len(train_range))
        # test_range = [safe_to_datetime(i) for i in intervals['test'].index]
        # max_prediction_length = intervals.get('max_prediction_length', 1)

        plot_time_series_cv_splits(cv, train_range, data_name = f'Wave {waveID} Shift (Responsiveness) {shift_value}')

#from MLAMA Package 2025 Data.ipynb
# Purpose:
# Provide the user with an overview of the split of the entire dataset, including the time coverage of each wave's data.
# This contextualizes the temporal partitioning and demonstrates if each wave has sufficient data for splitting and model evaluation.

# Visualization:

# Line plots or segment bars showing full data spans for each wave.

# to do: Add vertical color bands for train/test separation (optional). not done yet


def describe_and_plot_waves(waves, xtick_frequency=1):
    """
    Summarizes and visualizes the train/test periods of each wave.

    Args:
        waves (list of Wave): List of Wave objects returned by `split_data_into_waves`.
        xtick_frequency (int): Frequency of x-ticks to display (e.g., every 2nd, 4th date).
    """
    print(f"\nTotal Waves: {len(waves)}")
    print("-" * 60)

    k = len(waves)
    for wave in waves:
        train_len = len(wave.df.loc[wave.trainStartDate : wave.trainEndDate])
        test_len = len(wave.df.loc[wave.testStartDate : wave.testEndDate])
        print(f"Wave {wave.waveID}:")
        print(f"  Train: {wave.trainStartDate} to {wave.trainEndDate} ({train_len} records)")
        print(f"  Test : {wave.testStartDate} to {wave.testEndDate} ({test_len} records)")
        print(f"  Full : {wave.startDate} to {wave.endDate}")
        print("-" * 60)

    # --- Plot ---
    plt.figure(figsize=(12, 6))

    # Dummy lines for unified legend
    plt.plot([], [], color='tab:blue', lw=4, label='Train')
    plt.plot([], [], color='tab:orange', lw=4, label='Test')

    for wave in waves:
        wave_id = wave.waveID

        train_idx = wave.df.loc[wave.trainStartDate:wave.trainEndDate].index
        test_idx = wave.df.loc[wave.testStartDate:wave.testEndDate].index

        # Plot training
        plt.plot(train_idx,
                 [wave_id] * len(train_idx),
                 color='tab:blue', lw=4)

        # Plot testing
        plt.plot(test_idx,
                 [wave_id] * len(test_idx),
                 color='tab:orange', lw=4)

    # Collect all unique dates from all waves
    all_dates = pd.Index([])
    for wave in waves:
        all_dates = all_dates.union(wave.df.index)
    all_dates = all_dates.sort_values().unique()
    xticks = all_dates[::xtick_frequency]
    plt.xticks(ticks=xticks, rotation=45)

    plt.xlabel("Date")
    plt.ylabel("Wave ID")
    plt.yticks(range(1, len(waves) + 1))  # Set integer y-ticks
    plt.title(f"Train/Test Splits {k} Across Waves")
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0), fontsize='small')
    plt.tight_layout()
    plt.show()



#generalized version updated!
#visualization
def visualize_weekly_case_count_all_model_each_wave(WAVES, predictions, trend_adjustment_steps, wave_start_shift_matrix, model_evaluation_dictionary, recent_week_count, models):
    """
    Visualizes weekly case counts and model predictions (e.g., ARIMA, ML models) for each wave using a grid of subplots.

    For each wave and each trend adjustment shift, this function:
    - Aligns observed weekly case counts and predictions.
    - Displays predictions from all specified models across different prediction lengths.
    - Ensures consistent y-axis across subplots based on global value percentiles.
    - Shows trend change and prediction boundary lines for interpretability.

    Parameters:
        WAVES (list): List of Wave objects, each representing a distinct forecasting wave.
        predictions (list of int): List of prediction lengths (in weeks) to be visualized.
        trend_adjustment_steps (list of int): List of shift amounts (in weeks) representing forecast re-training points.
        wave_start_shift_matrix (dict): Dictionary mapping wave ID and shift value to a DataFrame of weekly case data.
        model_evaluation_dictionary (dict): Nested dictionary containing model outputs (predictions, weeks, observed values) for each wave, shift, and prediction length.
        recent_week_count (int): Number of most recent weeks to visualize per wave.
        models (dict): Dictionary of model names and their corresponding initialized model classes or instances.

    Notes:
        - The function uses `individual_model_weekly_count()` to preprocess model outputs for plotting.
        - Uses 98th percentile of all observed and predicted values to set consistent y-axis limits.
        - Dynamically generates and displays a matplotlib grid for each wave, including scatter and line plots.
        - Designed for exploratory data analysis and model comparison.
    """

    # Generate per-model metrics (A_dict, B_dict, etc.)
    model_dicts = individual_model_weekly_count(WAVES, predictions, trend_adjustment_steps, model_evaluation_dictionary, models, recent_week_count)
    # print(model_dicts)
    #model_dicts = {}
    #for model_name in models.keys():
        #model_dicts[model_name] = model_results[model_name]

    max_x_tick = 25  # Maximum number of x-tick labels

    for WAVE in WAVES:
        waveID = WAVE.waveID
        #print("Wave: ", waveID)

        fig = plt.figure(figsize=(25, 25))
        gs = fig.add_gridspec(len(predictions) + 1, len(trend_adjustment_steps), hspace=0.2, wspace=0.2)

        #time = WAVE.get_wave_df().tail(recent_week_count).reset_index(drop=False)
        # Determine global min and max for y-axis across all shifts and predictions
        all_weekcase_values = []
        all_prediction_values = []

        for shift in trend_adjustment_steps:
            from_date, to_date = WAVE.get_wave_test_start_date_with_shift(shift)
            shifted_wave, _, _ = WAVE.get_wave_dates_with_shift(shift, wave_start_shift_matrix)
            time = shifted_wave.tail(recent_week_count).reset_index(drop=False)
            all_weekcase_values.extend(time['weekcase'].tolist())
            for prediction_length in predictions:
              for model_name, model_data in model_dicts.items():
                    wave_model_data = model_data[waveID][shift]
                    column_name = f"{model_name}_{prediction_length}"
                    if column_name in wave_model_data.columns:
                        all_prediction_values.extend(wave_model_data[column_name].tolist())


        # Combine all values for percentile calculation
        all_values = np.array(all_weekcase_values + all_prediction_values)

        all_values = all_values[np.isfinite(all_values)]  # Keep only finite values

        # Check if all_values is empty, and provide a default max_y if needed
        if len(all_values) > 0:
            upper_limit = np.percentile(all_values, 98)  # Use 98th percentile to avoid extreme outliers
            max_y = max(upper_limit, max(all_weekcase_values, default=0)) * 1.2  # Add 20% margin for better visualization
        else:
            max_y = 1  # Default small value to avoid NaN/Inf error

        # Set the minimum y-limit
        min_y = 0  # Weekly case count can't be negative

        # Find global min and max y-values
        # min_y = 0  # Assuming weekly case count can't be negative
        # max_y = max(all_weekcase_values) * 1.2  # Adding 20% margin for better visibility
        #max_y = max(max(all_weekcase_values, default=0), max(all_prediction_values, default=0)) * 1.1  # Adding 10% margin for better visibility


        shift0 = trend_adjustment_steps[0]
        trend_change_date, _ = WAVE.get_wave_test_start_date_with_shift(shift0)
        d = datetime.datetime.strptime(trend_change_date,"%Y-%m-%d")
        w = datetime.timedelta(weeks=1)
        s = d-w
        trend_change_date = s.strftime("%Y-%m-%d")

        shifted_wave, _, _ = WAVE.get_wave_dates_with_shift(shift0, wave_start_shift_matrix)
        time0 = shifted_wave.tail(recent_week_count).reset_index(drop=False)
        # print(time0)
        for shift in trend_adjustment_steps:
            from_date, to_date = WAVE.get_wave_test_start_date_with_shift(shift)
            shifted_wave, _, _ = WAVE.get_wave_dates_with_shift(shift, wave_start_shift_matrix)
            time = shifted_wave.tail(recent_week_count).reset_index(drop=False)
            all_weekcase_values.extend(time['weekcase'].tolist())
            additional_time_in_time0 = time0[~time0['week'].isin(time['week'])]

            # print(f"Additional time points in shift 0 at the start for shift {shift}:\n", additional_time_in_time0)

            print("Wave: ", waveID, "Shift: ", shift, 'from: ', from_date, to_date)#updated time here, to get correct x_axis
            for prediction_length in predictions:
                ax = fig.add_subplot(gs[prediction_length, shift])
                plt.subplots_adjust(left=0.04, right=0.9, top=0.9, bottom=0.01)
                ax.set_ylim(min_y, max_y)  # Ensure consistent y-axis across all subplots


                # Scatter plot for observed weekly cases

                # Concatenate additional_time_in_time0 at the front of time
                time_extended = pd.concat([additional_time_in_time0, time], ignore_index=True)
                # Sort by 'week' to maintain chronological order
                time_extended = time_extended.sort_values(by='week').reset_index(drop=True)

                # Now plot
                ax.scatter(time_extended['week'], time_extended['weekcase'], color='black', label='Observed', zorder=3)
                #ax.scatter(time['week'], time['weekcase'], color='black', label='Observed', zorder=3)

                # Customize Axes
                #ax.axvline(x=from_date, color='grey', linestyle="--")
                ax.axvline(x=trend_change_date, color='grey', linestyle="-")
                ax.axvline(x=to_date, color='grey', linestyle="--")

                # Plot each model's predictions dynamically

                for model_name, model_data in model_dicts.items():
                    wave_model_data = model_data[waveID][shift]

                    #print(f"{model_name}: {wave_model_data}")
                    column_name = f"{model_name}_{prediction_length}"

                    if column_name in wave_model_data.columns:
                        ax.plot(wave_model_data[column_name].dropna(), label=model_name, linewidth=2)


                if shift == 0:
                    plt.ylabel(f"Prediction Length = {prediction_length} Week")
                if prediction_length == 1:
                    ax.set_title(f"Shift = {shift} Week")
                if prediction_length == 6:
                    ax.tick_params(axis='x', labelrotation=90)
                else:
                    ax.set_xticklabels([])
                    ax.set_xticks([])

        ax.legend(bbox_to_anchor=(-0.5, -0.5), ncol=4, fontsize=20)
        fig.text(0, 0.5, f'Weekly Case Count, Wave = {waveID}', va='center', rotation='vertical', fontsize="20")
        plt.show()



#generalized

from matplotlib.colors import ListedColormap
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

def visualize_weekly_MAPE_all_model_each_wave(WAVES, predictions, trend_adjustment_steps, model_evaluation_dictionary, recent_week_count, models):
    """
    Generalized function to visualize weekly MAPE for multiple models across waves.

    Parameters:
        WAVES: List of wave objects containing wave IDs.
        predictions: Model predictions.
        trend_adjustment_steps: List of shifts for predictions.
        model_evaluation_dictionary: Dictionary of evaluation results.
        recent_week_count: Number of recent weeks to consider.
        models: Dictionary of models to visualize with their keys and associated methods (e.g., {'ARIMA': SARIMAX, 'RF': RandomForestRegressor}).
    """
    model_results_wave_collection = individual_model_weekly_MAPE(WAVES, predictions, trend_adjustment_steps, model_evaluation_dictionary, models)
    mape_wave_shift = {}
    # print('individual_model_weekly_MAPE DONE')
    for WAVE in WAVES:  # Iterate over each wave
        waveID = WAVE.waveID
        fig, axes = plt.subplots(len(models), len(trend_adjustment_steps), sharex=True, sharey=True, figsize=(25, 10))
        gs = fig.add_gridspec(len(models), len(trend_adjustment_steps), hspace=0.2, wspace=0.2)
        plt.subplots_adjust(left=0.08, right=0.9, top=0.9, bottom=0.1)

        for model_index, (model_name, model_class) in enumerate(models.items()):  # Dynamically iterate over models
            model_results_collection = model_results_wave_collection[model_name][waveID]

            for shift in trend_adjustment_steps:  # Iterate over shifts
                ax = axes[model_index, shift]
                mape_shift = pd.DataFrame()
                weeks = [x - 1 for x in predictions]
                #print('model_results_collection', model_results_collection)
                # Retrieve and plot model results
                all_week_list, values_list = find_model_week_values_sum_shift(model_results_collection, shift, weeks)
                values_df = pd.DataFrame(values_list)
                values_df.columns = [model_name]
                #print('okk')
                # Bar and line plot
                all_week_list.plot(
                    kind='bar',
                    stacked=False,
                    width=1,
                    colormap=ListedColormap(sns.color_palette("muted", 10)),
                    figsize=(13, 15),
                    ax=ax
                )
                #ax.plot(values_list, label="MAPE")
                ax.plot(values_list, label="MAPE", marker='o')  # Line plot with markers
                ax.scatter(range(len(values_list)), values_list, color='red', label="MAPE Points", zorder=3)  # Scatter plot for individual points

                ax.set_title(f"Shift = {shift} Week ")
                ax.get_legend().remove()

                mape_shift = pd.concat([mape_shift, values_df], axis=1, join='inner')  # Concatenate MAPE results
                mape_wave_shift[waveID] = mape_shift
                #print('waveID ', waveID, 'shift', shift)#, 'mape_shift', mape_shift)
                # Labeling
                if shift == 0:
                    ax.set_ylabel(model_name)
                if shift == len(trend_adjustment_steps) - 1 and model_index == len(models) - 1:
                    ax.legend(
                        ["MAPE", "MAPE", 'First Week', 'Second Week', 'Third Week', 'Fourth Week', 'Fifth Week', 'Sixth Week'],
                        loc='lower center',
                        bbox_to_anchor=(-2, -0.3),
                        ncol=7
                    )

        # Super labels
        fig.supxlabel(f"Prediction Length (Week), Wave = {waveID}")
        fig.supylabel("MAPE %")

    return mape_wave_shift



#Visualization.py
def visualize_wave_shifts(data_dict):
    """
    Plots clearer and user-friendly time interval ranges for all wave-shift combinations.

    Args:
        data_dict (dict): A dictionary containing wave shift combinations
                          with 'all', 'train', and 'test' data ranges.
    """
    plt.figure(figsize=(14, 8))
    plt.title("Time Interval Comparison for Wave-shift Combinations", fontsize=16, pad=20)
    plt.xlabel("Date", fontsize=14, labelpad=40)  # Move x-axis label down
    plt.ylabel("Wave-shift Combinations", fontsize=14, labelpad=15)  # Move y-axis label up

    # Move y-axis label farther to the right
    plt.gca().yaxis.set_label_coords(-0.1, 0.5)  # Adjust x and y positions of label


    y_offset = 1  # Start y_offset for waves
    spacing = 2  # Spacing between each wave

    for wave_name, intervals in data_dict.items():
        all_range = [safe_to_datetime(i) for i in intervals['all'].index]
        train_range = [safe_to_datetime(i) for i in intervals['train'].index]
        test_range = [safe_to_datetime(i) for i in intervals['test'].index]


    # for wave_name, intervals in data_dict.items():
    #     # Extract ranges and convert to datetime
    #     all_range = [datetime.datetime.fromisoformat(i) for i in intervals['all'].index]
    #     train_range = [datetime.datetime.fromisoformat(i) for i in intervals['train'].index]
    #     test_range = [datetime.datetime.fromisoformat(i) for i in intervals['test'].index]

        # Plot 'all', 'train', and 'test' ranges with spacing
        plt.hlines(y=y_offset, xmin=all_range[0], xmax=all_range[-1], color='gray', label='Full Range' if y_offset == 1 else "", linewidth=2, alpha=0.7)
        plt.hlines(y=y_offset + 0.5, xmin=train_range[0], xmax=train_range[-1], color='blue', label='Train Range' if y_offset == 1 else "", linewidth=2)
        plt.hlines(y=y_offset + 1, xmin=test_range[0], xmax=test_range[-1], color='green', label='Test Range' if y_offset == 1 else "", linewidth=2)

        # Add markers for start and end dates
        plt.scatter([all_range[0], all_range[-1]], [y_offset, y_offset], color='gray', edgecolor='black', s=40, label='_nolegend_')
        plt.scatter([train_range[0], train_range[-1]], [y_offset + 0.5, y_offset + 0.5], color='blue', edgecolor='black', s=40, label='_nolegend_')
        plt.scatter([test_range[0], test_range[-1]], [y_offset + 1, y_offset + 1], color='green', edgecolor='black', s=40, label='_nolegend_')

        # Annotate wave name slightly to the left
        plt.text(all_range[0] - datetime.timedelta(days=7), y_offset - 0.2, wave_name, fontsize=12, ha='right', color='black')

        # Increment y_offset for the next wave
        y_offset += spacing

    # Adjust y-axis limits
    plt.ylim(0, y_offset)
    plt.yticks([])  # Remove y-axis ticks for a cleaner look
    plt.xticks(rotation=45, fontsize=12)

    # Add a grouped legend
    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fontsize=12, ncol=3, frameon=False)

    # Final layout adjustments
    plt.tight_layout()
    plt.show()





#generalized


def plot_predictions(wave_tasks, labels, shift, prediction_length, MAPE_data_dictionary, models, observed_label='Observed', recent_week_count=None, model_colors=None):
    """
    Generalized function to plot predictions for multiple ML models and ARIMA.

    Parameters:
    - wave_tasks: List of wave task objects
    - shift: shift amount parameter
    - prediction_length: Prediction length parameter
    - MAPE_data_dictionary: Dictionary containing MAPE data for each wave, shift, and prediction length
    - models: Dictionary of models to include in the plot
    - observed_label: Column name for the observed data
    - recent_week_count: Optional. Number of weeks to consider for plotting. Defaults to None (all data).
    - model_colors: Optional dictionary mapping model names to specific plot colors.
    """
    fig = plt.figure(figsize=(16, 10))
    plt.subplots_adjust(left=0.1, right=1, top=1, bottom=0.15)
    gs = fig.add_gridspec(len(wave_tasks), 1, hspace=0, wspace=0)
    i = 0

    for wave in wave_tasks:
        waveID = wave.waveID
        wave_shift_prediction_length_key = f'wave {waveID} shift {shift} prediction_length {prediction_length}'
        task = MAPE_data_dictionary[wave_shift_prediction_length_key]

        # Extract recent weeks if specified
        if recent_week_count:
            task = task.tail(recent_week_count).reset_index(drop=True)

        ax = fig.add_subplot(gs[i, 0])

        # Plot each model's predictions
        for model_name in models.keys():
            if model_name in task.columns:
                color = model_colors.get(model_name, None) if model_colors else None
                ax.plot(task.index, task[model_name], label=model_name, linestyle='-', lw=1.5, color=color)

        # Plot observed data
        if observed_label in task.columns:
            ax.plot(task.index, task[observed_label], label=observed_label, color='black', linestyle='dotted')

        ax.set_ylabel("Wave " + labels[i], fontsize=13)
        i += 1

        if i >= 2:
            ax.legend(loc='lower center', bbox_to_anchor=(1.05, 1), ncol=1)
            ax.set_xticklabels(task.index, rotation=45)

        ax.axvline('2023-10-08', color='black', linestyle='--', lw=2)  # Example date for a vertical line

    # Adding title and labels
    fig.supxlabel('Week', fontsize=16)
    fig.supylabel("Covid Cases", fontsize=16)
    plt.show()



def plot_weekly_evaluation(weekly_prediction_future, models, shift, length, evaluation_metric_suffix, shift_type = 'Responsiveness', model_colors=None):
    """
    Plots weekly evaluation metrics (e.g., MAPE or MSE) from different models for a specified shift and length.

    Parameters:
    - weekly_prediction_future (dict): Dictionary containing weekly evaluation metrics.
    - models (dict): Dictionary mapping model names to their implementations.
    - shift (int): The shift value to filter the data.
    - length (float): The length value to filter the data.
    - evaluation_metric_suffix (str): The suffix for the evaluation metric (e.g., "_MAPE" or "_MSE").
    """

    print('Shift:', shift, 'prediction_length:', length)

    # Extract weeks (keys)
    weeks = list(weekly_prediction_future.keys())

    # Initialize dictionary to store evaluation metrics for each model
    model_evaluation = {model + evaluation_metric_suffix: [] for model in ['MLAMA', 'ARIMA'] + list(models.keys())}

    filtered_weeks = []

    # Loop through each week and extract the evaluation metrics
    for week in weeks:
        data = weekly_prediction_future.get(week)  # Get week's data safely
        if data is None:
            continue  # Skip if there's no data

        # Apply filtering based on shift and Length
        data_filtered = data[(data['Shift'] == shift) & (data['Length'] == length)]

        if data_filtered.empty:
            continue  # Skip if no matching data

        filtered_weeks.append(week)  # Store filtered week

        # Extract and store evaluation metrics for each model
        for model in model_evaluation.keys():
            if model in data_filtered:
                value = data_filtered[model].iloc[0]  # Extract first row's value safely
                if isinstance(value, list):
                    value = value[0]  # Extract from list if it's inside a list
                model_evaluation[model].append(value)
            else:
                model_evaluation[model].append(None)  # Fill missing values with None

    # Convert week labels to datetime for proper plotting
    week_dates = pd.to_datetime(filtered_weeks)

    # Plot the data
    plt.figure(figsize=(12, 6))

    # Plot each model's evaluation metric
    # for model, values in model_evaluation.items():
    #     plt.plot(week_dates, values, marker='o', label=model)

    for model, values in model_evaluation.items():
        if model_colors and model in model_colors:
            plt.plot(week_dates, values, marker='o', label=model, color=model_colors[model])
        else:
            plt.plot(week_dates, values, marker='o', label=model)  # default color

    plt.xlabel("Week")
    plt.ylabel(f"Evaluation Metric {evaluation_metric_suffix}")
    plt.title(f"Weekly Evaluation for Shift ({shift_type})={shift}, Length={length}")
    plt.legend()
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.show()

def plot_weekly_difference(weekly_prediction_future, models, delay, length, shift_type = 'Responsiveness', model_colors=None):
    """
    Plots weekly differences (prediction - observed) from different models for a specified delay and length.

    Parameters:
    - weekly_prediction_future (dict): Dictionary containing weekly predictions and all other values.
    - models (dict): Dictionary mapping model names to their implementations.
    - delay (int): The delay value to filter the data.
    - length (float): The length value to filter the data.
    - model_colors (dict, optional): Optional dictionary mapping model names to specific plot colors.
    """

    weeks = list(weekly_prediction_future.keys())
    model_diff = {model: [] for model in ['ARIMA', 'MLAMA'] + list(models.keys())}
    filtered_weeks = []

    for week in weeks:
        data = weekly_prediction_future.get(week)
        data_filtered = data[(data['Shift'] == delay) & (data['Length'] == length)]
        if data_filtered.empty:
            continue

        filtered_weeks.append(week)
        observed_val = data_filtered['Observed'].iloc[0] if 'Observed' in data_filtered else None

        model_diff['ARIMA'].append(data_filtered['diff_ARIMA'].iloc[0] if 'diff_ARIMA' in data_filtered else None)

        if 'MLAMA' in data_filtered and observed_val is not None:
            mlama_val = data_filtered['MLAMA'].iloc[0]
            model_diff['MLAMA'].append(mlama_val - observed_val)
        else:
            model_diff['MLAMA'].append(None)

        for model in models.keys():
            if model in ['ARIMA', 'MLAMA']:
                continue
            diff_col = 'diff_' + model
            model_diff[model].append(data_filtered[diff_col].iloc[0] if diff_col in data_filtered else None)

    week_dates = pd.to_datetime(filtered_weeks)

    # Plot
    plt.figure(figsize=(12, 6))
    for model, values in model_diff.items():
        if model_colors and model in model_colors:
            plt.plot(week_dates, values, marker='o', label=model, color=model_colors[model])
        else:
            plt.plot(week_dates, values, marker='o', label=model)  # default color

    plt.xlabel("Week")
    plt.ylabel("Difference (Prediction - Observed)")
    plt.title(f"Weekly Differences for Shift ({shift_type}) = {delay}, Length = {length}")
    plt.xticks(rotation=45)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()



def plot_responsiveness_vs_metric(theDD, metric_name):
    # Filter only metric data for plotting
    theDD_metric = theDD[theDD['Metric'] == metric_name].copy()

    # Ensure MLAMA is plotted last
    algo_order = sorted(theDD_metric['Algorithm'].unique(), key=lambda x: (x != 'MLAMA', x))

    # P1 Plot 1: Adaptability vs Metric
    plt.figure(figsize=(10, 6))
    sns.lineplot(data=theDD_metric, x='Adaptability', y='Value', hue='Algorithm', hue_order=algo_order, linewidth=2.0)

    plt.ylabel('S' + metric_name)
    plt.xlabel('Adaptability/Responsiveness is x-axis. Delayed train+test, how many additional weeks are added for training,  \n'
               'so testing starts from later point in time, test size depends on prediction_length,\n'
               'for all the waves and prediction length averaged to calculate MAPE. \n'
               'Number of Weeks of Data Since the Local Min/Max')
    plt.title('a. Responsiveness')
    plt.show()


def plot_prediction_length_vs_metric(theD_long, metric_name, shift_type = 'Responsiveness'):
    suffix = '_' + metric_name
    theDD_metric_length = theD_long[theD_long['Algorithm'].str.endswith(suffix)].copy()
    theDD_metric_length['Algorithm'] = theDD_metric_length['Algorithm'].str.replace(suffix, '', regex=False)

    # Group data
    theDD_metric_length = theDD_metric_length.groupby(['Algorithm', 'Prediction Length']).agg({'Value': 'mean'}).reset_index()

    # Ensure MLAMA is plotted last
    algo_order = sorted(theDD_metric_length['Algorithm'].unique(), key=lambda x: (x != 'MLAMA', x))

    # Plot with adjusted order
    plt.figure(figsize=(10, 6))
    sns.lineplot(data=theDD_metric_length, x='Prediction Length', y='Value', hue='Algorithm', hue_order=algo_order, linewidth=2.0)

    plt.ylabel(metric_name)
    plt.xlabel(f'Number of Weeks in Forecast, averaged for all shift ({shift_type}), wave')
    plt.title(f'Prediction Length vs {metric_name}')
    plt.show()

def plot_model_weights(stan_optimal_weights, shift_type = 'Responsiveness', plot_type='bar', order="shift_pred", title=""):
    """
    Plots model weights across shifts and prediction lengths.

    Parameters:
        stan_optimal_weights (dict): Dictionary with keys as "Shift PredictionLength" (str)
                                     and values as tuples of (model_names, weight_values).
        plot_type (str): Type of plot to generate. Options: 'bar', 'lineplot'.
        order (str): Ordering of x-axis. Options: "shift_pred" or "pred_shift".

    Returns:
        None
    """
    # Extract keys and values
    keys = list(stan_optimal_weights.keys())
    model_names, weight_values = zip(*stan_optimal_weights.values())  # Unpack names & weights
    weights = np.array(weight_values)  # Convert to NumPy array

    # Convert keys into separate shift and prediction length
    shifts, pred_lengths = zip(*[map(int, key.split()) for key in keys])

    # Sort data based on order preference
    if order == "shift_pred":
        sorted_indices = np.lexsort((pred_lengths, shifts))
    elif order == "pred_shift":
        sorted_indices = np.lexsort((shifts, pred_lengths))
    else:
        raise ValueError("Invalid order. Choose 'shift_pred' or 'pred_shift'.")

    # Apply sorting
    shifts = [shifts[i] for i in sorted_indices]
    pred_lengths = [pred_lengths[i] for i in sorted_indices]
    weights = weights[sorted_indices]
    keys = [keys[i] for i in sorted_indices]

    # Extract correct model names (assuming they are the same across keys)
    model_names = model_names[0]

    # Format x-axis labels based on ordering preference
    if order == "shift_pred":
        x_labels = [f"({s}, {p})" for s, p in zip(shifts, pred_lengths)]
        xlabel = f"(Shift ({shift_type}), Prediction Length)"
    else:
        x_labels = [f"({p}, {s})" for s, p in zip(shifts, pred_lengths)]
        xlabel = f"(Prediction Length, Shift ({shift_type})"

    if plot_type == 'bar':
        # Bar Plot (Side by Side)
        fig, ax = plt.subplots(figsize=(12, 6))
        x = np.arange(len(x_labels))  # X-axis positions
        width = 0.15  # Bar width

        for i, model in enumerate(model_names):
            ax.bar(x + i * width, weights[:, i], width=width, label=model)

        ax.set_xticks(x + (len(model_names) - 1) * width / 2)
        ax.set_xticklabels(x_labels, rotation=45, ha="right")
        ax.set_ylabel('Weight')
        ax.set_xlabel(xlabel)
        ax.set_title('Model Weights' +title)
        ax.legend(title="Models")
        ax.grid(axis="y", linestyle="--", alpha=0.7)

    elif plot_type == 'lineplot':
        # Line Plot
        plt.figure(figsize=(10, 5))

        for i, model in enumerate(model_names):
            model_weights = [weights[j][i] for j in range(len(weights))]
            plt.plot(x_labels, model_weights, label=model, marker='o')

        plt.xticks(rotation=45, ha="right")
        plt.xlabel(xlabel)
        plt.ylabel('Weight')
        plt.title('Model Weights')
        plt.legend(title="Models")
        plt.grid(linestyle="--", alpha=0.7)

    else:
        raise ValueError("Invalid plot_type. Choose 'bar' or 'lineplot'.")

    plt.show()

def plot_model_weights_all_weeks(model_weights, shift_type='Responsiveness', plot_type='bar', order='shift_pred'):
    """
    Plots model weights for each week contained in the model_weights dictionary.

    Parameters:
        model_weights (dict): Nested dictionary structured as:
                              {
                                '2025-01-05': {
                                    '0 1': (['ARIMA', 'RF', 'xgb'], [0.29, 0.33, 0.37]),
                                    ...
                                },
                                ...
                              }
        shift_type (str): Descriptive label for 'Shift' in x-axis (default: 'Responsiveness').
        plot_type (str): 'bar' or 'lineplot' for each week's visualization.
        order (str): 'shift_pred' or 'pred_shift' for x-axis ordering.

    Returns:
        None
    """
    for week, weight_dict in model_weights.items():
        print(f"📅 Plotting weights for week: {week}")
        plot_model_weights(weight_dict, shift_type=shift_type, plot_type=plot_type, order=order)#, title = "week: {week}"

import matplotlib.pyplot as plt
from collections import defaultdict
import numpy as np

def plot_weights_by_shift_length_over_weeks(model_weights, shift_type='Responsiveness', plot_type='bar'):
    """
    For each shift length, plot model weights (ARIMA, RF, xgb) across all weeks.

    Parameters:
        model_weights (dict): Nested dictionary structured as:
                              {
                                '2025-01-05': {
                                    '0 1': (['ARIMA', 'RF', 'xgb'], [0.29, 0.33, 0.37]),
                                    ...
                                },
                                ...
                              }
        shift_type (str): Descriptor to include in plot titles.
        plot_type (str): 'line' or 'bar' to control the type of plot.

    Returns:
        None
    """
    # Organize data: { shift_length -> { model -> [(week, weight)] } }
    shift_model_time_series = defaultdict(lambda: defaultdict(list))

    for week, shift_dict in model_weights.items():
        for shift_length, (models, weights) in shift_dict.items():
            for model, weight in zip(models, weights):
                shift_model_time_series[shift_length][model].append((week, weight))

    # Plot for each shift length
    for shift_length, model_data in shift_model_time_series.items():
        plt.figure(figsize=(10, 6))
        sorted_weeks = sorted({week for model in model_data.values() for week, _ in model})
        x = np.arange(len(sorted_weeks))  # positions for bars or x-axis ticks

        if plot_type == 'bar':
            bar_width = 0.2
            offsets = np.linspace(-bar_width, bar_width, len(model_data))

            for offset, (model, week_weight_pairs) in zip(offsets, model_data.items()):
                weeks, weights = zip(*sorted(week_weight_pairs))
                weights_ordered = [dict(week_weight_pairs).get(w, 0) for w in sorted_weeks]
                plt.bar(x + offset, weights_ordered, width=bar_width, label=model)

            plt.xticks(x, sorted_weeks, rotation=45)

        else:  # 'line' plot
            for model, week_weight_pairs in model_data.items():
                weeks, weights = zip(*sorted(week_weight_pairs))
                plt.plot(weeks, weights, marker='o', label=model)

        plt.title(f'Model Weights Over Weeks - Shift ({shift_type}) Length: {shift_length}')
        plt.xlabel('Week')
        plt.ylabel('Weight')
        plt.ylim(0, 1)
        plt.grid(True, linestyle='--', alpha=0.6)
        plt.legend()
        plt.tight_layout()
        plt.show()