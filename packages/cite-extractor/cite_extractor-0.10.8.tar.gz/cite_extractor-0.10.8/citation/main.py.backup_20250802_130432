import os
import logging
import fitz  # PyMuPDF
from typing import Dict, Optional

from .vertical_llm import VerticalCitationLLM
from .utils import (
    parse_page_range,
    get_input_type,
    determine_url_type,
    save_citation,
    to_csl_json,
    create_subset_pdf,
    extract_pdf_text,
)
from .file_converter import convert_to_pdf
from .type_judge import determine_document_type
from .model import CitationLLM

# Configure logging
logging.basicConfig(
from .ocr_text_clean_before_llm import clean_extracted_text
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

class CitationExtractor:
    def __init__(self, llm_model="ollama/qwen3"):
        """Initialize the citation extractor."""
        self.llm = CitationLLM(llm_model)

    def extract_citation(
        self,
        input_source: str,
        output_dir: str = "example",
        doc_type_override: Optional[str] = None,
        lang: str = "auto",
        text_direction: str = "horizontal",
        vertical_lang: str = "ch",
        page_range: str = "1-5, -3",
    ) -> Optional[Dict]:
        """Main function to extract citation from any supported source."""
        temp_pdf_path = None
        try:
            input_type = get_input_type(input_source)

            if input_type == "URL":
                logging.info(f"Detected URL input: {input_source}")
                # This part of the workflow remains unchanged.
                # return self.extract_from_url(input_source, output_dir)
                pass # Placeholder for existing URL logic
            
            elif input_type == "MEDIA_FILE":
                logging.info(f"Detected media file input: {input_source}")
                # This part of the workflow remains unchanged.
                # return self.extract_from_media_file(input_source, output_dir)
                pass # Placeholder for existing media file logic

            elif input_type == "OFFICE_DOCUMENT":
                logging.info(f"Detected Office document: {input_source}")
                return self.extract_from_office_document_unified(
                    input_source, output_dir, doc_type_override, lang,
                    text_direction, vertical_lang, page_range
                )

            elif input_type == "PYMUPDF_DOCUMENT":
                logging.info(f"Detected PyMuPDF-supported document: {input_source}")
                return self.extract_from_document(
                    input_source, output_dir, doc_type_override, lang, 
                    text_direction, vertical_lang, page_range
                )

            else:
                logging.error(f"Unknown or unsupported input type: {input_source}")
                if os.path.exists(input_source):
                    logging.error(f"File exists but is not a supported format.")
                else:
                    logging.error(f"File does not exist: {input_source}")
                return None

        except Exception as e:
            logging.error(f"Error in citation extraction: {e}")
            import traceback
            logging.debug(traceback.format_exc())
            return None
        finally:
            # Ensure temporary PDF from Office conversion is always cleaned up
            if temp_pdf_path and os.path.exists(temp_pdf_path):
                os.remove(temp_pdf_path)
                logging.info(f"Removed temporary file: {temp_pdf_path}")

    def extract_from_document(
        self,
        doc_path: str,
        output_dir: str,
        doc_type_override: Optional[str],
        lang: str,
        text_direction: str,
        vertical_lang: str,
        page_range: str,
    ) -> Optional[Dict]:
        """Unified function to extract citation from any document supported by PyMuPDF."""
        temp_subset_pdf = None
        try:
            print(f"ðŸ“„ Starting document citation extraction...")

            # Step 1: Analyze document for page count
            print("ðŸ” Step 1: Analyzing document structure...")
            num_pages, _ = self._analyze_document_structure(doc_path)
            if num_pages == 0:
                logging.error(f"Could not read document file: {doc_path}")
                return None

            # Step 2: Document Type Pre-filtering by Page Count
            print(f"ðŸ“Š Step 2: Document type pre-filtering from page count ({num_pages} pages)...")
            if num_pages >= 70:
                allowed_doc_types = ["book", "thesis"]
                page_count_hint = "book"
            else:
                allowed_doc_types = ["journal", "bookchapter"]
                page_count_hint = "journal"

            # Adjust page range based on total pages
            if num_pages >= 70:
                page_range = "1-5"
            else:
                page_range = "1-3, -3"

            # Step 3: Create subset PDF from page range
            print(f"âœ‚ï¸ Step 3: Creating temporary PDF from page range '{page_range}'...")
            temp_subset_pdf = create_subset_pdf(doc_path, page_range, num_pages)
            if not temp_subset_pdf:
                return None

            # Step 4: Process the subset PDF to extract text
            accumulated_text = self._process_subset_pdf(temp_subset_pdf, text_direction)
            if not accumulated_text.strip():
                print("âŒ No text could be extracted from the document.")
                return None

            # Step 5: Document Type Determination
            print("ðŸ” Step 5: Determining document type...")
            doc_type = doc_type_override or self._determine_document_type_filtered(
                temp_subset_pdf, num_pages, allowed_doc_types, page_count_hint
            )
            print(f"ðŸ“‹ Determined document type: {doc_type.upper()}")

            # Step 6: LLM Extraction
            print(f"ðŸ¤– Step 6: Extracting citation from accumulated text with LLM...")
            if text_direction in ["vertical", "auto"] and getattr(self, "_used_vertical_mode", False):
                vertical_llm = VerticalCitationLLM()
                extracted_info = vertical_llm.extract_vertical_citation(accumulated_text, doc_type)
            else:
                extracted_info = self.llm.extract_citation_from_text(accumulated_text, doc_type)
            
            if not extracted_info:
                print("âŒ Failed to extract any citation information with LLM.")
                return None

            # Step 7: Convert to CSL JSON and save
            print("ðŸ’¾ Step 7: Converting to CSL JSON and saving...")
            csl_data = to_csl_json(extracted_info, doc_type)
            save_citation(csl_data, output_dir)
            print("âœ… Citation extraction completed successfully!")
            return csl_data

        except Exception as e:
            logging.error(f"Error extracting citation from document: {e}")
            import traceback
            logging.debug(traceback.format_exc())
            return None
        finally:
            # Clean up the subset PDF
            if temp_subset_pdf and os.path.exists(temp_subset_pdf):
                os.remove(temp_subset_pdf)
                logging.info(f"Removed temporary subset file: {temp_subset_pdf}")

    def _analyze_document_structure(self, doc_path: str) -> tuple:
        """Analyze document structure using PyMuPDF."""
        try:
            doc = fitz.open(doc_path)
            num_pages = doc.page_count
            doc.close()
            return num_pages, os.path.basename(doc_path)
        except Exception as e:
            # Handle password-protected files gracefully
            if "password" in str(e).lower():
                logging.error(f"The file is password-protected and cannot be processed: {doc_path}")
            else:
                logging.error(f"Error analyzing document structure: {e}")
            return 0, ""

    def _process_subset_pdf(self, pdf_path: str, text_direction: str) -> str:
        """Processes a subset PDF to extract text based on layout."""
        if text_direction == "horizontal":
            return self._process_horizontal_mode(pdf_path)
        elif text_direction == "vertical":
            self._used_vertical_mode = True
            return self._process_vertical_mode(pdf_path)
        elif text_direction == "auto":
            return self._process_auto_mode(pdf_path)
        return ""

    def _process_horizontal_mode(self, pdf_path: str) -> str:
        # (Implementation for horizontal text extraction remains the same)
        from .utils import ensure_searchable_pdf_with_detection
        searchable_pdf_path = ensure_searchable_pdf_with_detection(pdf_path)
        doc = fitz.open(searchable_pdf_path)
        accumulated_text = ""
        for page in doc:
            accumulated_text += page.get_text() + "\n\n"
        doc.close()
        return accumulated_text

    def _process_vertical_mode(self, pdf_path: str) -> str:
        # (Implementation for vertical text extraction remains the same)
        from .vertical_handler import process_vertical_pdf
        return process_vertical_pdf(pdf_path, "ch")

    def _process_auto_mode(self, pdf_path: str) -> str:
        # (Implementation for auto-detection remains the same)
        doc = fitz.open(pdf_path)
        if doc.page_count == 0:
            doc.close()
            return ""
        
        first_page_pix = doc[0].get_pixmap()
        doc.close()
        
        from .vertical_handler import is_vertical_from_layout
        if is_vertical_from_layout(first_page_pix, "ch"):
            self._used_vertical_mode = True
            return self._process_vertical_mode(pdf_path)
        else:
            return self._process_horizontal_mode(pdf_path)

    def _determine_document_type_filtered(self, pdf_path: str, num_pages: int, allowed_types: list, default_type: str) -> str:
        """Determine document type with pre-filtering based on page count."""
        detected_type = determine_document_type(pdf_path, num_pages)
        return detected_type if detected_type in allowed_types else default_type