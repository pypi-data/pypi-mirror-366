# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

import httpx

from .core.api_error import ApiError
from .core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from .core.jsonable_encoder import jsonable_encoder
from .core.remove_none_from_dict import remove_none_from_dict
from .environment import OpenPipeApiEnvironment
from .types.check_cache_response import CheckCacheResponse
from .types.create_chat_completion_request_audio import CreateChatCompletionRequestAudio
from .types.create_chat_completion_request_function_call import CreateChatCompletionRequestFunctionCall
from .types.create_chat_completion_request_functions_item import CreateChatCompletionRequestFunctionsItem
from .types.create_chat_completion_request_messages_item import CreateChatCompletionRequestMessagesItem
from .types.create_chat_completion_request_response_format import CreateChatCompletionRequestResponseFormat
from .types.create_chat_completion_request_stop import CreateChatCompletionRequestStop
from .types.create_chat_completion_request_stream_options import CreateChatCompletionRequestStreamOptions
from .types.create_chat_completion_request_tool_choice import CreateChatCompletionRequestToolChoice
from .types.create_chat_completion_request_tools_item import CreateChatCompletionRequestToolsItem
from .types.create_chat_completion_response import CreateChatCompletionResponse
from .types.create_dataset_entries_request_entries_item import CreateDatasetEntriesRequestEntriesItem
from .types.create_dataset_entries_response import CreateDatasetEntriesResponse
from .types.create_dataset_response import CreateDatasetResponse
from .types.create_model_request_training_config import CreateModelRequestTrainingConfig
from .types.create_model_response import CreateModelResponse
from .types.delete_dataset_response import DeleteDatasetResponse
from .types.delete_model_response import DeleteModelResponse
from .types.get_criterion_judgement_request_input import GetCriterionJudgementRequestInput
from .types.get_criterion_judgement_request_output import GetCriterionJudgementRequestOutput
from .types.get_criterion_judgement_response import GetCriterionJudgementResponse
from .types.get_model_response import GetModelResponse
from .types.list_datasets_response import ListDatasetsResponse
from .types.list_models_response import ListModelsResponse
from .types.local_testing_only_get_latest_logged_call_response import LocalTestingOnlyGetLatestLoggedCallResponse
from .types.report_anthropic_request_req_payload import ReportAnthropicRequestReqPayload
from .types.report_anthropic_request_resp_payload import ReportAnthropicRequestRespPayload
from .types.report_anthropic_request_tags_value import ReportAnthropicRequestTagsValue
from .types.report_anthropic_response import ReportAnthropicResponse
from .types.report_request_tags_value import ReportRequestTagsValue
from .types.report_response import ReportResponse
from .types.unstable_dataset_create_response import UnstableDatasetCreateResponse
from .types.unstable_dataset_delete_response import UnstableDatasetDeleteResponse
from .types.unstable_dataset_entry_create_request_entries_item import UnstableDatasetEntryCreateRequestEntriesItem
from .types.unstable_dataset_entry_create_response import UnstableDatasetEntryCreateResponse
from .types.unstable_dataset_list_response_item import UnstableDatasetListResponseItem
from .types.unstable_finetune_create_request_overrides import UnstableFinetuneCreateRequestOverrides
from .types.unstable_finetune_create_response import UnstableFinetuneCreateResponse
from .types.unstable_finetune_delete_response import UnstableFinetuneDeleteResponse
from .types.unstable_finetune_get_response import UnstableFinetuneGetResponse
from .types.update_log_metadata_request_filters_item import UpdateLogMetadataRequestFiltersItem
from .types.update_log_metadata_request_metadata_value import UpdateLogMetadataRequestMetadataValue
from .types.update_log_metadata_response import UpdateLogMetadataResponse
from .types.update_log_tags_request_filters_item import UpdateLogTagsRequestFiltersItem
from .types.update_log_tags_request_tags_value import UpdateLogTagsRequestTagsValue
from .types.update_log_tags_response import UpdateLogTagsResponse

try:
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class OpenPipeApi:
    def __init__(
        self,
        *,
        base_url: typing.Optional[str] = None,
        environment: OpenPipeApiEnvironment = OpenPipeApiEnvironment.DEFAULT,
        token: typing.Union[str, typing.Callable[[], str]],
        timeout: typing.Optional[float] = 240,
        httpx_client: typing.Optional[httpx.Client] = None,
    ):
        self._client_wrapper = SyncClientWrapper(
            base_url=_get_base_url(base_url=base_url, environment=environment),
            token=token,
            httpx_client=httpx.Client(timeout=timeout) if httpx_client is None else httpx_client,
        )

    def check_cache(
        self,
        *,
        requested_at: float,
        req_payload: typing.Optional[typing.Any] = OMIT,
        tags: typing.Optional[typing.Dict[str, str]] = OMIT,
    ) -> CheckCacheResponse:
        """
        DEPRECATED: we no longer support prompt caching.

        Parameters:
            - requested_at: float. Unix timestamp in milliseconds

            - req_payload: typing.Optional[typing.Any].

            - tags: typing.Optional[typing.Dict[str, str]]. Extra tags to attach to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }
        """
        _request: typing.Dict[str, typing.Any] = {"requestedAt": requested_at}
        if req_payload is not OMIT:
            _request["reqPayload"] = req_payload
        if tags is not OMIT:
            _request["tags"] = tags
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "check-cache"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CheckCacheResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_chat_completion(
        self,
        *,
        messages: typing.List[CreateChatCompletionRequestMessagesItem],
        model: str,
        audio: typing.Optional[CreateChatCompletionRequestAudio] = OMIT,
        function_call: typing.Optional[CreateChatCompletionRequestFunctionCall] = OMIT,
        functions: typing.Optional[typing.List[CreateChatCompletionRequestFunctionsItem]] = OMIT,
        tool_choice: typing.Optional[CreateChatCompletionRequestToolChoice] = OMIT,
        tools: typing.Optional[typing.List[CreateChatCompletionRequestToolsItem]] = OMIT,
        n: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[float] = OMIT,
        max_completion_tokens: typing.Optional[float] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        top_p: typing.Optional[float] = OMIT,
        presence_penalty: typing.Optional[float] = OMIT,
        frequency_penalty: typing.Optional[float] = OMIT,
        stop: typing.Optional[CreateChatCompletionRequestStop] = OMIT,
        response_format: typing.Optional[CreateChatCompletionRequestResponseFormat] = OMIT,
        logprobs: typing.Optional[bool] = OMIT,
        top_logprobs: typing.Optional[float] = OMIT,
        stream_options: typing.Optional[CreateChatCompletionRequestStreamOptions] = OMIT,
        store: typing.Optional[bool] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[str]]] = OMIT,
        stream: typing.Optional[bool] = OMIT,
    ) -> CreateChatCompletionResponse:
        """
        OpenAI-compatible route for generating inference and optionally logging the request.

        Parameters:
            - messages: typing.List[CreateChatCompletionRequestMessagesItem].

            - model: str.

            - audio: typing.Optional[CreateChatCompletionRequestAudio].

            - function_call: typing.Optional[CreateChatCompletionRequestFunctionCall].

            - functions: typing.Optional[typing.List[CreateChatCompletionRequestFunctionsItem]].

            - tool_choice: typing.Optional[CreateChatCompletionRequestToolChoice].

            - tools: typing.Optional[typing.List[CreateChatCompletionRequestToolsItem]].

            - n: typing.Optional[float].

            - max_tokens: typing.Optional[float].

            - max_completion_tokens: typing.Optional[float].

            - temperature: typing.Optional[float].

            - top_p: typing.Optional[float].

            - presence_penalty: typing.Optional[float].

            - frequency_penalty: typing.Optional[float].

            - stop: typing.Optional[CreateChatCompletionRequestStop].

            - response_format: typing.Optional[CreateChatCompletionRequestResponseFormat].

            - logprobs: typing.Optional[bool].

            - top_logprobs: typing.Optional[float].

            - stream_options: typing.Optional[CreateChatCompletionRequestStreamOptions].

            - store: typing.Optional[bool].

            - metadata: typing.Optional[typing.Dict[str, typing.Optional[str]]].

            - stream: typing.Optional[bool].
        """
        _request: typing.Dict[str, typing.Any] = {"messages": messages, "model": model}
        if audio is not OMIT:
            _request["audio"] = audio
        if function_call is not OMIT:
            _request["function_call"] = function_call
        if functions is not OMIT:
            _request["functions"] = functions
        if tool_choice is not OMIT:
            _request["tool_choice"] = tool_choice
        if tools is not OMIT:
            _request["tools"] = tools
        if n is not OMIT:
            _request["n"] = n
        if max_tokens is not OMIT:
            _request["max_tokens"] = max_tokens
        if max_completion_tokens is not OMIT:
            _request["max_completion_tokens"] = max_completion_tokens
        if temperature is not OMIT:
            _request["temperature"] = temperature
        if top_p is not OMIT:
            _request["top_p"] = top_p
        if presence_penalty is not OMIT:
            _request["presence_penalty"] = presence_penalty
        if frequency_penalty is not OMIT:
            _request["frequency_penalty"] = frequency_penalty
        if stop is not OMIT:
            _request["stop"] = stop
        if response_format is not OMIT:
            _request["response_format"] = response_format
        if logprobs is not OMIT:
            _request["logprobs"] = logprobs
        if top_logprobs is not OMIT:
            _request["top_logprobs"] = top_logprobs
        if stream_options is not OMIT:
            _request["stream_options"] = stream_options
        if store is not OMIT:
            _request["store"] = store
        if metadata is not OMIT:
            _request["metadata"] = metadata
        if stream is not OMIT:
            _request["stream"] = stream
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "chat/completions"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CreateChatCompletionResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def report(
        self,
        *,
        requested_at: typing.Optional[float] = OMIT,
        received_at: typing.Optional[float] = OMIT,
        req_payload: typing.Optional[typing.Any] = OMIT,
        resp_payload: typing.Optional[typing.Any] = OMIT,
        status_code: typing.Optional[float] = OMIT,
        error_message: typing.Optional[str] = OMIT,
        tags: typing.Optional[typing.Dict[str, ReportRequestTagsValue]] = OMIT,
    ) -> ReportResponse:
        """
        Record request logs from OpenAI models

        Parameters:
            - requested_at: typing.Optional[float]. Unix timestamp in milliseconds

            - received_at: typing.Optional[float]. Unix timestamp in milliseconds

            - req_payload: typing.Optional[typing.Any].

            - resp_payload: typing.Optional[typing.Any].

            - status_code: typing.Optional[float]. HTTP status code of response

            - error_message: typing.Optional[str]. User-friendly error message

            - tags: typing.Optional[typing.Dict[str, ReportRequestTagsValue]]. DEPRECATED: use "reqPayload.metadata" to attach extra metadata tags to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }
        ---
        from OpenPipe.client import OpenPipeApi

        client = OpenPipeApi(
            token="YOUR_TOKEN",
        )
        client.report()
        """
        _request: typing.Dict[str, typing.Any] = {}
        if requested_at is not OMIT:
            _request["requestedAt"] = requested_at
        if received_at is not OMIT:
            _request["receivedAt"] = received_at
        if req_payload is not OMIT:
            _request["reqPayload"] = req_payload
        if resp_payload is not OMIT:
            _request["respPayload"] = resp_payload
        if status_code is not OMIT:
            _request["statusCode"] = status_code
        if error_message is not OMIT:
            _request["errorMessage"] = error_message
        if tags is not OMIT:
            _request["tags"] = tags
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "report"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ReportResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def report_anthropic(
        self,
        *,
        requested_at: typing.Optional[float] = OMIT,
        received_at: typing.Optional[float] = OMIT,
        req_payload: typing.Optional[ReportAnthropicRequestReqPayload] = OMIT,
        resp_payload: typing.Optional[ReportAnthropicRequestRespPayload] = OMIT,
        status_code: typing.Optional[float] = OMIT,
        error_message: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, str]] = OMIT,
        tags: typing.Optional[typing.Dict[str, ReportAnthropicRequestTagsValue]] = OMIT,
    ) -> ReportAnthropicResponse:
        """
        Record request logs from Anthropic models

        Parameters:
            - requested_at: typing.Optional[float]. Unix timestamp in milliseconds

            - received_at: typing.Optional[float]. Unix timestamp in milliseconds

            - req_payload: typing.Optional[ReportAnthropicRequestReqPayload]. JSON-encoded request payload

            - resp_payload: typing.Optional[ReportAnthropicRequestRespPayload]. JSON-encoded response payload

            - status_code: typing.Optional[float]. HTTP status code of response

            - error_message: typing.Optional[str]. User-friendly error message

            - metadata: typing.Optional[typing.Dict[str, str]]. Extra metadata tags to attach to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }

            - tags: typing.Optional[typing.Dict[str, ReportAnthropicRequestTagsValue]]. Deprecated: use "metadata" instead
        ---
        from OpenPipe.client import OpenPipeApi

        client = OpenPipeApi(
            token="YOUR_TOKEN",
        )
        client.report_anthropic()
        """
        _request: typing.Dict[str, typing.Any] = {}
        if requested_at is not OMIT:
            _request["requestedAt"] = requested_at
        if received_at is not OMIT:
            _request["receivedAt"] = received_at
        if req_payload is not OMIT:
            _request["reqPayload"] = req_payload
        if resp_payload is not OMIT:
            _request["respPayload"] = resp_payload
        if status_code is not OMIT:
            _request["statusCode"] = status_code
        if error_message is not OMIT:
            _request["errorMessage"] = error_message
        if metadata is not OMIT:
            _request["metadata"] = metadata
        if tags is not OMIT:
            _request["tags"] = tags
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "report-anthropic"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ReportAnthropicResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_log_tags(
        self,
        *,
        filters: typing.List[UpdateLogTagsRequestFiltersItem],
        tags: typing.Dict[str, UpdateLogTagsRequestTagsValue],
    ) -> UpdateLogTagsResponse:
        """
        DEPRECATED: use "/logs/update-metadata" instead

        Parameters:
            - filters: typing.List[UpdateLogTagsRequestFiltersItem].

            - tags: typing.Dict[str, UpdateLogTagsRequestTagsValue]. Extra tags to attach to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "logs/update-tags"),
            json=jsonable_encoder({"filters": filters, "tags": tags}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UpdateLogTagsResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_log_metadata(
        self,
        *,
        filters: typing.List[UpdateLogMetadataRequestFiltersItem],
        metadata: typing.Dict[str, UpdateLogMetadataRequestMetadataValue],
    ) -> UpdateLogMetadataResponse:
        """
        Update tags metadata for logged calls matching the provided filters.

        Parameters:
            - filters: typing.List[UpdateLogMetadataRequestFiltersItem].

            - metadata: typing.Dict[str, UpdateLogMetadataRequestMetadataValue]. Extra metadata to attach to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "logs/update-metadata"),
            json=jsonable_encoder({"filters": filters, "metadata": metadata}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UpdateLogMetadataResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def local_testing_only_get_latest_logged_call(self) -> typing.Optional[LocalTestingOnlyGetLatestLoggedCallResponse]:
        """
        Get the latest logged call (only for local testing)
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", "local-testing-only-get-latest-logged-call"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Optional[LocalTestingOnlyGetLatestLoggedCallResponse], _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_criterion_judgement(
        self,
        *,
        criterion_id: str,
        input: typing.Optional[GetCriterionJudgementRequestInput] = OMIT,
        output: GetCriterionJudgementRequestOutput,
    ) -> GetCriterionJudgementResponse:
        """
        Get a judgement of a completion against the specified criterion

        Parameters:
            - criterion_id: str. The ID of the criterion to judge.

            - input: typing.Optional[GetCriterionJudgementRequestInput].

            - output: GetCriterionJudgementRequestOutput. The completion message of the model.
        """
        _request: typing.Dict[str, typing.Any] = {"criterion_id": criterion_id, "output": output}
        if input is not OMIT:
            _request["input"] = input
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "criteria/judge"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(GetCriterionJudgementResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_datasets(self) -> ListDatasetsResponse:
        """
        List datasets for a project.

        ---
        from OpenPipe.client import OpenPipeApi

        client = OpenPipeApi(
            token="YOUR_TOKEN",
        )
        client.list_datasets()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "datasets"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ListDatasetsResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_dataset(self, *, name: str) -> CreateDatasetResponse:
        """
        Create a new dataset.

        Parameters:
            - name: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "datasets"),
            json=jsonable_encoder({"name": name}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CreateDatasetResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_dataset(self, dataset_id: str) -> DeleteDatasetResponse:
        """
        Delete a dataset.

        Parameters:
            - dataset_id: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"datasets/{dataset_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DeleteDatasetResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_dataset_entries(
        self, dataset_id: str, *, entries: typing.List[CreateDatasetEntriesRequestEntriesItem]
    ) -> CreateDatasetEntriesResponse:
        """
        Add new dataset entries.

        Parameters:
            - dataset_id: str.

            - entries: typing.List[CreateDatasetEntriesRequestEntriesItem].
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"datasets/{dataset_id}/entries"),
            json=jsonable_encoder({"entries": entries}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CreateDatasetEntriesResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_models(self) -> ListModelsResponse:
        """
        List all models for a project.

        ---
        from OpenPipe.client import OpenPipeApi

        client = OpenPipeApi(
            token="YOUR_TOKEN",
        )
        client.list_models()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "models"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ListModelsResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_model(
        self,
        *,
        dataset_id: str,
        slug: str,
        pruning_rule_ids: typing.Optional[typing.List[str]] = OMIT,
        training_config: CreateModelRequestTrainingConfig,
        default_temperature: typing.Optional[float] = OMIT,
    ) -> CreateModelResponse:
        """
        Train a new model.

        Parameters:
            - dataset_id: str.

            - slug: str.

            - pruning_rule_ids: typing.Optional[typing.List[str]].

            - training_config: CreateModelRequestTrainingConfig.

            - default_temperature: typing.Optional[float].
        """
        _request: typing.Dict[str, typing.Any] = {
            "datasetId": dataset_id,
            "slug": slug,
            "trainingConfig": training_config,
        }
        if pruning_rule_ids is not OMIT:
            _request["pruningRuleIds"] = pruning_rule_ids
        if default_temperature is not OMIT:
            _request["defaultTemperature"] = default_temperature
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "models"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CreateModelResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_model(self, model_slug: str) -> GetModelResponse:
        """
        Get a model by ID.

        Parameters:
            - model_slug: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"models/{model_slug}"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(GetModelResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_model(self, model_slug: str) -> DeleteModelResponse:
        """
        Delete an existing model.

        Parameters:
            - model_slug: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"models/{model_slug}"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DeleteModelResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def unstable_dataset_create(self, *, name: str) -> UnstableDatasetCreateResponse:
        """
        DEPRECATED: use the `/datasets` endpoint instead

        Parameters:
            - name: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/dataset/create"),
            json=jsonable_encoder({"name": name}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableDatasetCreateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def unstable_dataset_delete(self, *, dataset_id: str) -> UnstableDatasetDeleteResponse:
        """
        DEPRECATED: use the `/datasets/{dataset}` endpoint instead

        Parameters:
            - dataset_id: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/dataset/delete"),
            json=jsonable_encoder({"datasetId": dataset_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableDatasetDeleteResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def unstable_dataset_list(self) -> typing.List[UnstableDatasetListResponseItem]:
        """
        DEPRECATED: use the `/datasets` endpoint instead

        ---
        from OpenPipe.client import OpenPipeApi

        client = OpenPipeApi(
            token="YOUR_TOKEN",
        )
        client.unstable_dataset_list()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/dataset/list"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[UnstableDatasetListResponseItem], _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def unstable_dataset_entry_create(
        self, *, dataset_id: str, entries: typing.List[UnstableDatasetEntryCreateRequestEntriesItem]
    ) -> UnstableDatasetEntryCreateResponse:
        """
        DEPRECATED: use the `/datasets/{dataset}/entries` endpoint instead

        Parameters:
            - dataset_id: str.

            - entries: typing.List[UnstableDatasetEntryCreateRequestEntriesItem].
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/dataset-entry/create"),
            json=jsonable_encoder({"datasetId": dataset_id, "entries": entries}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableDatasetEntryCreateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def unstable_finetune_create(
        self,
        *,
        dataset_id: str,
        slug: str,
        base_model: str,
        overrides: typing.Optional[UnstableFinetuneCreateRequestOverrides] = OMIT,
    ) -> UnstableFinetuneCreateResponse:
        """
        DEPRECATED

        Parameters:
            - dataset_id: str.

            - slug: str.

            - base_model: str. The base model to fine-tune from. Supported models include: meta-llama/Meta-Llama-3.1-8B-Instruct, meta-llama/Meta-Llama-3.1-70B-Instruct

            - overrides: typing.Optional[UnstableFinetuneCreateRequestOverrides].
        """
        _request: typing.Dict[str, typing.Any] = {"datasetId": dataset_id, "slug": slug, "baseModel": base_model}
        if overrides is not OMIT:
            _request["overrides"] = overrides
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/finetune/create"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableFinetuneCreateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def unstable_finetune_get(
        self, *, id: typing.Optional[str] = None, slug: typing.Optional[str] = None
    ) -> UnstableFinetuneGetResponse:
        """
        DEPRECATED: use the `/models/{model}` endpoint instead

        Parameters:
            - id: typing.Optional[str].

            - slug: typing.Optional[str].
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/finetune/get"),
            params=remove_none_from_dict({"id": id, "slug": slug}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableFinetuneGetResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def unstable_finetune_delete(
        self, *, id: typing.Optional[str] = OMIT, slug: typing.Optional[str] = OMIT
    ) -> UnstableFinetuneDeleteResponse:
        """
        DEPRECATED: use the `/models/{model}` endpoint instead

        Parameters:
            - id: typing.Optional[str].

            - slug: typing.Optional[str].
        """
        _request: typing.Dict[str, typing.Any] = {}
        if id is not OMIT:
            _request["id"] = id
        if slug is not OMIT:
            _request["slug"] = slug
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/finetune/delete"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableFinetuneDeleteResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncOpenPipeApi:
    def __init__(
        self,
        *,
        base_url: typing.Optional[str] = None,
        environment: OpenPipeApiEnvironment = OpenPipeApiEnvironment.DEFAULT,
        token: typing.Union[str, typing.Callable[[], str]],
        timeout: typing.Optional[float] = 240,
        httpx_client: typing.Optional[httpx.AsyncClient] = None,
    ):
        self._client_wrapper = AsyncClientWrapper(
            base_url=_get_base_url(base_url=base_url, environment=environment),
            token=token,
            httpx_client=httpx.AsyncClient(timeout=timeout) if httpx_client is None else httpx_client,
        )

    async def check_cache(
        self,
        *,
        requested_at: float,
        req_payload: typing.Optional[typing.Any] = OMIT,
        tags: typing.Optional[typing.Dict[str, str]] = OMIT,
    ) -> CheckCacheResponse:
        """
        DEPRECATED: we no longer support prompt caching.

        Parameters:
            - requested_at: float. Unix timestamp in milliseconds

            - req_payload: typing.Optional[typing.Any].

            - tags: typing.Optional[typing.Dict[str, str]]. Extra tags to attach to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }
        """
        _request: typing.Dict[str, typing.Any] = {"requestedAt": requested_at}
        if req_payload is not OMIT:
            _request["reqPayload"] = req_payload
        if tags is not OMIT:
            _request["tags"] = tags
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "check-cache"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CheckCacheResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_chat_completion(
        self,
        *,
        messages: typing.List[CreateChatCompletionRequestMessagesItem],
        model: str,
        audio: typing.Optional[CreateChatCompletionRequestAudio] = OMIT,
        function_call: typing.Optional[CreateChatCompletionRequestFunctionCall] = OMIT,
        functions: typing.Optional[typing.List[CreateChatCompletionRequestFunctionsItem]] = OMIT,
        tool_choice: typing.Optional[CreateChatCompletionRequestToolChoice] = OMIT,
        tools: typing.Optional[typing.List[CreateChatCompletionRequestToolsItem]] = OMIT,
        n: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[float] = OMIT,
        max_completion_tokens: typing.Optional[float] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        top_p: typing.Optional[float] = OMIT,
        presence_penalty: typing.Optional[float] = OMIT,
        frequency_penalty: typing.Optional[float] = OMIT,
        stop: typing.Optional[CreateChatCompletionRequestStop] = OMIT,
        response_format: typing.Optional[CreateChatCompletionRequestResponseFormat] = OMIT,
        logprobs: typing.Optional[bool] = OMIT,
        top_logprobs: typing.Optional[float] = OMIT,
        stream_options: typing.Optional[CreateChatCompletionRequestStreamOptions] = OMIT,
        store: typing.Optional[bool] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[str]]] = OMIT,
        stream: typing.Optional[bool] = OMIT,
    ) -> CreateChatCompletionResponse:
        """
        OpenAI-compatible route for generating inference and optionally logging the request.

        Parameters:
            - messages: typing.List[CreateChatCompletionRequestMessagesItem].

            - model: str.

            - audio: typing.Optional[CreateChatCompletionRequestAudio].

            - function_call: typing.Optional[CreateChatCompletionRequestFunctionCall].

            - functions: typing.Optional[typing.List[CreateChatCompletionRequestFunctionsItem]].

            - tool_choice: typing.Optional[CreateChatCompletionRequestToolChoice].

            - tools: typing.Optional[typing.List[CreateChatCompletionRequestToolsItem]].

            - n: typing.Optional[float].

            - max_tokens: typing.Optional[float].

            - max_completion_tokens: typing.Optional[float].

            - temperature: typing.Optional[float].

            - top_p: typing.Optional[float].

            - presence_penalty: typing.Optional[float].

            - frequency_penalty: typing.Optional[float].

            - stop: typing.Optional[CreateChatCompletionRequestStop].

            - response_format: typing.Optional[CreateChatCompletionRequestResponseFormat].

            - logprobs: typing.Optional[bool].

            - top_logprobs: typing.Optional[float].

            - stream_options: typing.Optional[CreateChatCompletionRequestStreamOptions].

            - store: typing.Optional[bool].

            - metadata: typing.Optional[typing.Dict[str, typing.Optional[str]]].

            - stream: typing.Optional[bool].
        """
        _request: typing.Dict[str, typing.Any] = {"messages": messages, "model": model}
        if audio is not OMIT:
            _request["audio"] = audio
        if function_call is not OMIT:
            _request["function_call"] = function_call
        if functions is not OMIT:
            _request["functions"] = functions
        if tool_choice is not OMIT:
            _request["tool_choice"] = tool_choice
        if tools is not OMIT:
            _request["tools"] = tools
        if n is not OMIT:
            _request["n"] = n
        if max_tokens is not OMIT:
            _request["max_tokens"] = max_tokens
        if max_completion_tokens is not OMIT:
            _request["max_completion_tokens"] = max_completion_tokens
        if temperature is not OMIT:
            _request["temperature"] = temperature
        if top_p is not OMIT:
            _request["top_p"] = top_p
        if presence_penalty is not OMIT:
            _request["presence_penalty"] = presence_penalty
        if frequency_penalty is not OMIT:
            _request["frequency_penalty"] = frequency_penalty
        if stop is not OMIT:
            _request["stop"] = stop
        if response_format is not OMIT:
            _request["response_format"] = response_format
        if logprobs is not OMIT:
            _request["logprobs"] = logprobs
        if top_logprobs is not OMIT:
            _request["top_logprobs"] = top_logprobs
        if stream_options is not OMIT:
            _request["stream_options"] = stream_options
        if store is not OMIT:
            _request["store"] = store
        if metadata is not OMIT:
            _request["metadata"] = metadata
        if stream is not OMIT:
            _request["stream"] = stream
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "chat/completions"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CreateChatCompletionResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def report(
        self,
        *,
        requested_at: typing.Optional[float] = OMIT,
        received_at: typing.Optional[float] = OMIT,
        req_payload: typing.Optional[typing.Any] = OMIT,
        resp_payload: typing.Optional[typing.Any] = OMIT,
        status_code: typing.Optional[float] = OMIT,
        error_message: typing.Optional[str] = OMIT,
        tags: typing.Optional[typing.Dict[str, ReportRequestTagsValue]] = OMIT,
    ) -> ReportResponse:
        """
        Record request logs from OpenAI models

        Parameters:
            - requested_at: typing.Optional[float]. Unix timestamp in milliseconds

            - received_at: typing.Optional[float]. Unix timestamp in milliseconds

            - req_payload: typing.Optional[typing.Any].

            - resp_payload: typing.Optional[typing.Any].

            - status_code: typing.Optional[float]. HTTP status code of response

            - error_message: typing.Optional[str]. User-friendly error message

            - tags: typing.Optional[typing.Dict[str, ReportRequestTagsValue]]. DEPRECATED: use "reqPayload.metadata" to attach extra metadata tags to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }
        ---
        from OpenPipe.client import AsyncOpenPipeApi

        client = AsyncOpenPipeApi(
            token="YOUR_TOKEN",
        )
        await client.report()
        """
        _request: typing.Dict[str, typing.Any] = {}
        if requested_at is not OMIT:
            _request["requestedAt"] = requested_at
        if received_at is not OMIT:
            _request["receivedAt"] = received_at
        if req_payload is not OMIT:
            _request["reqPayload"] = req_payload
        if resp_payload is not OMIT:
            _request["respPayload"] = resp_payload
        if status_code is not OMIT:
            _request["statusCode"] = status_code
        if error_message is not OMIT:
            _request["errorMessage"] = error_message
        if tags is not OMIT:
            _request["tags"] = tags
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "report"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ReportResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def report_anthropic(
        self,
        *,
        requested_at: typing.Optional[float] = OMIT,
        received_at: typing.Optional[float] = OMIT,
        req_payload: typing.Optional[ReportAnthropicRequestReqPayload] = OMIT,
        resp_payload: typing.Optional[ReportAnthropicRequestRespPayload] = OMIT,
        status_code: typing.Optional[float] = OMIT,
        error_message: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, str]] = OMIT,
        tags: typing.Optional[typing.Dict[str, ReportAnthropicRequestTagsValue]] = OMIT,
    ) -> ReportAnthropicResponse:
        """
        Record request logs from Anthropic models

        Parameters:
            - requested_at: typing.Optional[float]. Unix timestamp in milliseconds

            - received_at: typing.Optional[float]. Unix timestamp in milliseconds

            - req_payload: typing.Optional[ReportAnthropicRequestReqPayload]. JSON-encoded request payload

            - resp_payload: typing.Optional[ReportAnthropicRequestRespPayload]. JSON-encoded response payload

            - status_code: typing.Optional[float]. HTTP status code of response

            - error_message: typing.Optional[str]. User-friendly error message

            - metadata: typing.Optional[typing.Dict[str, str]]. Extra metadata tags to attach to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }

            - tags: typing.Optional[typing.Dict[str, ReportAnthropicRequestTagsValue]]. Deprecated: use "metadata" instead
        ---
        from OpenPipe.client import AsyncOpenPipeApi

        client = AsyncOpenPipeApi(
            token="YOUR_TOKEN",
        )
        await client.report_anthropic()
        """
        _request: typing.Dict[str, typing.Any] = {}
        if requested_at is not OMIT:
            _request["requestedAt"] = requested_at
        if received_at is not OMIT:
            _request["receivedAt"] = received_at
        if req_payload is not OMIT:
            _request["reqPayload"] = req_payload
        if resp_payload is not OMIT:
            _request["respPayload"] = resp_payload
        if status_code is not OMIT:
            _request["statusCode"] = status_code
        if error_message is not OMIT:
            _request["errorMessage"] = error_message
        if metadata is not OMIT:
            _request["metadata"] = metadata
        if tags is not OMIT:
            _request["tags"] = tags
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "report-anthropic"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ReportAnthropicResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_log_tags(
        self,
        *,
        filters: typing.List[UpdateLogTagsRequestFiltersItem],
        tags: typing.Dict[str, UpdateLogTagsRequestTagsValue],
    ) -> UpdateLogTagsResponse:
        """
        DEPRECATED: use "/logs/update-metadata" instead

        Parameters:
            - filters: typing.List[UpdateLogTagsRequestFiltersItem].

            - tags: typing.Dict[str, UpdateLogTagsRequestTagsValue]. Extra tags to attach to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "logs/update-tags"),
            json=jsonable_encoder({"filters": filters, "tags": tags}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UpdateLogTagsResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_log_metadata(
        self,
        *,
        filters: typing.List[UpdateLogMetadataRequestFiltersItem],
        metadata: typing.Dict[str, UpdateLogMetadataRequestMetadataValue],
    ) -> UpdateLogMetadataResponse:
        """
        Update tags metadata for logged calls matching the provided filters.

        Parameters:
            - filters: typing.List[UpdateLogMetadataRequestFiltersItem].

            - metadata: typing.Dict[str, UpdateLogMetadataRequestMetadataValue]. Extra metadata to attach to the call for filtering. Eg { "userId": "123", "prompt_id": "populate-title" }
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "logs/update-metadata"),
            json=jsonable_encoder({"filters": filters, "metadata": metadata}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UpdateLogMetadataResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def local_testing_only_get_latest_logged_call(
        self,
    ) -> typing.Optional[LocalTestingOnlyGetLatestLoggedCallResponse]:
        """
        Get the latest logged call (only for local testing)
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", "local-testing-only-get-latest-logged-call"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Optional[LocalTestingOnlyGetLatestLoggedCallResponse], _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_criterion_judgement(
        self,
        *,
        criterion_id: str,
        input: typing.Optional[GetCriterionJudgementRequestInput] = OMIT,
        output: GetCriterionJudgementRequestOutput,
    ) -> GetCriterionJudgementResponse:
        """
        Get a judgement of a completion against the specified criterion

        Parameters:
            - criterion_id: str. The ID of the criterion to judge.

            - input: typing.Optional[GetCriterionJudgementRequestInput].

            - output: GetCriterionJudgementRequestOutput. The completion message of the model.
        """
        _request: typing.Dict[str, typing.Any] = {"criterion_id": criterion_id, "output": output}
        if input is not OMIT:
            _request["input"] = input
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "criteria/judge"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(GetCriterionJudgementResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_datasets(self) -> ListDatasetsResponse:
        """
        List datasets for a project.

        ---
        from OpenPipe.client import AsyncOpenPipeApi

        client = AsyncOpenPipeApi(
            token="YOUR_TOKEN",
        )
        await client.list_datasets()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "datasets"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ListDatasetsResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_dataset(self, *, name: str) -> CreateDatasetResponse:
        """
        Create a new dataset.

        Parameters:
            - name: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "datasets"),
            json=jsonable_encoder({"name": name}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CreateDatasetResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_dataset(self, dataset_id: str) -> DeleteDatasetResponse:
        """
        Delete a dataset.

        Parameters:
            - dataset_id: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"datasets/{dataset_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DeleteDatasetResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_dataset_entries(
        self, dataset_id: str, *, entries: typing.List[CreateDatasetEntriesRequestEntriesItem]
    ) -> CreateDatasetEntriesResponse:
        """
        Add new dataset entries.

        Parameters:
            - dataset_id: str.

            - entries: typing.List[CreateDatasetEntriesRequestEntriesItem].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"datasets/{dataset_id}/entries"),
            json=jsonable_encoder({"entries": entries}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CreateDatasetEntriesResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_models(self) -> ListModelsResponse:
        """
        List all models for a project.

        ---
        from OpenPipe.client import AsyncOpenPipeApi

        client = AsyncOpenPipeApi(
            token="YOUR_TOKEN",
        )
        await client.list_models()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "models"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ListModelsResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_model(
        self,
        *,
        dataset_id: str,
        slug: str,
        pruning_rule_ids: typing.Optional[typing.List[str]] = OMIT,
        training_config: CreateModelRequestTrainingConfig,
        default_temperature: typing.Optional[float] = OMIT,
    ) -> CreateModelResponse:
        """
        Train a new model.

        Parameters:
            - dataset_id: str.

            - slug: str.

            - pruning_rule_ids: typing.Optional[typing.List[str]].

            - training_config: CreateModelRequestTrainingConfig.

            - default_temperature: typing.Optional[float].
        """
        _request: typing.Dict[str, typing.Any] = {
            "datasetId": dataset_id,
            "slug": slug,
            "trainingConfig": training_config,
        }
        if pruning_rule_ids is not OMIT:
            _request["pruningRuleIds"] = pruning_rule_ids
        if default_temperature is not OMIT:
            _request["defaultTemperature"] = default_temperature
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "models"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(CreateModelResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_model(self, model_slug: str) -> GetModelResponse:
        """
        Get a model by ID.

        Parameters:
            - model_slug: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"models/{model_slug}"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(GetModelResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_model(self, model_slug: str) -> DeleteModelResponse:
        """
        Delete an existing model.

        Parameters:
            - model_slug: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"models/{model_slug}"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DeleteModelResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def unstable_dataset_create(self, *, name: str) -> UnstableDatasetCreateResponse:
        """
        DEPRECATED: use the `/datasets` endpoint instead

        Parameters:
            - name: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/dataset/create"),
            json=jsonable_encoder({"name": name}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableDatasetCreateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def unstable_dataset_delete(self, *, dataset_id: str) -> UnstableDatasetDeleteResponse:
        """
        DEPRECATED: use the `/datasets/{dataset}` endpoint instead

        Parameters:
            - dataset_id: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/dataset/delete"),
            json=jsonable_encoder({"datasetId": dataset_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableDatasetDeleteResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def unstable_dataset_list(self) -> typing.List[UnstableDatasetListResponseItem]:
        """
        DEPRECATED: use the `/datasets` endpoint instead

        ---
        from OpenPipe.client import AsyncOpenPipeApi

        client = AsyncOpenPipeApi(
            token="YOUR_TOKEN",
        )
        await client.unstable_dataset_list()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/dataset/list"),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[UnstableDatasetListResponseItem], _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def unstable_dataset_entry_create(
        self, *, dataset_id: str, entries: typing.List[UnstableDatasetEntryCreateRequestEntriesItem]
    ) -> UnstableDatasetEntryCreateResponse:
        """
        DEPRECATED: use the `/datasets/{dataset}/entries` endpoint instead

        Parameters:
            - dataset_id: str.

            - entries: typing.List[UnstableDatasetEntryCreateRequestEntriesItem].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/dataset-entry/create"),
            json=jsonable_encoder({"datasetId": dataset_id, "entries": entries}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableDatasetEntryCreateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def unstable_finetune_create(
        self,
        *,
        dataset_id: str,
        slug: str,
        base_model: str,
        overrides: typing.Optional[UnstableFinetuneCreateRequestOverrides] = OMIT,
    ) -> UnstableFinetuneCreateResponse:
        """
        DEPRECATED

        Parameters:
            - dataset_id: str.

            - slug: str.

            - base_model: str. The base model to fine-tune from. Supported models include: meta-llama/Meta-Llama-3.1-8B-Instruct, meta-llama/Meta-Llama-3.1-70B-Instruct

            - overrides: typing.Optional[UnstableFinetuneCreateRequestOverrides].
        """
        _request: typing.Dict[str, typing.Any] = {"datasetId": dataset_id, "slug": slug, "baseModel": base_model}
        if overrides is not OMIT:
            _request["overrides"] = overrides
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/finetune/create"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableFinetuneCreateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def unstable_finetune_get(
        self, *, id: typing.Optional[str] = None, slug: typing.Optional[str] = None
    ) -> UnstableFinetuneGetResponse:
        """
        DEPRECATED: use the `/models/{model}` endpoint instead

        Parameters:
            - id: typing.Optional[str].

            - slug: typing.Optional[str].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/finetune/get"),
            params=remove_none_from_dict({"id": id, "slug": slug}),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableFinetuneGetResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def unstable_finetune_delete(
        self, *, id: typing.Optional[str] = OMIT, slug: typing.Optional[str] = OMIT
    ) -> UnstableFinetuneDeleteResponse:
        """
        DEPRECATED: use the `/models/{model}` endpoint instead

        Parameters:
            - id: typing.Optional[str].

            - slug: typing.Optional[str].
        """
        _request: typing.Dict[str, typing.Any] = {}
        if id is not OMIT:
            _request["id"] = id
        if slug is not OMIT:
            _request["slug"] = slug
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "unstable/finetune/delete"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=240,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(UnstableFinetuneDeleteResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


def _get_base_url(*, base_url: typing.Optional[str] = None, environment: OpenPipeApiEnvironment) -> str:
    if base_url is not None:
        return base_url
    elif environment is not None:
        return environment.value
    else:
        raise Exception("Please pass in either base_url or environment to construct the client")
