import asyncio
import os

import constants
import streamlit as st
from annotated_types import T
from constants import QUICK_EXAMPLE_PROBLEMS
from csp_tools import CSPExtractor, CSPGenerator, MCPCSPRunner
from llm_provider import LLMStudioProvider, OllamaProvider
from streamlit_ace import st_ace


def initialize_components():

    # Initialize components
    if "code_generator" not in st.session_state:
        st.session_state.code_generator = CSPGenerator(
            st.session_state.model, st.session_state.brand, st.session_state.environment
        )
    if len(st.session_state.code_generator.get_error_messages()) != 0:
        for msg in st.session_state.code_generator.get_error_messages():
            st.warning(msg)
        st.stop()

    if "mcp_runner" not in st.session_state:
        st.session_state.mcp_runner = MCPCSPRunner()

    if "extractor" not in st.session_state:
        st.session_state.extractor = CSPExtractor()

    if "problem_value" not in st.session_state:
        st.session_state.problem_value = ""

    # Variables pour d√©tecter les changements
    if "last_selection" not in st.session_state:
        st.session_state.last_selection = ""
    if "last_uploaded_file" not in st.session_state:
        st.session_state.last_uploaded_file = None
    if "problem_label" not in st.session_state:
        st.session_state.problem_label = ""
    if "temperature" not in st.session_state:
        st.session_state.temperature = 0.8
    if "max_tokens" not in st.session_state:
        st.session_state.max_tokens = 4000
    if "running_timeout" not in st.session_state:
        st.session_state.running_timeout = 300


def handle_model_selection() -> None:

    selected_model = st.session_state["model_key"]

    if st.session_state.environment == constants.ENVIRONMENTS[2]:
        parse_split = selected_model.split("[")
        model = parse_split[1].replace("]", "").strip()
        brand = parse_split[0].strip()
    else:
        model = selected_model
        brand = st.session_state.environment

    print(20 * "=", model, brand)
    st.session_state.code_generator = CSPGenerator(
        model, brand, st.session_state.environment
    )


def main():
    if "environment" not in st.session_state:
        st.session_state.environment = os.environ["LLM_ENV"]

    st.set_page_config(
        page_title="CSP Problem Solver with LLM", page_icon="üíª", layout="wide"
    )

    st.markdown(
        r"""
    <style>
    .stAppDeployButton {
            visibility: hidden;
        }
    </style>
    """,
        unsafe_allow_html=True,
    )

    st.title("üíª Constraint Programming with LLM")
    st.markdown("Solve constraint programming problems using LLM")
    st.success(f"üí° LLM environment : { str.upper(st.session_state.environment)}")

    st.sidebar.header("‚öôÔ∏è Configuration")

    st.sidebar.subheader("Model parameters")

    if st.session_state.environment == constants.ENVIRONMENTS[2]:
        model = st.sidebar.selectbox(
            "Model",
            constants.MODELS,
            index=0,
            key="model_key",
            on_change=handle_model_selection,
        )

    elif st.session_state.environment == constants.ENVIRONMENTS[0]:
        try:
            msg, models = asyncio.run(OllamaProvider().get_models())
            if msg != "Ok":
                st.error(msg)
                st.stop()
            else:
                model = st.sidebar.selectbox(
                    "Model",
                    models,
                    index=0,
                    key="model_key",
                    on_change=handle_model_selection,
                )
        except Exception as e:
            st.error(
                "Unable to connect to your local OLLAMA.\n\n Make sure you have installed it and the api endpoint http://localhost:11434/ is enabled"
            )
            st.info("[Install Ollama](https://ollama.com)")
            st.stop()
    else:
        try:
            msg, models = asyncio.run(LLMStudioProvider().get_models())
            if msg != "Ok":
                st.error(msg)
                st.stop()
            else:
                model = st.sidebar.selectbox(
                    "Model",
                    models,
                    index=0,
                    key="model_key",
                    on_change=handle_model_selection,
                )
        except Exception as e:
            st.error(
                "Unable to connect to your LMSTUDIO.\n\n Make sure you have installed it and the api endpoint http://localhost:1234/ is enabled"
            )
            st.info("[Install LM Studio](https://lmstudio.ai/)")
            st.stop()

    if st.session_state.environment == constants.ENVIRONMENTS[2]:
        parse_split = model.split("[")
        st.session_state.model = parse_split[1].replace("]", "").strip()
        st.session_state.brand = parse_split[0].strip()
    else:
        st.session_state.model = model
        st.session_state.brand = st.session_state.environment

    st.sidebar.divider()

    initialize_components()

    temperature = st.sidebar.slider(
        "Temperature",
        0.0,
        2.0,
        st.session_state.temperature,
        0.1,
        help="Controls creativity (0 = deterministic, 2 = very creative)",
    )
    st.session_state.temperature = temperature

    max_tokens = st.sidebar.slider(
        "Max Tokens",
        1000,
        5000,
        st.session_state.max_tokens,
        100,
        help="Maximum number of tokens in the response",
    )
    st.session_state.max_tokens = max_tokens

    running_timeout = st.sidebar.number_input(
        "Running timeout(s)",
        value=st.session_state.running_timeout,
        help="Program execution timeout in seconds",
    )
    st.session_state.running_timeout = running_timeout

    st.sidebar.write(f"{round(running_timeout/60,2)} in minutes")

    st.sidebar.divider()
    st.empty()
    st.empty()
    st.empty()

    st.sidebar.link_button(
        "üö® Report an issue",
        "mailto:kemgue@cril.fr?subject=Report an issue in csp llm app",
    )

    st.divider()

    st.subheader(
        f"Selected model is :green[*{str.upper(st.session_state.model)}*] from :green[*{str.upper(st.session_state.brand)}*] provider"
    )

    # Main interface
    col1, col2 = st.columns([1, 1])

    with col1:
        selected_example = st.selectbox(
            "Choose an example or custom:",
            list(constants.EXAMPLE_PROBLEMS.keys()),
            index=0,
            key="problem_selector",
            help="Select an problem example",
        )

        uploaded_txt_file = st.file_uploader(
            "Choose a problem file",
            type=["txt", "md"],
            key="file_uploader",
            help="Upload a problem description from a file",
        )

        # select and upload logic

        content_updated = False

        # Is new selection done ?
        if selected_example != st.session_state.last_selection:
            if selected_example != "Custom":
                st.session_state.problem_value = constants.EXAMPLE_PROBLEMS[
                    selected_example
                ]

                st.session_state.problem_label = "Problem Description:"
                content_updated = True
            else:
                st.session_state.problem_value = ""
                st.session_state.problem_label = (
                    "Describe your constraint programming problem:"
                )
                content_updated = True

            st.session_state.last_selection = selected_example

        # Is new file uploaded ?
        elif (
            uploaded_txt_file is not None
            and uploaded_txt_file != st.session_state.last_uploaded_file
        ):
            try:
                file_content = uploaded_txt_file.read().decode("utf-8")
                st.session_state.problem_value = file_content
                content_updated = True
                st.session_state.problem_label = f"A constraint programming problem from file {uploaded_txt_file.name}"

                # not necessary
                # uploaded_txt_file.seek(0)

            except Exception as e:
                st.error(f"‚ùå Unexpected error: {str(e)}")

            st.session_state.last_uploaded_file = uploaded_txt_file

        # ===================

        st.header("Problem Description")
        tab1, tab2 = st.tabs(["üìù Problem description", "üìñ Preview Markdown"])

        with tab1:
            problem_description = st.text_area(
                st.session_state.problem_label,
                value=st.session_state.problem_value,
                height=160,
                placeholder="Example: Place 4 queens on a 4x4 chessboard...",
                key="problem_key",
            )

        with tab2:
            st.markdown("**Preview Markdown:**")
            st.markdown(problem_description)

        if st.button("ü§ñ Generate CSP Code with LLM", type="primary"):
            if problem_description:
                # Streaming mode with proper async handling
                st.markdown("### üîÑ LLM is generating code...")
                streaming_container = st.container()

                async def run_streaming_generation():
                    return await st.session_state.code_generator.generate_csp_code_stream_async(
                        problem_description, streaming_container
                    )

                # Execute the async streaming function
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    with st.spinner("ü§î LLM is generating..."):
                        llm_response = loop.run_until_complete(
                            run_streaming_generation()
                        )

                    # Extract PyCSP3 code
                    extracted_code = st.session_state.extractor.extract_pycsp3_code(
                        llm_response
                    )

                    # Store in session state
                    st.session_state.generated_code = extracted_code
                    st.session_state.llm_response = llm_response

                    st.success("‚úÖ Code generated successfully!")
                except Exception as e:
                    st.error(f"‚ùå Generation failed: {str(e)}")
                finally:
                    loop.close()

            else:
                st.error("Please enter a problem description.")

    with col2:
        st.header("Generated PyCSP3 Code")

        if "generated_code" in st.session_state:
            # Show final generated code in a clean format
            st.subheader("üìã Final Generated Code")
            # st.code(st.session_state.generated_code, language="python")
            theme_editor = st.selectbox(
                "üé® Th√®me:",
                [
                    "twilight",
                    "terminal",
                    "dracula",
                    "tomorrow",
                    "xcode",
                    "solarized_dark",
                    "vibrant_ink",
                ],
                index=0,
            )

            code = st_ace(
                value=st.session_state.generated_code,
                language="python",
                theme=theme_editor,
                show_gutter=True,  # Affiche les num√©ros de ligne
                show_print_margin=True,
                wrap=False,
                font_size=14,
                height=400,
                readonly=True,
            )

            # Show raw LLM response in expander
            with st.expander("ü§ñ View Full LLM Response"):
                st.text(st.session_state.llm_response)

            # Edit code option
            if st.checkbox("‚úèÔ∏è Edit code before execution"):
                edited_code = st_ace(
                    value=st.session_state.generated_code,
                    language="python",
                    theme=theme_editor,
                    key="code_editor",
                    height=400,
                    font_size=14,
                    auto_update=True,
                    annotations=None,
                    markers=None,
                )
                execution_code = edited_code
            else:
                execution_code = st.session_state.generated_code

            # Execution controls
            st.subheader("üöÄ Execution Controls")

            col2_1, col2_2, col2_3 = st.columns([1, 1, 1])

            with col2_1:
                if st.button("üîß Execute via MCP", type="secondary"):
                    with st.spinner("Executing CSP code via MCP..."):
                        # Create real-time execution container
                        execution_container = st.container()
                        execution_status = execution_container.empty()
                        execution_progress = execution_container.progress(0)

                        # Update progress
                        execution_status.info("üîÑ Initializing MCP runner...")
                        execution_progress.progress(25)

                        # Run code through MCP
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)

                        try:
                            # Initialize MCP if needed
                            execution_status.info("üîÑ Setting up MCP session...")
                            execution_progress.progress(50)

                            if (
                                not hasattr(st.session_state.mcp_runner, "session")
                                or not st.session_state.mcp_runner.session
                            ):
                                loop.run_until_complete(
                                    st.session_state.mcp_runner.initialize_mcp()
                                )

                            # Execute code
                            execution_status.info("üîÑ Executing CSP code...")
                            execution_progress.progress(75)

                            result = loop.run_until_complete(
                                st.session_state.mcp_runner.run_csp_code(execution_code)
                            )

                            execution_progress.progress(100)
                            execution_status.success("‚úÖ Execution completed!")

                            st.session_state.execution_result = result

                        except Exception as e:
                            execution_status.error(f"‚ùå Execution failed: {str(e)}")
                            st.session_state.execution_result = {
                                "success": False,
                                "output": "",
                                "error": str(e),
                                "code": execution_code,
                            }
                        finally:
                            loop.close()

            with col2_2:
                if st.button("üíæ Save Code"):
                    # Create download link for the code
                    st.download_button(
                        label="üì• Download PyCSP3 Code",
                        data=execution_code,
                        file_name=f"csp_problem_{len(execution_code)}.py",
                        mime="text/plain",
                    )

            with col2_3:
                if st.button("üîÑ Reset"):
                    # Clear session state
                    for key in [
                        "generated_code",
                        "llm_response",
                        "execution_result",
                    ]:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.rerun()

        else:
            st.info("üí° Tips to use:")
            st.info(
                "üëà The description of a problem for which you want to generate code in PyCSP3 is in natural language\n\n"
                "üëà On the left, you can select, an example problem or select **custom** to describe your problem in the text box\n\n"
                "üëà On the left, you can browse a markdown file containing the description of a constraint problem in natural language"
            )

            # Show placeholder for streaming
            if st.session_state.get("show_streaming_placeholder", True):
                st.markdown("### üîÑ Response Preview")
                st.code(
                    "# LLM's response will appear here in real-time...",
                    language="python",
                )

    # Results section
    if "execution_result" in st.session_state:
        st.header("üéØ Execution Results")

        result = st.session_state.execution_result

        # Create columns for results
        result_col1, result_col2 = st.columns([2, 1])

        with result_col1:
            if result["success"]:
                st.success("‚úÖ Code executed successfully!")

                if result["output"]:
                    st.subheader("üìä Solution Output:")
                    # Try to format the output nicely
                    output_lines = result["output"].strip().split("\n")
                    for line in output_lines:
                        if line.strip():
                            if "Solution:" in line or "Result:" in line:
                                st.markdown(f"**{line}**")
                            else:
                                st.text(line)
                else:
                    st.info("Code executed but produced no output.")
            else:
                st.error("‚ùå Execution failed!")

                if result["error"]:
                    st.subheader("üö® Error Details:")
                    st.code(result["error"], language="text")

        with result_col2:
            # Execution metrics
            st.subheader("üìà Execution Info")

            # Create metrics
            if result["success"]:
                st.metric("Status", "‚úÖ Success", delta="Solved")
            else:
                st.metric("Status", "‚ùå Failed", delta="Error")

            # Code length metric
            code_lines = len(result["code"].split("\n"))
            st.metric("Code Lines", code_lines)

            # Show execution time if available (placeholder)
            st.metric("Runtime", "< 1s", delta="Fast")

        # Show detailed execution info in expander
        with st.expander("üîç Detailed Execution Information"):
            st.json(
                {
                    "success": result["success"],
                    "output_length": len(result["output"]) if result["output"] else 0,
                    "error_present": bool(result["error"]),
                    "code_length": len(result["code"]),
                }
            )

            # Show the actual executed code
            st.subheader("Executed Code:")
            st.code(result["code"], language="python")

    # Real-time streaming demo section
    st.markdown("---")
    st.header("üîÑ Real-time generation demo")

    demo_col1, demo_col2 = st.columns([1, 1])

    with demo_col1:
        st.subheader("Try Quick Examples")

        selected_quick = st.selectbox(
            "Quick examples:", ["Select..."] + list(QUICK_EXAMPLE_PROBLEMS.keys())
        )

        if selected_quick != "Select..." and st.button("üöÄ Generate Quickly"):
            # st.session_state.show_streaming_placeholder = True
            # Auto-fill and trigger generation

            if selected_quick in QUICK_EXAMPLE_PROBLEMS:
                with st.container():
                    st.markdown("### üîÑ Streaming LLM's Response...")
                    streaming_container = st.container()

                    # Run async streaming in a proper event loop
                    async def run_quick_generation():
                        return await st.session_state.code_generator.generate_csp_code_stream_async(
                            QUICK_EXAMPLE_PROBLEMS[selected_quick], streaming_container
                        )

                    # Execute the async function
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        llm_response = loop.run_until_complete(run_quick_generation())

                        extracted_code = st.session_state.extractor.extract_pycsp3_code(
                            llm_response
                        )
                        st.session_state.generated_code = extracted_code
                        st.session_state.llm_response = llm_response

                        st.success("‚úÖ Quick example generated!")
                    finally:
                        loop.close()
