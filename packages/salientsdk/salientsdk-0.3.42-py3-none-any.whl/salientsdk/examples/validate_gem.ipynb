{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate GEM Skill\n",
    "\n",
    "This example shows how to evaluate Salient's native daily GEM forecasts and calculate meaningful metrics. It demonstrates [validation best practices](https://salientpredictions.notion.site/Validation-0220c48b9460429fa86f577914ea5248) such as:\n",
    "\n",
    "- Proper scoring using the Ensemble Continuous Ranked Probability Score (CRPS)\n",
    "- Considers the full forecast distribution to reward both accuracy and precision\n",
    "- Less sensitive to climatology decisions than metrics like Anomaly Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests.sessions.Session at 0x7fccdac77cd0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from reprlib import repr as rrepr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import salientsdk as sk\n",
    "except ModuleNotFoundError as e:\n",
    "    if os.path.exists(\"../salientsdk\"):\n",
    "        sys.path.append(os.path.abspath(\"..\"))\n",
    "        import salientsdk as sk\n",
    "    else:\n",
    "        raise ModuleNotFoundError(\"Install salient SDK with: pip install salientsdk\")\n",
    "\n",
    "# Prevent wrapping on tables for readability\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "sk.set_file_destination(\"validate_gem_example\")\n",
    "sk.login(\"SALIENT_USERNAME\", \"SALIENT_PASSWORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize The Validation\n",
    "\n",
    "This notebook is written flexibly so you have the option of validating Salient and other forecasts multiple ways. These variables will control what, when, and how the validation proceeds.\n",
    "\n",
    "More information on available hindcast dates is available in the [salient documentation](https://salientpredictions.notion.site/Hindcasts-18fc9d5a921b8073a781e599e6d46be3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast dates to test [4]: ['2020-10-16', '2022-04-12', '2023-10-08', '2025-04-04']\n"
     ]
    }
   ],
   "source": [
    "# 1. The meteorological variable that we'll be evaluating:\n",
    "var = \"tmax\"\n",
    "\n",
    "# 2. Set the number of forecast samples to download:\n",
    "(start_date, end_date) = (\"2020-10-16\", \"2025-04-04\")\n",
    "count_date = 4  # Get a few date samples from the range for a fast proof-of-concept\n",
    "# count_date = 256 # Get a healthy range of samples for a good but still quick test\n",
    "# count_date = None # get all available date samples (N=1632) from the range for a comprehensive test\n",
    "\n",
    "# 3. The reference model to compare Salient GEM to\n",
    "# ref_model = None  # skip the reference model comparison\n",
    "ref_model = \"noaa_gefs\"\n",
    "# ref_model = \"ecmwf_ens\"\n",
    "# ref_model = \"gem\"\n",
    "\n",
    "# ===== Additional shared variables ==========================\n",
    "# Not recommended to change these.\n",
    "\n",
    "debias = False\n",
    "gem_model = \"gem\"\n",
    "gem_name = gem_model.replace(\"_\", \" \").upper()\n",
    "ref_name = ref_model.replace(\"_\", \" \").upper()\n",
    "leads = {\"noaa_gefs\": 35, \"ecmwf_ens\": 42, \"gem\": 50, None: None}[ref_model]\n",
    "freq = \"daily\"\n",
    "force = False  # Cache data to save on repeat API calls\n",
    "verbose = False  # Show diagnostic details\n",
    "figsize = (8, 5)  # Make all figures have a consistent size\n",
    "poc_warn = f\"INDICATIVE (N={count_date}) \" if count_date < 128 else \"\"\n",
    "\n",
    "\n",
    "# Determine which dates for which to request forecasts:\n",
    "if ref_model == \"ecmwf_ens\":\n",
    "    date_range = sk.get_hindcast_dates(\n",
    "        start_date=start_date, end_date=end_date, timescale=ref_model, extend=True\n",
    "    )\n",
    "    date_range = pd.to_datetime(date_range)\n",
    "else:\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "\n",
    "if count_date is not None and len(date_range) > count_date:\n",
    "    date_range = date_range[np.linspace(0, len(date_range) - 1, count_date, dtype=int)]\n",
    "\n",
    "date_range = date_range.strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "print(f\"Forecast dates to test [{len(date_range)}]: {rrepr(date_range)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Area of Interest\n",
    "\n",
    "The Salient SDK uses a \"Location\" object to specify the geographic bounds of a request. In this case, we will be validating against the vector of airport locations that are used to settle the Chicago Mercantile Exchange's Cooling and Heating Degree Day contracts. With `load_location_file` we can see that the file contains:\n",
    "\n",
    "- `lat` / `lon`: latitude and longitude of the met station, standard for a `location_file`\n",
    "- `name`: the 3-letter IATA airport code of the location, also `location_file` standard\n",
    "- `ghcnd`: the global climate network ID of the station, used to validate against observations. To customize this analysis for any set of observation stations, use the NCEI [stations list](https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt).\n",
    "- `cme`: the CME code for the location used to create CDD/HDD strip codes.\n",
    "- `description`: full name of the airport\n",
    "\n",
    "If you have a list of locations already defined in a separate CSV file, you can use [`upload_file`](https://sdk.salientpredictions.com/api/#salientsdk.upload_file) to upload the file directly without building it in code via `upload_location_file`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lat        lon name        ghcnd cme                description                     geometry\n",
      "0   33.62972  -84.44224  ATL  USW00013874   1         Atlanta Hartsfield   POINT (-84.44224 33.62972)\n",
      "1   42.36057  -71.00975  BOS  USW00014739   W               Boston Logan   POINT (-71.00975 42.36057)\n",
      "2   34.19966 -118.36543  BUR  USW00023152   P  Burbank-Glendale-Pasadena  POINT (-118.36543 34.19966)\n",
      "3   41.96017  -87.93164  ORD  USW00094846   2             Chicago O'Hare   POINT (-87.93164 41.96017)\n",
      "4   39.04443  -84.67241  CVG  USW00093814   3     Cincinnati (Covington)   POINT (-84.67241 39.04443)\n",
      "5   32.89744  -97.02196  DFW  USW00003927   5          Dallas-Fort Worth   POINT (-97.02196 32.89744)\n",
      "6   29.98438  -95.36072  IAH  USW00012960   R        Houston-George Bush   POINT (-95.36072 29.98438)\n",
      "7   36.07190 -115.16343  LAS  USW00023169   0         Las Vegas McCarran   POINT (-115.16343 36.0719)\n",
      "8   44.88523  -93.23133  MSP  USW00014922   Q         Minneapolis-StPaul   POINT (-93.23133 44.88523)\n",
      "9   40.77945  -73.88027  LGA  USW00014732   4        New York La Guardia   POINT (-73.88027 40.77945)\n",
      "10  39.87326  -75.22681  PHL  USW00013739   6               Philadelphia   POINT (-75.22681 39.87326)\n",
      "11  45.59578 -122.60919  PDX  USW00024229   7                   Portland  POINT (-122.60919 45.59578)\n",
      "12  38.50659 -121.49604  SAC  USW00023232   S            Sacramento Exec  POINT (-121.49604 38.50659)\n"
     ]
    }
   ],
   "source": [
    "# fmt: off\n",
    "loc = sk.Location(location_file=sk.upload_location_file(\n",
    "    lats =[33.62972     ,      42.36057,      34.19966,      41.96017,      39.04443,      32.89744,      29.98438,      36.07190,      44.88523,      40.77945,      39.87326,      45.59578,      38.50659],\n",
    "    lons =[-84.44224    ,     -71.00975,    -118.36543,     -87.93164,     -84.67241,     -97.02196,     -95.36072,    -115.16343,     -93.23133,     -73.88027,     -75.22681,    -122.60919,    -121.49604],\n",
    "    names=[\"ATL\"        ,         \"BOS\",         \"BUR\",         \"ORD\",         \"CVG\",         \"DFW\",         \"IAH\",         \"LAS\",         \"MSP\",         \"LGA\",         \"PHL\",         \"PDX\",         \"SAC\"],\n",
    "    ghcnd=[\"USW00013874\", \"USW00014739\", \"USW00023152\", \"USW00094846\", \"USW00093814\", \"USW00003927\", \"USW00012960\", \"USW00023169\", \"USW00014922\", \"USW00014732\", \"USW00013739\", \"USW00024229\", \"USW00023232\"],\n",
    "    cme  =[\"1\"          ,           \"W\",           \"P\",           \"2\",           \"3\",           \"5\",           \"R\",           \"0\",           \"Q\",           \"4\",           \"6\",           \"7\",           \"S\"],\n",
    "    geoname=\"cmeus\",\n",
    "    force=force,\n",
    "    description=[\"Atlanta Hartsfield\", \"Boston Logan\", \"Burbank-Glendale-Pasadena\", \"Chicago O'Hare\", \"Cincinnati (Covington)\",\"Dallas-Fort Worth\", \"Houston-George Bush\", \"Las Vegas McCarran\", \"Minneapolis-StPaul\", \"New York La Guardia\",\"Philadelphia\", \"Portland\", \"Sacramento Exec\"],\n",
    "))\n",
    "# fmt: on\n",
    "stations = loc.load_location_file()\n",
    "print(stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Forecasts\n",
    "\n",
    "The [`forecast_timeseries`](https://api.salientpredictions.com/v2/documentation/api/#/Forecasts/forecast_timeseries) API endpoint and SDK function gets a forecast from a particular forecast date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 1MB\n",
      "Dimensions:        (forecast_date: 4, lead: 35, location: 13, ensemble: 200)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * ensemble       (ensemble) int64 2kB 0 1 2 3 4 5 ... 194 195 196 197 198 199\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    lat            (location) float64 104B 33.63 42.36 34.2 ... 39.87 45.6 38.51\n",
      "    lon            (location) float64 104B -84.44 -71.01 ... -122.6 -121.5\n",
      "  * location       (location) <U3 156B 'ATL' 'BOS' 'BUR' ... 'PHL' 'PDX' 'SAC'\n",
      "    time           (forecast_date, lead) datetime64[ns] 1kB 2020-10-16 ... 20...\n",
      "Data variables:\n",
      "    vals_ens       (forecast_date, lead, location, ensemble) float32 1MB 21.2...\n"
     ]
    }
   ],
   "source": [
    "fcst_args = dict(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    debias=debias,\n",
    "    field=\"vals_ens\",\n",
    "    date=date_range,\n",
    "    timescale=freq,\n",
    "    leads=leads,\n",
    "    verbose=verbose,\n",
    "    force=force,\n",
    "    strict=False,  # if one downscale call fails, proceed with others\n",
    ")\n",
    "gem_src = sk.forecast_timeseries(model=gem_model, **fcst_args)\n",
    "gem = sk.stack_forecast(gem_src, compute=False)\n",
    "print(gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 228kB\n",
      "Dimensions:        (forecast_date: 4, lead: 35, location: 13, ensemble: 31)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * ensemble       (ensemble) int64 248B 0 1 2 3 4 5 6 ... 24 25 26 27 28 29 30\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    lat            (location) float64 104B 33.63 42.36 34.2 ... 39.87 45.6 38.51\n",
      "    lon            (location) float64 104B -84.44 -71.01 ... -122.6 -121.5\n",
      "  * location       (location) <U3 156B 'ATL' 'BOS' 'BUR' ... 'PHL' 'PDX' 'SAC'\n",
      "    time           (forecast_date, lead) datetime64[ns] 1kB 2020-10-16 ... 20...\n",
      "Data variables:\n",
      "    vals_ens       (forecast_date, lead, location, ensemble) float32 226kB 21...\n"
     ]
    }
   ],
   "source": [
    "if ref_model is not None:\n",
    "    fcst_args[\"debias\"] = False  # GEFS & ENS don't support debiasing\n",
    "    ref_src = sk.forecast_timeseries(model=ref_model, **fcst_args)\n",
    "    ref = sk.stack_forecast(ref_src, compute=False)\n",
    "    print(ref)\n",
    "else:\n",
    "    ref = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Historical Truth\n",
    "\n",
    "Download daily historical values from [`data_timeseries`](https://sdk.salientpredictions.com/api/#salientsdk.data_timeseries) and [`met_observations`](https://api.salientpredictions.com/v2/documentation/api/#/Meteorological%20Stations/met_observations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 15kB\n",
      "Dimensions:        (forecast_date: 4, lead: 35, location: 13)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * location       (location) <U3 156B 'ATL' 'BOS' 'BUR' ... 'PHL' 'PDX' 'SAC'\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "Data variables:\n",
      "    vals_ens       (forecast_date, lead, location) float64 15kB dask.array<chunksize=(1, 35, 13), meta=np.ndarray>\n",
      "Attributes:\n",
      "    long_name:   2 metre temperature\n",
      "    units:       degC\n",
      "    clim_start:  1990-01-01\n",
      "    clim_end:    2019-12-31\n"
     ]
    }
   ],
   "source": [
    "hist_args = {\n",
    "    \"loc\": loc,\n",
    "    \"start\": np.datetime64(start_date) - np.timedelta64(5, \"D\"),\n",
    "    \"end\": np.datetime64(end_date) + np.timedelta64(leads + 1, \"D\"),\n",
    "    \"verbose\": verbose,\n",
    "    \"force\": force,\n",
    "}\n",
    "obs_src = sk.met_observations(variables=var, **hist_args)\n",
    "era_src = sk.data_timeseries(variable=var, field=\"vals\", **hist_args)\n",
    "\n",
    "\n",
    "obs = (\n",
    "    sk.stack_history(obs_src, forecast_date=gem.forecast_date, lead=gem.lead, compute=False)\n",
    "    .rename({var: \"vals_ens\"})\n",
    "    .reset_coords(drop=True)\n",
    ")\n",
    "era = (\n",
    "    sk.stack_history(era_src, forecast_date=gem.forecast_date, lead=gem.lead, compute=False)\n",
    "    .rename({\"vals\": \"vals_ens\"})\n",
    "    .reset_coords(drop=True)\n",
    ")\n",
    "print(era)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Skill Metrics\n",
    "\n",
    "Compare the forecast and ERA5 datasets to see how well they match. Here we will calculate the same \"Continuous Ranked Probability Score\" that resulted from the call to `hindcast_summary` earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 20kB\n",
      "Dimensions:        (forecast_date: 4, lead: 35, location: 13)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * location       (location) <U3 156B 'ATL' 'BOS' 'BUR' ... 'PHL' 'PDX' 'SAC'\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    lat            (location) float64 104B 33.63 42.36 34.2 ... 39.87 45.6 38.51\n",
      "    lon            (location) float64 104B -84.44 -71.01 ... -122.6 -121.5\n",
      "    time           (forecast_date, lead) datetime64[ns] 1kB 2020-10-16 ... 20...\n",
      "Data variables:\n",
      "    crps_ens_all   (forecast_date, lead, location) float64 15kB 0.473 ... 2.479\n",
      "    crps_ens       (lead, location) float64 4kB 0.7765 1.101 ... 1.201 1.746\n",
      "Attributes:\n",
      "    short_name:  crps\n",
      "    long_name:   CRPS\n"
     ]
    }
   ],
   "source": [
    "skill_gem = sk.skill.crps_ensemble(observations=era, forecasts=gem)\n",
    "print(skill_gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 20kB\n",
      "Dimensions:        (forecast_date: 4, location: 13, lead: 35)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * location       (location) <U3 156B 'ATL' 'BOS' 'BUR' ... 'PHL' 'PDX' 'SAC'\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    lat            (location) float64 104B 33.63 42.36 34.2 ... 39.87 45.6 38.51\n",
      "    lon            (location) float64 104B -84.44 -71.01 ... -122.6 -121.5\n",
      "    time           (forecast_date, lead) datetime64[ns] 1kB 2020-10-16 ... 20...\n",
      "Data variables:\n",
      "    crpss_ens_all  (forecast_date, lead, location) float64 15kB -9.386 ... -1...\n",
      "    crpss_ens      (lead, location) float64 4kB -1.907 -1.268 ... -0.3851\n",
      "Attributes:\n",
      "    short_name:  crpss\n",
      "    long_name:   CRPSS\n"
     ]
    }
   ],
   "source": [
    "if ref is None:\n",
    "    print(\"No reference model, skipping relative comparison\")\n",
    "    skill_ref = None\n",
    "    skill_rel = None\n",
    "else:\n",
    "    # Skill of the reference model:\n",
    "    skill_ref = sk.skill.crps_ensemble(observations=era, forecasts=ref)\n",
    "\n",
    "    # Relative skills score of Salient downscale vs the reference model:\n",
    "    skill_rel = sk.skill.crpss(forecast=skill_gem, reference=skill_ref)\n",
    "    print(skill_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skill_ref is None:\n",
    "    print(\"Skipping relative skill plotting\")\n",
    "else:\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    skill_ref[f\"crps_ens\"].mean(\"location\", keep_attrs=True).plot(\n",
    "        ax=ax,\n",
    "        color=\"#FF7F00\",\n",
    "        linewidth=2,\n",
    "        label=ref_name,\n",
    "    )\n",
    "    skill_gem[f\"crps_ens\"].mean(\"location\", keep_attrs=True).plot(\n",
    "        ax=ax,\n",
    "        color=\"dodgerblue\",\n",
    "        linewidth=2,\n",
    "        label=gem_name,\n",
    "    )\n",
    "\n",
    "    ax.xaxis.set_major_formatter(lambda x, pos: f\"{x/1e9/86400:.0f}\")\n",
    "    ax.set_xlabel(\"Lead Time (days)\")\n",
    "    ax.set_ylabel(f\"CRPS {gem.vals_ens.attrs['long_name']} [{gem.vals_ens.attrs['units']}]\")\n",
    "    ax.set_title(f\"{poc_warn} All-locations Mean CRPS (lower is better)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skill_rel is None:\n",
    "    print(\"Skipping relative skill boxplot\")\n",
    "else:\n",
    "    medians = skill_rel[f\"crpss_ens\"].median(\"lead\")\n",
    "    sorted_locations = medians.sortby(medians, ascending=False).location.values\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    df = skill_rel[f\"crpss_ens\"].to_pandas().melt(ignore_index=False)\n",
    "    ax.boxplot(\n",
    "        [df[df[\"location\"] == loc][\"value\"] for loc in sorted_locations],\n",
    "        tick_labels=sorted_locations,  # Updated parameter name\n",
    "        patch_artist=True,\n",
    "        showfliers=False,\n",
    "        medianprops=dict(color=\"black\"),\n",
    "        boxprops=dict(facecolor=\"dodgerblue\"),\n",
    "    )\n",
    "    ax.axhline(y=0, color=\"grey\", linestyle=\":\", zorder=0)\n",
    "    ax.set_xlabel(\"Location\")\n",
    "    ax.set_ylabel(f\"CRPSS {gem.vals_ens.attrs['long_name']}\")\n",
    "    ax.set_title(f\"{poc_warn} Relative Skill {gem_name} vs {ref_name} (higher is better)\")\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.set_ylim(max(-1, ymin), min(1, ymax))\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salientsdk-54A4kIpb-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
