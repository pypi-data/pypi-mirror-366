<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>statkit.feature_selection API documentation</title>
<meta name="description" content="Select features using statistical hypothesis testing." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>statkit.feature_selection</code></h1>
</header>
<section id="section-intro">
<p>Select features using statistical hypothesis testing.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Select features using statistical hypothesis testing.&#34;&#34;&#34;

from typing import Literal

from numpy import linalg, nan
from numpy.typing import NDArray

from pandas import DataFrame
from scipy.stats import (  # type: ignore
    epps_singleton_2samp as epps_singleton,
    ks_2samp as kolmogorov_smirnov,
    mannwhitneyu as mann_whitney_u,
)
from sklearn.base import BaseEstimator  # type: ignore
from sklearn.feature_selection import SelectorMixin  # type: ignore
from sklearn.utils.multiclass import unique_labels  # type: ignore
from sklearn.utils import check_X_y  # type: ignore
from statsmodels.stats.multitest import fdrcorrection, multipletests  # type: ignore


class StatisticalTestFilter(BaseEstimator, SelectorMixin):
    &#34;&#34;&#34;Select columns with significant difference between labels.

    Test which features the distribution of the postive class is stastistically
    different from the negative class, using multiple testing correction. Keep only the
    features that passed the statistical test.
    &#34;&#34;&#34;

    def _apply_test(
        self,
        X_pos: NDArray,
        X_neg: NDArray,
        multiple_testing: Literal[
            &#34;benjamini-hochberg&#34;, &#34;bonferroni&#34;
        ] = &#34;benjamini-hochberg&#34;,
    ) -&gt; DataFrame:
        &#34;&#34;&#34;Column-wise test between positive and negative group.&#34;&#34;&#34;
        columns = tuple(range(X_pos.shape[1]))
        if hasattr(self, &#34;feature_names_in_&#34;):
            columns = self.feature_names_in_

        result = DataFrame(columns=[&#34;statistic&#34;, &#34;pvalue&#34;], index=columns)

        # Perform test for each feature.
        for i, col in enumerate(columns):
            try:
                statistic, p_value = self.test_(
                    X_pos[:, i], X_neg[:, i], **self.test_kwargs_
                )
            except (linalg.LinAlgError, ValueError):
                statistic, p_value = nan, nan
            result.loc[col] = [statistic, p_value]  # type: ignore

        # Apply multiple-testing correction.
        if multiple_testing == &#34;benjamini-hochberg&#34;:
            reject, pvalue_corrected = fdrcorrection(result.pvalue, alpha=self.p_value)
        elif multiple_testing == &#34;bonferroni&#34;:
            reject, pvalue_corrected, _, _ = multipletests(
                result.pvalue, alpha=self.p_value, method=&#34;bonferroni&#34;
            )

        result[&#34;pvalue-corrected&#34;] = pvalue_corrected
        result[&#34;reject&#34;] = reject

        return result

    def __init__(
        self,
        statistical_test: Literal[
            &#34;kolmogorov-smirnov&#34;, &#34;mann-whitney-u&#34;, &#34;epps-singleton&#34;
        ] = &#34;kolmogorov-smirnov&#34;,
        p_value: float = 0.05,
        multiple_testing: Literal[
            &#34;benjamini-hochberg&#34;, &#34;bonferroni&#34;
        ] = &#34;benjamini-hochberg&#34;,
        invert: bool = False,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Args:
            statistical_test: Test for difference in feature distributions
                between labels.
            p_value: The null hypothesis rejection probability (including
                `correction`).
            multiple_testing: What type of correction strategy to apply to account for
                multiple testing.
            invert: Invert selection, by keeping only the non-significant (instead of
                significant) columns.
        &#34;&#34;&#34;
        super().__init__(**kwargs)
        self.statistical_test = statistical_test
        self.p_value = p_value
        self.multiple_testing = multiple_testing
        self.invert = invert

    def _get_support_mask(self):
        &#34;&#34;&#34;Compute support mask of features.&#34;&#34;&#34;
        if self.invert:
            return ~self.scores_[&#34;reject&#34;]
        return self.scores_[&#34;reject&#34;]

    def fit(self, X, y):
        &#34;&#34;&#34;Perform column-wise statistical test.&#34;&#34;&#34;
        check_X_y(X, y)
        self._check_feature_names(X, reset=True)

        self.test_kwargs_ = {}
        statistical_functions = {
            &#34;mann-whitney-u&#34;: mann_whitney_u,
            &#34;kolmogorov-smirnov&#34;: kolmogorov_smirnov,
            &#34;epps-singleton&#34;: epps_singleton,
        }

        if self.statistical_test not in statistical_functions.keys():
            raise KeyError(f&#34;Unknown statistical method {self.statistical_test}.&#34;)

        self.test_ = statistical_functions[self.statistical_test]

        # Only allow two classes right now.
        self.classes_ = unique_labels(y)
        assert len(self.classes_) == 2
        X_neg = X[y == self.classes_[0]]
        X_pos = X[y == self.classes_[1]]

        if isinstance(X, DataFrame):
            X_neg = X_neg.to_numpy()
            X_pos = X_pos.to_numpy()

        self.scores_ = self._apply_test(
            X_pos, X_neg, multiple_testing=self.multiple_testing
        )

        return self</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="statkit.feature_selection.StatisticalTestFilter"><code class="flex name class">
<span>class <span class="ident">StatisticalTestFilter</span></span>
<span>(</span><span>statistical_test: Literal['kolmogorov-smirnov', 'mann-whitney-u', 'epps-singleton'] = 'kolmogorov-smirnov', p_value: float = 0.05, multiple_testing: Literal['benjamini-hochberg', 'bonferroni'] = 'benjamini-hochberg', invert: bool = False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Select columns with significant difference between labels.</p>
<p>Test which features the distribution of the postive class is stastistically
different from the negative class, using multiple testing correction. Keep only the
features that passed the statistical test.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>statistical_test</code></strong></dt>
<dd>Test for difference in feature distributions
between labels.</dd>
<dt><strong><code>p_value</code></strong></dt>
<dd>The null hypothesis rejection probability (including
<code>correction</code>).</dd>
<dt><strong><code>multiple_testing</code></strong></dt>
<dd>What type of correction strategy to apply to account for
multiple testing.</dd>
<dt><strong><code>invert</code></strong></dt>
<dd>Invert selection, by keeping only the non-significant (instead of
significant) columns.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StatisticalTestFilter(BaseEstimator, SelectorMixin):
    &#34;&#34;&#34;Select columns with significant difference between labels.

    Test which features the distribution of the postive class is stastistically
    different from the negative class, using multiple testing correction. Keep only the
    features that passed the statistical test.
    &#34;&#34;&#34;

    def _apply_test(
        self,
        X_pos: NDArray,
        X_neg: NDArray,
        multiple_testing: Literal[
            &#34;benjamini-hochberg&#34;, &#34;bonferroni&#34;
        ] = &#34;benjamini-hochberg&#34;,
    ) -&gt; DataFrame:
        &#34;&#34;&#34;Column-wise test between positive and negative group.&#34;&#34;&#34;
        columns = tuple(range(X_pos.shape[1]))
        if hasattr(self, &#34;feature_names_in_&#34;):
            columns = self.feature_names_in_

        result = DataFrame(columns=[&#34;statistic&#34;, &#34;pvalue&#34;], index=columns)

        # Perform test for each feature.
        for i, col in enumerate(columns):
            try:
                statistic, p_value = self.test_(
                    X_pos[:, i], X_neg[:, i], **self.test_kwargs_
                )
            except (linalg.LinAlgError, ValueError):
                statistic, p_value = nan, nan
            result.loc[col] = [statistic, p_value]  # type: ignore

        # Apply multiple-testing correction.
        if multiple_testing == &#34;benjamini-hochberg&#34;:
            reject, pvalue_corrected = fdrcorrection(result.pvalue, alpha=self.p_value)
        elif multiple_testing == &#34;bonferroni&#34;:
            reject, pvalue_corrected, _, _ = multipletests(
                result.pvalue, alpha=self.p_value, method=&#34;bonferroni&#34;
            )

        result[&#34;pvalue-corrected&#34;] = pvalue_corrected
        result[&#34;reject&#34;] = reject

        return result

    def __init__(
        self,
        statistical_test: Literal[
            &#34;kolmogorov-smirnov&#34;, &#34;mann-whitney-u&#34;, &#34;epps-singleton&#34;
        ] = &#34;kolmogorov-smirnov&#34;,
        p_value: float = 0.05,
        multiple_testing: Literal[
            &#34;benjamini-hochberg&#34;, &#34;bonferroni&#34;
        ] = &#34;benjamini-hochberg&#34;,
        invert: bool = False,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Args:
            statistical_test: Test for difference in feature distributions
                between labels.
            p_value: The null hypothesis rejection probability (including
                `correction`).
            multiple_testing: What type of correction strategy to apply to account for
                multiple testing.
            invert: Invert selection, by keeping only the non-significant (instead of
                significant) columns.
        &#34;&#34;&#34;
        super().__init__(**kwargs)
        self.statistical_test = statistical_test
        self.p_value = p_value
        self.multiple_testing = multiple_testing
        self.invert = invert

    def _get_support_mask(self):
        &#34;&#34;&#34;Compute support mask of features.&#34;&#34;&#34;
        if self.invert:
            return ~self.scores_[&#34;reject&#34;]
        return self.scores_[&#34;reject&#34;]

    def fit(self, X, y):
        &#34;&#34;&#34;Perform column-wise statistical test.&#34;&#34;&#34;
        check_X_y(X, y)
        self._check_feature_names(X, reset=True)

        self.test_kwargs_ = {}
        statistical_functions = {
            &#34;mann-whitney-u&#34;: mann_whitney_u,
            &#34;kolmogorov-smirnov&#34;: kolmogorov_smirnov,
            &#34;epps-singleton&#34;: epps_singleton,
        }

        if self.statistical_test not in statistical_functions.keys():
            raise KeyError(f&#34;Unknown statistical method {self.statistical_test}.&#34;)

        self.test_ = statistical_functions[self.statistical_test]

        # Only allow two classes right now.
        self.classes_ = unique_labels(y)
        assert len(self.classes_) == 2
        X_neg = X[y == self.classes_[0]]
        X_pos = X[y == self.classes_[1]]

        if isinstance(X, DataFrame):
            X_neg = X_neg.to_numpy()
            X_pos = X_pos.to_numpy()

        self.scores_ = self._apply_test(
            X_pos, X_neg, multiple_testing=self.multiple_testing
        )

        return self</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.base.BaseEstimator</li>
<li>sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin</li>
<li>sklearn.utils._metadata_requests._MetadataRequester</li>
<li>sklearn.feature_selection._base.SelectorMixin</li>
<li>sklearn.base.TransformerMixin</li>
<li>sklearn.utils._set_output._SetOutputMixin</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="statkit.feature_selection.StatisticalTestFilter.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform column-wise statistical test.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, X, y):
    &#34;&#34;&#34;Perform column-wise statistical test.&#34;&#34;&#34;
    check_X_y(X, y)
    self._check_feature_names(X, reset=True)

    self.test_kwargs_ = {}
    statistical_functions = {
        &#34;mann-whitney-u&#34;: mann_whitney_u,
        &#34;kolmogorov-smirnov&#34;: kolmogorov_smirnov,
        &#34;epps-singleton&#34;: epps_singleton,
    }

    if self.statistical_test not in statistical_functions.keys():
        raise KeyError(f&#34;Unknown statistical method {self.statistical_test}.&#34;)

    self.test_ = statistical_functions[self.statistical_test]

    # Only allow two classes right now.
    self.classes_ = unique_labels(y)
    assert len(self.classes_) == 2
    X_neg = X[y == self.classes_[0]]
    X_pos = X[y == self.classes_[1]]

    if isinstance(X, DataFrame):
        X_neg = X_neg.to_numpy()
        X_pos = X_pos.to_numpy()

    self.scores_ = self._apply_test(
        X_pos, X_neg, multiple_testing=self.multiple_testing
    )

    return self</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="statkit" href="index.html">statkit</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="statkit.feature_selection.StatisticalTestFilter" href="#statkit.feature_selection.StatisticalTestFilter">StatisticalTestFilter</a></code></h4>
<ul class="">
<li><code><a title="statkit.feature_selection.StatisticalTestFilter.fit" href="#statkit.feature_selection.StatisticalTestFilter.fit">fit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>