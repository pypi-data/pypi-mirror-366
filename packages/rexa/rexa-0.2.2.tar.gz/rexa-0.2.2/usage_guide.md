# üéâ Rexa Usage Guide

Welcome to **Rexa**, your one-stop Python library for powerful regex operations and text preprocessing! Whether you‚Äôre building web scrapers, form validators, or NLP pipelines, this guide will help you harness Rexa‚Äôs full potential.

---

## üîç 1. Validator (`validation.py`)
Validate and match common patterns with ease:

| Method                      | What it does                                          | Example                                                |
|-----------------------------|-------------------------------------------------------|--------------------------------------------------------|
| `Is_Email(s)`               | ‚úÖ Returns True if `s` is a valid email               | `Rex().Is_Email("user@example.com")  # True`         |
| `Match_Email(s)`            | üîé Returns a Match object for valid email, else None  | `Rex().Match_Email("bad@")  # None`                   |
| `Is_URL(s)`                 | ‚úÖ Validate HTTP/HTTPS URLs                           | `Rex().Is_URL("https://site.io")  # True`             |
| `Match_URL(s)`              | üîé Match URL and capture path/query                   | `m = Rex().Match_URL("site.com/path")`                |
| `Is_Date_ISO(s)`            | ‚úÖ Check `YYYY-MM-DD` date format                      | `Rex().Is_Date_ISO("2025-08-02")  # True`             |
| `Match_Date_ISO(s)`         | üîé Capture ISO date, if present                       | `Rex().Match_Date_ISO("02/08/2025")  # None`          |

*And many more `Is_*` / `Match_*` methods for phones, UUIDs, etc.*

---

## üì• 2. Extractor (`extraction.py`)
Pull data out of messy text:

| Method                          | Extracts‚Ä¶                                | Example                                                      |
|---------------------------------|------------------------------------------|--------------------------------------------------------------|
| `Extract_Emails(text)`          | All email addresses                      | `Rex().Extract_Emails("a@a.com b@b.org")` # [`a@a.com`,`b@b.org`] |
| `Extract_URLs(text)`            | All web links                            | `Rex().Extract_URLs("Go to http://x.com")` # [`http://x.com`]    |
| `Extract_Dates(text)`           | Dates in ISO/EU formats                  | `Rex().Extract_Dates("2021-01-01 or 01/01/2021")`           |
| `Extract_Phones(text)`          | Phone numbers (intl & local)             | `Rex().Extract_Phones("+123456789, 09121234567")`           |

*‚Ä¶plus IPv4, UUIDs, and more.*

---

## üîÑ 3. Converter (`conversion.py`)
Normalize and reformat strings:

| Method                                  | Transforms‚Ä¶                                   | Example                                                      |
|-----------------------------------------|-----------------------------------------------|--------------------------------------------------------------|
| `Convert_MultipleSpaces(text)`          | Collapse extra spaces                         | `Rex().Convert_MultipleSpaces("A   B")` ‚Üí `"A B"`        |
| `Convert_ThousandSeparatedNumbers(text)`| Strip commas from large numbers               | `Rex().Convert_ThousandSeparatedNumbers("1,000,000")` ‚Üí `"1000000"` |
| `Convert_DateFormat(s,from,to)`         | Swap date separators                          | `Rex().Convert_DateFormat("01.01.2025",".","/")` ‚Üí `"01/01/2025"` |
| `Slugify(text)`                         | Generate SEO-friendly URL slugs               | `Rex().Slugify("Hello World!")` ‚Üí `"hello-world"`         |

---

## ‚ú® 4. Formatter (`formatting.py`)
Clean up and standardize:

| Method                           | Cleans‚Ä¶                          | Example                                            |
|----------------------------------|----------------------------------|----------------------------------------------------|
| `Strip_HTMLTags(s)`              | Remove HTML tags                 | `Rex().Strip_HTMLTags("<b>Hi</b>")` ‚Üí `"Hi"`     |
| `Normalize_Spaces(s)`            | Single-space normalization       | `Rex().Normalize_Spaces("A   B")` ‚Üí `"A B"`     |
| `Remove_ThousandSeparators(s)`   | Drop commas in numbers           | `Rex().Remove_ThousandSeparators("1,234")` ‚Üí `"1234"` |
| `Normalize_DateSeparator(s,sep)` | Consistent date delimiter        | `Rex().Normalize_DateSeparator("2021/01.01","-")` ‚Üí `"2021-01-01"` |

---

## üßπ 5. TextTools (`texttools.py`)
Advanced NLP & text cleaning utilities:

| Method                               | Description                              | Example                                                       |
|--------------------------------------|------------------------------------------|---------------------------------------------------------------|
| `to_lower(s)`                        | Lowercase entire string                  | `TextTools.to_lower("HELLO")` ‚Üí `"hello"`                   |
| `to_upper(s)`                        | Uppercase entire string                  | `TextTools.to_upper("hi")` ‚Üí `"HI"`                         |
| `remove_emojis(s)`                   | Strip Unicode emojis                     | `TextTools.remove_emojis("I ‚ù§Ô∏è you")` ‚Üí `"I  you"`         |
| `remove_numbers(s)`                  | Remove all digits                        | `TextTools.remove_numbers("a1b2")` ‚Üí `"ab"`                |
| `remove_usernames(s)`                | Remove `@username` tokens                | `TextTools.remove_usernames("@me hi")` ‚Üí `" hi"`            |
| `remove_punctuation(s)`              | Strip punctuation & symbols              | `TextTools.remove_punctuation("Hey!?@")` ‚Üí `"Hey"`         |
| `remove_urls_emails(s)`              | Drop URLs & email addresses              | `TextTools.remove_urls_emails("a@b.com http://x")` ‚Üí `" "`  |
| `remove_stopwords(s)`                | Filter common words (using NLTK)         | `TextTools.remove_stopwords("the cat sits")` ‚Üí `"cat sits"`  |
| `lemmatize_text(s)`                  | Lemmatize tokens                         | `TextTools.lemmatize_text("running")` ‚Üí `"running"`         |
| `stem_text(s)`                       | Stem tokens                              | `TextTools.stem_text("running")` ‚Üí `"run"`                  |
| `normalize_whitespace(s)`            | Collapse whitespace                      | `TextTools.normalize_whitespace(" A  B\n")` ‚Üí `"A B"`    |
| `normalize_arabic(s)`                | Persian/Arabic char mapping & diacritics | `TextTools.normalize_arabic("ŸÉ€åŸÅ")` ‚Üí `"⁄©€åŸÅ"`              |
| `count_tokens(s)`                    | Count word tokens                        | `TextTools.count_tokens("a b c")` ‚Üí `3`                       |
| `remove_short_long_words(s,min,max)` | Keep words len in range                  | `TextTools.remove_short_long_words("a bb ccc",2,3)` ‚Üí `"bb ccc"` |
| `detect_language(s)`                 | Auto-detect text language                | `TextTools.detect_language("hello")` ‚Üí `"en"`              |
| `clean_text(...kwargs)`             | Pipeline for common cleaning options     | `TextTools.clean_text("Hi @you 123 üòä", lowercase=True, remove_emoji=True, remove_username=True, remove_urls_emails=True, remove_punct=True)` ‚Üí `"hi"` |

---

## üöÄ Quick Tips

- **Mix & Match**: Call only the methods you need or use `clean_text` for a one-shot pipeline.  
- **Extendable**: Create subclasses to add domain-specific patterns.  
- **Performance**: For bulk text, parallelize tokenization and regex calls.  

Happy coding with **Rexa**! Questions or feedback? Open an issue at https://github.com/arshia82sbn/rexa/issues
